{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Zipline_Reloaded_BacktestEngine.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "77fec636d3954e9bad017b71779b1225": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_69ee373d8e504d0d92bc966293cd7ea2",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_cbc7915c31274e1aa7e43760699c8de2",
            "value": ""
          }
        },
        "69ee373d8e504d0d92bc966293cd7ea2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cbc7915c31274e1aa7e43760699c8de2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/francoishcm/BackTesting/blob/master/Zipline_Reloaded_BacktestEngine_1_05082022.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üß∞**INSTALL MODULES**"
      ],
      "metadata": {
        "id": "xRTs1_SK0Scj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive \n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "ABrWrt1q06gq",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1tlwk44QhErd"
      },
      "source": [
        "# Install ta-lib v0.4.0\n",
        "%%bash\n",
        "wget http://prdownloads.sourceforge.net/ta-lib/ta-lib-0.4.0-src.tar.gz\n",
        "tar -xzf ta-lib-0.4.0-src.tar.gz\n",
        "cd ta-lib/\n",
        "./configure\n",
        "make\n",
        "make install"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JSwN3Ywihz3r",
        "collapsed": true
      },
      "source": [
        "# Install zipline\n",
        "%pip install zipline-reloaded"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install iso3166==2.0.2"
      ],
      "metadata": {
        "id": "w2cgjqTU8TKt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Install Pyfolio\n",
        "!pip install pyfolio-reloaded"
      ],
      "metadata": {
        "id": "m-y07xfPTFVK",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Install matplot library\n",
        "!pip install matplotlib"
      ],
      "metadata": {
        "collapsed": true,
        "id": "zoV1_FSc_5MW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Install data bundle 'Quandl'\n",
        "!pip install quandl"
      ],
      "metadata": {
        "collapsed": true,
        "id": "8-pgTCGp2XzF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import zipline\n",
        "zipline.__version__"
      ],
      "metadata": {
        "id": "C9erwAEdVunF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nasdaq-data-link"
      ],
      "metadata": {
        "id": "jjqASrBOT4Rc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üíΩ**SET WORKING DIRECTORY**"
      ],
      "metadata": {
        "id": "4Ixua2eyz0Hr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os \n",
        "\n",
        "# Set your working directory to a folder in your Google Drive. This way, if your notebook times out,\n",
        "# your files will be saved in your Google Drive!\n",
        "\n",
        "# the base Google Drive directory\n",
        "root_dir = \"/content/drive/\"\n"
      ],
      "metadata": {
        "id": "eWtZZXQol34j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os \n",
        "\n",
        "# Set your working directory to a folder in your Google Drive. This way, if your notebook times out,\n",
        "# your files will be saved in your Google Drive!\n",
        "\n",
        "\n",
        "# choose where you want your project files to be saved\n",
        "project_folder = \"MyDrive/Colab Notebooks/My Project Folder\"\n"
      ],
      "metadata": {
        "id": "c4jxNssSmApK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_and_set_working_directory(project_folder):\n",
        "  # check if your project folder exists. if not, it will be created.\n",
        "  if os.path.isdir(root_dir + project_folder) == False:\n",
        "    os.mkdir(root_dir + project_folder)\n",
        "    print(root_dir + project_folder + ' did not exist but was created.')\n",
        "\n",
        "  # change the OS to use your project folder as the working directory\n",
        "  os.chdir(root_dir + project_folder)\n",
        "\n",
        "  # create a test file to make sure it shows up in the right place\n",
        "  !touch 'new_file_in_working_directory.txt'\n",
        "  print('\\nYour working directory was changed to ' + root_dir + project_folder + \\\n",
        "        \"\\n\\nAn empty text file was created there. You can also run !pwd to confirm the current working directory.\" )\n",
        "\n",
        "create_and_set_working_directory(project_folder)"
      ],
      "metadata": {
        "id": "Y0PGKB_SmAR5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Confirm current working directory\n",
        "!pwd"
      ],
      "metadata": {
        "id": "Q4_HSs4HneUa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "for f in os.listdir(\"//content/drive/MyDrive/Colab Notebooks/My Project Folder\"):\n",
        "\tprint(f)"
      ],
      "metadata": {
        "id": "8HB8gDZGqsfB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ‚è≥**INGEST DATA**"
      ],
      "metadata": {
        "id": "z5Y1KYNHeqeu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ingest custom bundle\n",
        "!zipline ingest --bundle 'crypto'"
      ],
      "metadata": {
        "id": "CvMaJ1U1eVhB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ingest custom bundle\n",
        "!zipline ingest --bundle 'equities_csvdir'"
      ],
      "metadata": {
        "id": "okd6vU6j5iPt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ingest custom bundle\n",
        "!zipline ingest --bundle 'random_futures_data'"
      ],
      "metadata": {
        "id": "1tKhQWGK5Z8T",
        "outputId": "bc8d0821-9105-4bf2-e2db-e29118cb614d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2022-08-05 15:52:13.251111] INFO: zipline.data.bundles.core: Ingesting random_futures_data.\n",
            "Loading data...: 100% 735/735 [00:37<00:00, 19.68it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ingest custom bundle\n",
        "!zipline ingest --bundle 'random_stock_data'"
      ],
      "metadata": {
        "id": "lvSZVAHNJDW4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "INGEST QUANDL STOCK BUNDLE\n",
        "'''\n",
        "# Ingest bundle API\n",
        "!QUANDL_API_KEY=KUnssHvVERHb5XYu9C1- zipline ingest -b 'quandl'"
      ],
      "metadata": {
        "id": "KiUF_IBQCSlm",
        "collapsed": true,
        "outputId": "843e73a1-aaa6-49b5-fd76-077a682fcde6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2022-08-05 16:11:15.981935] INFO: zipline.data.bundles.core: Ingesting quandl.\n",
            "[2022-08-05 16:11:15.982213] INFO: zipline.data.bundles.quandl: Downloading WIKI metadata.\n",
            "\u001b[?25lDownloading WIKI Prices table from Quandl  [####################################]  100%          \u001b[?25h\n",
            "[2022-08-05 16:11:29.947303] INFO: zipline.data.bundles.quandl: Parsing raw data.\n",
            "[2022-08-05 16:12:05.302010] INFO: zipline.data.bundles.quandl: Generating asset metadata.\n",
            "\u001b[?25lMerging daily equity files:  [---------------------#--------------]  1731/usr/local/lib/python3.7/dist-packages/zipline/data/bcolz_daily_bars.py:366: UserWarning: Ignoring 1 values because they are out of bounds for uint32:             open  ...  split_ratio\n",
            "2011-04-11  1.79  ...          1.0\n",
            "\n",
            "[1 rows x 7 columns]\n",
            "  winsorise_uint32(raw_data, invalid_data_behavior, \"volume\", *OHLC)\n",
            "\u001b[?25lMerging daily equity files:  [####################################]      \u001b[?25h\n",
            "[2022-08-05 16:14:44.391215] INFO: zipline.data.bundles.quandl: Parsing split data.\n",
            "[2022-08-05 16:14:44.557813] INFO: zipline.data.bundles.quandl: Parsing dividend data.\n",
            "[2022-08-05 16:14:46.226532] WARNING: zipline.data.adjustments: Couldn't compute ratio for dividend sid=67, ex_date=2017-11-09, amount=0.620\n",
            "[2022-08-05 16:14:46.226745] WARNING: zipline.data.adjustments: Couldn't compute ratio for dividend sid=93, ex_date=2017-11-09, amount=0.240\n",
            "[2022-08-05 16:14:46.226825] WARNING: zipline.data.adjustments: Couldn't compute ratio for dividend sid=161, ex_date=2017-11-09, amount=0.110\n",
            "[2022-08-05 16:14:46.226901] WARNING: zipline.data.adjustments: Couldn't compute ratio for dividend sid=283, ex_date=2017-11-09, amount=0.415\n",
            "[2022-08-05 16:14:46.226972] WARNING: zipline.data.adjustments: Couldn't compute ratio for dividend sid=298, ex_date=2017-11-09, amount=1.420\n",
            "[2022-08-05 16:14:46.227029] WARNING: zipline.data.adjustments: Couldn't compute ratio for dividend sid=318, ex_date=2017-11-09, amount=0.330\n",
            "[2022-08-05 16:14:46.227081] WARNING: zipline.data.adjustments: Couldn't compute ratio for dividend sid=434, ex_date=2017-11-09, amount=0.110\n",
            "[2022-08-05 16:14:46.227131] WARNING: zipline.data.adjustments: Couldn't compute ratio for dividend sid=516, ex_date=1996-05-30, amount=0.310\n",
            "[2022-08-05 16:14:46.227198] WARNING: zipline.data.adjustments: Couldn't compute ratio for dividend sid=524, ex_date=2017-11-09, amount=0.050\n",
            "[2022-08-05 16:14:46.227249] WARNING: zipline.data.adjustments: Couldn't compute ratio for dividend sid=556, ex_date=2017-11-09, amount=0.075\n",
            "[2022-08-05 16:14:46.227313] WARNING: zipline.data.adjustments: Couldn't compute ratio for dividend sid=578, ex_date=2017-11-09, amount=0.160\n",
            "[2022-08-05 16:14:46.227363] WARNING: zipline.data.adjustments: Couldn't compute ratio for dividend sid=605, ex_date=2017-11-09, amount=0.040\n",
            "[2022-08-05 16:14:46.227414] WARNING: zipline.data.adjustments: Couldn't compute ratio for dividend sid=666, ex_date=1990-03-26, amount=0.140\n",
            "[2022-08-05 16:14:46.227464] WARNING: zipline.data.adjustments: Couldn't compute ratio for dividend sid=694, ex_date=1990-03-27, amount=0.100\n",
            "[2022-08-05 16:14:46.227513] WARNING: zipline.data.adjustments: Couldn't compute ratio for dividend sid=723, ex_date=2017-11-09, amount=1.620\n",
            "[2022-08-05 16:14:46.227563] WARNING: zipline.data.adjustments: Couldn't compute ratio for dividend sid=758, ex_date=2017-11-09, amount=0.500\n",
            "[2022-08-05 16:14:46.227612] WARNING: zipline.data.adjustments: Couldn't compute ratio for dividend sid=788, ex_date=2017-11-09, amount=0.060\n",
            "[2022-08-05 16:14:46.227661] WARNING: zipline.data.adjustments: Couldn't compute ratio for dividend sid=859, ex_date=1995-05-09, amount=0.100\n",
            "[2022-08-05 16:14:46.227710] WARNING: zipline.data.adjustments: Couldn't compute ratio for dividend sid=904, ex_date=2017-11-09, amount=0.135\n",
            "[2022-08-05 16:14:46.227759] WARNING: zipline.data.adjustments: Couldn't compute ratio for dividend sid=975, ex_date=2017-11-09, amount=0.030\n",
            "[2022-08-05 16:14:46.227808] WARNING: zipline.data.adjustments: Couldn't compute ratio for dividend sid=1057, ex_date=2017-11-09, amount=0.250\n",
            "[2022-08-05 16:14:46.227858] WARNING: zipline.data.adjustments: Couldn't compute ratio for dividend sid=1088, ex_date=1990-03-26, amount=0.240\n",
            "[2022-08-05 16:14:46.227911] WARNING: zipline.data.adjustments: Couldn't compute ratio for dividend sid=1091, ex_date=2017-11-09, amount=0.075\n",
            "[2022-08-05 16:14:46.227976] WARNING: zipline.data.adjustments: Couldn't compute ratio for dividend sid=1111, ex_date=1993-03-04, amount=0.070\n",
            "[2022-08-05 16:14:46.228028] WARNING: zipline.data.adjustments: Couldn't compute ratio for dividend sid=1172, ex_date=2017-11-09, amount=0.130\n",
            "[2022-08-05 16:14:46.228077] WARNING: zipline.data.adjustments: Couldn't compute ratio for dividend sid=1209, ex_date=2017-11-09, amount=0.010\n",
            "[2022-08-05 16:14:46.228127] WARNING: zipline.data.adjustments: Couldn't compute ratio for dividend sid=1322, ex_date=1995-05-25, amount=0.150\n",
            "[2022-08-05 16:14:46.228189] WARNING: zipline.data.adjustments: Couldn't compute ratio for dividend sid=1441, ex_date=2017-11-09, amount=1.500\n",
            "[2022-08-05 16:14:46.228240] WARNING: zipline.data.adjustments: Couldn't compute ratio for dividend sid=1525, ex_date=2017-11-09, amount=0.090\n",
            "[2022-08-05 16:14:46.228290] WARNING: zipline.data.adjustments: Couldn't compute ratio for dividend sid=1600, ex_date=2015-07-06, amount=16.500\n",
            "[2022-08-05 16:14:46.228340] WARNING: zipline.data.adjustments: Couldn't compute ratio for dividend sid=1642, ex_date=2017-11-09, amount=0.270\n",
            "[2022-08-05 16:14:46.228389] WARNING: zipline.data.adjustments: Couldn't compute ratio for dividend sid=1748, ex_date=2017-11-09, amount=0.740\n",
            "[2022-08-05 16:14:46.228438] WARNING: zipline.data.adjustments: Couldn't compute ratio for dividend sid=1876, ex_date=2017-11-09, amount=0.120\n",
            "[2022-08-05 16:14:46.228487] WARNING: zipline.data.adjustments: Couldn't compute ratio for dividend sid=1922, ex_date=2017-11-09, amount=0.040\n",
            "[2022-08-05 16:14:46.228535] WARNING: zipline.data.adjustments: Couldn't compute ratio for dividend sid=1947, ex_date=1990-03-26, amount=0.150\n",
            "[2022-08-05 16:14:46.228597] WARNING: zipline.data.adjustments: Couldn't compute ratio for dividend sid=2098, ex_date=2017-11-09, amount=0.200\n",
            "[2022-08-05 16:14:46.228647] WARNING: zipline.data.adjustments: Couldn't compute ratio for dividend sid=2118, ex_date=2014-11-06, amount=0.050\n",
            "[2022-08-05 16:14:46.228695] WARNING: zipline.data.adjustments: Couldn't compute ratio for dividend sid=2120, ex_date=2017-11-09, amount=0.110\n",
            "[2022-08-05 16:14:46.228744] WARNING: zipline.data.adjustments: Couldn't compute ratio for dividend sid=2149, ex_date=2017-11-09, amount=0.330\n",
            "[2022-08-05 16:14:46.228793] WARNING: zipline.data.adjustments: Couldn't compute ratio for dividend sid=2204, ex_date=2017-11-09, amount=0.320\n",
            "[2022-08-05 16:14:46.228841] WARNING: zipline.data.adjustments: Couldn't compute ratio for dividend sid=2220, ex_date=2017-11-09, amount=0.660\n",
            "[2022-08-05 16:14:46.228891] WARNING: zipline.data.adjustments: Couldn't compute ratio for dividend sid=2281, ex_date=2017-11-09, amount=0.450\n",
            "[2022-08-05 16:14:46.228940] WARNING: zipline.data.adjustments: Couldn't compute ratio for dividend sid=2389, ex_date=2017-11-09, amount=0.140\n",
            "[2022-08-05 16:14:46.228995] WARNING: zipline.data.adjustments: Couldn't compute ratio for dividend sid=2441, ex_date=2017-11-09, amount=0.215\n",
            "[2022-08-05 16:14:46.229046] WARNING: zipline.data.adjustments: Couldn't compute ratio for dividend sid=2517, ex_date=2017-11-09, amount=0.080\n",
            "[2022-08-05 16:14:46.229095] WARNING: zipline.data.adjustments: Couldn't compute ratio for dividend sid=2582, ex_date=2017-11-09, amount=0.780\n",
            "[2022-08-05 16:14:46.229155] WARNING: zipline.data.adjustments: Couldn't compute ratio for dividend sid=2622, ex_date=2017-11-09, amount=0.390\n",
            "[2022-08-05 16:14:46.229207] WARNING: zipline.data.adjustments: Couldn't compute ratio for dividend sid=2662, ex_date=2015-01-14, amount=0.750\n",
            "[2022-08-05 16:14:46.229256] WARNING: zipline.data.adjustments: Couldn't compute ratio for dividend sid=2754, ex_date=2000-12-27, amount=0.250\n",
            "[2022-08-05 16:14:46.229306] WARNING: zipline.data.adjustments: Couldn't compute ratio for dividend sid=2754, ex_date=2009-09-11, amount=0.420\n",
            "[2022-08-05 16:14:46.229355] WARNING: zipline.data.adjustments: Couldn't compute ratio for dividend sid=2754, ex_date=2009-12-11, amount=0.420\n",
            "[2022-08-05 16:14:46.229403] WARNING: zipline.data.adjustments: Couldn't compute ratio for dividend sid=2754, ex_date=2010-03-11, amount=0.420\n",
            "[2022-08-05 16:14:46.229451] WARNING: zipline.data.adjustments: Couldn't compute ratio for dividend sid=2754, ex_date=2010-12-15, amount=0.180\n",
            "[2022-08-05 16:14:46.229500] WARNING: zipline.data.adjustments: Couldn't compute ratio for dividend sid=2766, ex_date=2017-11-09, amount=0.320\n",
            "[2022-08-05 16:14:46.229549] WARNING: zipline.data.adjustments: Couldn't compute ratio for dividend sid=2798, ex_date=2017-11-09, amount=0.065\n",
            "[2022-08-05 16:14:46.229597] WARNING: zipline.data.adjustments: Couldn't compute ratio for dividend sid=2817, ex_date=1992-03-03, amount=0.300\n",
            "[2022-08-05 16:14:46.229646] WARNING: zipline.data.adjustments: Couldn't compute ratio for dividend sid=2824, ex_date=2017-11-09, amount=0.120\n",
            "[2022-08-05 16:14:46.229694] WARNING: zipline.data.adjustments: Couldn't compute ratio for dividend sid=2843, ex_date=2017-11-09, amount=0.150\n",
            "[2022-08-05 16:14:46.229743] WARNING: zipline.data.adjustments: Couldn't compute ratio for dividend sid=2857, ex_date=2011-09-07, amount=0.410\n",
            "[2022-08-05 16:14:46.229793] WARNING: zipline.data.adjustments: Couldn't compute ratio for dividend sid=2968, ex_date=1990-03-26, amount=0.100\n",
            "[2022-08-05 16:14:46.229841] WARNING: zipline.data.adjustments: Couldn't compute ratio for dividend sid=3005, ex_date=1990-03-26, amount=0.070\n",
            "[2022-08-05 16:14:46.229889] WARNING: zipline.data.adjustments: Couldn't compute ratio for dividend sid=3078, ex_date=2014-05-12, amount=0.060\n",
            "[2022-08-05 16:14:46.229939] WARNING: zipline.data.adjustments: Couldn't compute ratio for dividend sid=3117, ex_date=2017-11-09, amount=0.430\n",
            "[2022-08-05 16:14:46.229995] WARNING: zipline.data.adjustments: Couldn't compute ratio for dividend sid=3138, ex_date=2010-08-16, amount=0.060\n",
            "[2022-08-05 16:14:46.230045] WARNING: zipline.data.adjustments: Couldn't compute ratio for dividend sid=3145, ex_date=2017-11-09, amount=0.050\n",
            "[2022-08-05 16:14:46.230386] WARNING: zipline.data.adjustments: Dividend ratio <= 0 for dividend sid=501, ex_date=2006-01-03, amount=41.560\n",
            "[2022-08-05 16:14:46.230483] WARNING: zipline.data.adjustments: Dividend ratio <= 0 for dividend sid=1557, ex_date=2007-07-02, amount=88.530\n",
            "[2022-08-05 16:14:46.230562] WARNING: zipline.data.adjustments: Dividend ratio <= 0 for dividend sid=1632, ex_date=2000-07-13, amount=181.000\n",
            "[2022-08-05 16:14:46.230617] WARNING: zipline.data.adjustments: Dividend ratio <= 0 for dividend sid=1657, ex_date=2013-09-30, amount=21.355\n",
            "[2022-08-05 16:14:46.230666] WARNING: zipline.data.adjustments: Dividend ratio <= 0 for dividend sid=1775, ex_date=1994-12-01, amount=76.000\n",
            "[2022-08-05 16:14:46.230716] WARNING: zipline.data.adjustments: Dividend ratio <= 0 for dividend sid=1776, ex_date=1996-11-04, amount=36.708\n",
            "[2022-08-05 16:14:46.230765] WARNING: zipline.data.adjustments: Dividend ratio <= 0 for dividend sid=2455, ex_date=2016-10-03, amount=25.611\n",
            "[2022-08-05 16:14:46.230816] WARNING: zipline.data.adjustments: Dividend ratio <= 0 for dividend sid=2687, ex_date=2008-06-26, amount=10.000\n",
            "[2022-08-05 16:14:46.230865] WARNING: zipline.data.adjustments: Dividend ratio <= 0 for dividend sid=2900, ex_date=2007-07-02, amount=88.530\n",
            "[2022-08-05 16:14:46.230914] WARNING: zipline.data.adjustments: Dividend ratio <= 0 for dividend sid=3088, ex_date=2015-04-27, amount=31.291\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Confirm existing bundles\n",
        "!zipline bundles"
      ],
      "metadata": {
        "id": "Ol2e01cH_O3z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# clean everything older than <date>\n",
        "!zipline clean -b crypto --after 2022-04-13"
      ],
      "metadata": {
        "id": "mzYjOy4meAx3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üìä**ANDREAS CLENOW MODELS**"
      ],
      "metadata": {
        "id": "r6pHOCkwUJOo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Clenow Momentum Model**\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "EHQUpvbK0RNj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "%matplotlib inline\n",
        "\n",
        "import zipline\n",
        "from zipline import run_algorithm\n",
        "from zipline.api import order_target_percent, symbol, set_commission, set_slippage, schedule_function, date_rules, time_rules\n",
        "from pandas import Timestamp\n",
        "from datetime import datetime\n",
        "import pytz\n",
        "import matplotlib.pyplot as plt \n",
        "import pyfolio as pf\n",
        "import pandas as pd \n",
        "import numpy as np \n",
        "from scipy import stats\n",
        "from zipline.finance.commission import PerDollar\n",
        "from zipline.finance.slippage import VolumeShareSlippage, FixedSlippage\n",
        "\n",
        "#Model Settings\n",
        "\n",
        "intial_portfolio = 100000\n",
        "momentum_window = 125\n",
        "minimum_momentum = 40\n",
        "portfolio_size = 30\n",
        "vola_window = 20\n",
        "\n",
        "#Commission and Slippage Settings\n",
        "\n",
        "enable_commission = True \n",
        "commission_pct = 0.001 \n",
        "enable_slippage = True \n",
        "slippage_volume_limit = 0.025\n",
        "slippage_impact = 0.05\n",
        "\n",
        "def momentum_score(ts):\n",
        "\n",
        "  #Input: Price time series.Output: Annualized exponential regression slope, multiplied by the R2\n",
        "\n",
        "  # Make a list of consecutive numbers \n",
        "  x = np.arange(len(ts))\n",
        "  # Get logs\n",
        "  log_ts = np.log(ts)\n",
        "  # Calculate regression values\n",
        "  slope, intercept, r_value, p_value, std_err = stats.linregress(x, log_ts) \n",
        "  # Annualize percent\n",
        "  annualized_slope = (np.power(np.exp(slope), 252) - 1) * 100 \n",
        "  #Adjust for fitness\n",
        "  score = annualized_slope * (r_value ** 2) \n",
        "  return score\n",
        "\n",
        "def volatility(ts):\n",
        "  return ts.pct_change().rolling(vola_window).std().iloc[-1]\n",
        "\n",
        "def output_progress(context):\n",
        "\n",
        "  #Output some performance numbers during backtest run \n",
        "  #This code just prints out the past month's performance,\n",
        "  # so that we have something to look at while the backtest runs.\n",
        "\n",
        "  # Get today's date\n",
        "  today = zipline.api.get_datetime().date()\n",
        "\n",
        "  # Calculate percent difference since last month\n",
        "  perf_pct = (context.portfolio.portfolio_value / context.last_month) - 1\n",
        "\n",
        "  # Print performance, format as percent with two decimals. \n",
        "  print(\"{} - Last Month Result: {:.2%}\".format(today, perf_pct))\n",
        "\n",
        "  # Remember today's portfolio value for next month's calculation \n",
        "  context.last_month = context.portfolio.portfolio_value\n",
        "\n",
        "#Initialization and trading logic\n",
        "\n",
        "\n",
        "def initialize(context):\n",
        "\n",
        "  # Set commission and slippage.\n",
        "  if enable_commission:\n",
        "    comm_model = PerDollar(cost=commission_pct) \n",
        "  else:\n",
        "    comm_model = PerDollar(cost=0.0) \n",
        "  set_commission(comm_model)\n",
        "  if enable_slippage: slippage_model=VolumeShareSlippage(volume_limit=slippage_volume_limit,\n",
        "price_impact=slippage_impact) \n",
        "  else:\n",
        "    slippage_model=FixedSlippage(spread=0.0) \n",
        "  set_slippage(slippage_model)\n",
        "\n",
        "  # Used only for progress output. \n",
        "  context.last_month = intial_portfolio\n",
        "\n",
        "  # Store index membership\n",
        "  context.index_members = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/My Project Folder/index members/sp500.csv', engine='python', error_bad_lines=False)\n",
        "\n",
        "\n",
        "  #Schedule rebalance monthly. \n",
        "  schedule_function(\n",
        "    func=rebalance, \n",
        "    date_rule=date_rules.month_start(), \n",
        "    time_rule=time_rules.market_open()\n",
        "  )\n",
        "\n",
        "def rebalance(context, data):\n",
        "  # Write some progress output during the backtest \n",
        "  output_progress(context)\n",
        "\n",
        "  # First, get today's date\n",
        "  today = zipline.api.get_datetime().date()\n",
        "\n",
        "  # Second, get the index makeup for all days prior to today.\n",
        "  all_prior = context.index_members.loc[context.index_members.index < today]\n",
        "\n",
        "  todays_universe = [ \n",
        "    symbol(ticker) for ticker in\n",
        "    context.index_members.loc[context.index_members.index < today].iloc[-1,0].split(',')\n",
        "  ]\n",
        "\n",
        "  # Get historical data\n",
        "  hist = data.history(todays_universe, \"close\", momentum_window, \"1d\")\n",
        "\n",
        "  # Make momentum ranking table\n",
        "  ranking_table = hist.apply(momentum_score).sort_values(ascending=False)\n",
        "\n",
        "  #Sell Logic\n",
        "  #First we check if any existing position should be sold.\n",
        "    #Sell if stock is no longer part of index.\n",
        "    #Sell if stock has too low momentum value.\n",
        "\n",
        "  kept_positions = list(context.portfolio.positions.keys()) \n",
        "  for security in context.portfolio.positions:\n",
        "    if (security not in todays_universe): \n",
        "      order_target_percent(security, 0.0) \n",
        "      kept_positions.remove(security)\n",
        "    elif ranking_table[security] < minimum_momentum: \n",
        "      order_target_percent(security, 0.0) \n",
        "      kept_positions.remove(security)\n",
        "\n",
        "  #Stock Selection Logic\n",
        "  #Check how many stocks we are keeping from last month.\n",
        "  #Fill from top of ranking list, until we reach the desired total number of portfolio holdings.\n",
        "\n",
        "  replacement_stocks = portfolio_size - len(kept_positions) \n",
        "  buy_list = ranking_table.loc[\n",
        "    ~ranking_table.index.isin(kept_positions)][:replacement_stocks]\n",
        "  new_portfolio = pd.concat(\n",
        "    (buy_list,\n",
        "    ranking_table.loc[ranking_table.index.isin(kept_positions)])\n",
        "  )\n",
        "  buy_list = ranking_table.loc[\n",
        "    ~ranking_table.index.isin(kept_positions)][:replacement_stocks]\n",
        "\n",
        "  #Calculate inverse volatility for stocks, and make target position weights.\n",
        "\n",
        "  vola_table = hist[new_portfolio.index].apply(volatility) \n",
        "  inv_vola_table = 1 / vola_table\n",
        "  sum_inv_vola = np.sum(inv_vola_table) \n",
        "  vola_target_weights = inv_vola_table / sum_inv_vola\n",
        "  for security, rank in new_portfolio.iteritems(): \n",
        "    weight = vola_target_weights[security]\n",
        "    if security in kept_positions:\n",
        "      order_target_percent(security, weight)\n",
        "    else:\n",
        "      if ranking_table[security] > minimum_momentum: \n",
        "        order_target_percent(security, weight)\n",
        "\n",
        "def analyze(context, perf):\n",
        "  perf['max'] = perf.portfolio_value.cummax() \n",
        "  perf['dd'] = (perf.portfolio_value / perf['max']) - 1 \n",
        "  maxdd = perf['dd'].min()\n",
        "\n",
        "  ann_ret = (np.power((perf.portfolio_value.iloc[-1] / perf.portfolio_value.iloc[0]),(252 / len(perf)))) - 1\n",
        "\n",
        "  print(\"Annualized Return: {:.2%} Max Drawdown: {:.2%}\".format(ann_ret, maxdd))\n",
        "\n",
        "  return\n",
        "'''\n",
        "start = datetime(1997, 1, 1, 8, 15, 12, 0, pytz.UTC)\n",
        "end = datetime(2008, 12, 31, 8, 15, 12, 0, pytz.UTC)\n",
        "'''\n",
        "\n",
        "start = pd.Timestamp('1997-1-1', tz='utc').date()\n",
        "end = pd.Timestamp('2018-12-1', tz='utc').date()\n",
        "df.loc[startdate:enddate]\n",
        "\n",
        "perf = zipline.run_algorithm(start=start, end=end, \n",
        "                             initialize=initialize, \n",
        "                             analyze=analyze, \n",
        "                             capital_base=intial_portfolio, \n",
        "                             data_frequency = 'daily', \n",
        "                             bundle='quandl' )"
      ],
      "metadata": {
        "id": "6aRGAkzKLH88",
        "collapsed": true,
        "cellView": "code",
        "outputId": "69e4f1b8-c235-45f3-d3b4-dafeca4c2753",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 450
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/zipline/algorithm.py:427: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version.\n",
            "\n",
            "\n",
            "  self._initialize(self, *args, **kwargs)\n",
            "Skipping line 1552: unexpected end of data\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1997-01-02 - Last Month Result: 0.00%\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-fd9a4528dc05>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    186\u001b[0m                              \u001b[0mcapital_base\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mintial_portfolio\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m                              \u001b[0mdata_frequency\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'daily'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m                              bundle='quandl' )\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/zipline/utils/run_algo.py\u001b[0m in \u001b[0;36mrun_algorithm\u001b[0;34m(start, end, initialize, capital_base, handle_data, before_trading_start, analyze, data_frequency, bundle, bundle_timestamp, trading_calendar, metrics_set, benchmark_returns, default_extension, extensions, strict_extensions, environ, custom_loader, blotter)\u001b[0m\n\u001b[1;32m    417\u001b[0m         \u001b[0mblotter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mblotter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m         \u001b[0mcustom_loader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 419\u001b[0;31m         \u001b[0mbenchmark_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbenchmark_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    420\u001b[0m     )\n\u001b[1;32m    421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/zipline/utils/run_algo.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(handle_data, initialize, before_trading_start, analyze, algofile, algotext, defines, data_frequency, capital_base, bundle, bundle_timestamp, start, end, output, trading_calendar, print_algo, metrics_set, local_namespace, environ, blotter, custom_loader, benchmark_spec)\u001b[0m\n\u001b[1;32m    223\u001b[0m             else {\n\u001b[1;32m    224\u001b[0m                 \u001b[0;34m\"algo_filename\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malgofile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"name\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"<algorithm>\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 225\u001b[0;31m                 \u001b[0;34m\"script\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0malgotext\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    226\u001b[0m             },\n\u001b[1;32m    227\u001b[0m         ).run()\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/zipline/algorithm.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, data_portal)\u001b[0m\n\u001b[1;32m    621\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m             \u001b[0mperfs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 623\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mperf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    624\u001b[0m                 \u001b[0mperfs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mperf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    625\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/zipline/gens/tradesimulation.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    226\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mdt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0maction\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mBAR\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 228\u001b[0;31m                     \u001b[0;32mfor\u001b[0m \u001b[0mcapital_change_packet\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mevery_bar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    229\u001b[0m                         \u001b[0;32myield\u001b[0m \u001b[0mcapital_change_packet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0maction\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mSESSION_START\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/zipline/gens/tradesimulation.py\u001b[0m in \u001b[0;36mevery_bar\u001b[0;34m(dt_to_use, current_data, handle_data)\u001b[0m\n\u001b[1;32m    141\u001b[0m                 \u001b[0mmetrics_tracker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_commission\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommission\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m             \u001b[0mhandle_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malgo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurrent_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdt_to_use\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m             \u001b[0;31m# grab any new orders from the blotter, then clear the list.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/zipline/utils/events.py\u001b[0m in \u001b[0;36mhandle_data\u001b[0;34m(self, context, data, dt)\u001b[0m\n\u001b[1;32m    207\u001b[0m                     \u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m                     \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m                     \u001b[0mdt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m                 )\n\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/zipline/utils/events.py\u001b[0m in \u001b[0;36mhandle_data\u001b[0;34m(self, context, data, dt)\u001b[0m\n\u001b[1;32m    227\u001b[0m         \"\"\"\n\u001b[1;32m    228\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_trigger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-2-fd9a4528dc05>\u001b[0m in \u001b[0;36mrebalance\u001b[0;34m(context, data)\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m   \u001b[0;31m# Second, get the index makeup for all days prior to today.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m   \u001b[0mall_prior\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_members\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_members\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mtoday\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m   todays_universe = [ \n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/ops/common.py\u001b[0m in \u001b[0;36mnew_method\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0mother\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mitem_from_zerodim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnew_method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/arraylike.py\u001b[0m in \u001b[0;36m__lt__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0munpack_zerodim_and_defer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"__lt__\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__lt__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cmp_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0munpack_zerodim_and_defer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"__le__\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexes/range.py\u001b[0m in \u001b[0;36m_cmp_method\u001b[0;34m(self, other, op)\u001b[0m\n\u001b[1;32m    877\u001b[0m             \u001b[0;31m# Both are immutable so if ._range attr. are equal, shortcut is possible\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    878\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cmp_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 879\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cmp_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    880\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    881\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_arith_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m_cmp_method\u001b[0;34m(self, other, op)\u001b[0m\n\u001b[1;32m   6059\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6060\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrstate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6061\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomparison_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6062\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6063\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/ops/array_ops.py\u001b[0m in \u001b[0;36mcomparison_op\u001b[0;34m(left, right, op)\u001b[0m\n\u001b[1;32m    285\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 287\u001b[0;31m         \u001b[0mres_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_na_arithmetic_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_cmp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    288\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mres_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/ops/array_ops.py\u001b[0m in \u001b[0;36m_na_arithmetic_op\u001b[0;34m(left, right, op, is_cmp)\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mleft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_object_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mleft\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mis_object_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mright\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_cmp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/computation/expressions.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(op, a, b, use_numexpr)\u001b[0m\n\u001b[1;32m    237\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0muse_numexpr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m             \u001b[0;31m# error: \"None\" not callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 239\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0m_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    240\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_evaluate_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/computation/expressions.py\u001b[0m in \u001b[0;36m_evaluate_numexpr\u001b[0;34m(op, op_str, a, b)\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_evaluate_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/computation/expressions.py\u001b[0m in \u001b[0;36m_evaluate_standard\u001b[0;34m(op, op_str, a, b)\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_TEST_MODE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0m_store_test_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: '<' not supported between instances of 'int' and 'datetime.date'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Clenow Trend Model**"
      ],
      "metadata": {
        "id": "x83jcz1QUFDe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "%matplotlib inline\n",
        "\n",
        "import zipline\n",
        "from zipline.api import future_symbol,  \\\n",
        "    set_commission, set_slippage, schedule_function, date_rules, \\\n",
        "    time_rules, continuous_future, order_target\n",
        "from pandas import Timestamp\n",
        "import pytz\n",
        "import datetime as datetime\n",
        "import matplotlib.pyplot as plt\n",
        "import pyfolio as pf\n",
        "import pandas as pd\n",
        "import numpy as np  \n",
        "from zipline.finance.commission import PerTrade, PerContract\n",
        "from zipline.finance.slippage import VolumeShareSlippage, \\\n",
        "    FixedSlippage, VolatilityVolumeShare\n",
        "\n",
        "# These lines are for the dynamic text reporting\n",
        "from IPython.display import display\n",
        "import ipywidgets as widgets\n",
        "out = widgets.HTML()\n",
        "display(out)\n",
        "\n",
        "\"\"\"\n",
        "Model Settings\n",
        "\"\"\"\n",
        "starting_portfolio = 50000000\n",
        "risk_factor = 0.0015\n",
        "stop_distance = 3\n",
        "breakout_window = 50\n",
        "vola_window = 40\n",
        "slow_ma = 80\n",
        "fast_ma = 40\n",
        "enable_commission = True\n",
        "enable_slippage = True  \n",
        "\n",
        "\n",
        "def report_result(context, data):\n",
        "    context.months += 1\n",
        "    today = zipline.api.get_datetime().date()\n",
        "    # Calculate annualized return so far\n",
        "    ann_ret = np.power(context.portfolio.portfolio_value / starting_portfolio, \n",
        "                   12 / context.months) - 1\n",
        "    \n",
        "    # Update the text\n",
        "    out.value = \"\"\"{} We have traded <b>{}</b> months \n",
        "    and the annualized return is <b>{:.2%}</b>\"\"\".format(today, context.months, ann_ret)\n",
        "\n",
        "def roll_futures(context, data):\n",
        "    open_orders = zipline.api.get_open_orders()\n",
        "    \n",
        "    for held_contract in context.portfolio.positions:\n",
        "        # don't roll positions that are set to change by core logic\n",
        "        if held_contract in open_orders: \n",
        "            continue\n",
        "        \n",
        "        # Save some time by only checking rolls for\n",
        "        # contracts stopping trading in the next days\n",
        "        days_to_auto_close = (\n",
        "            held_contract.auto_close_date.date() - data.current_session.date()\n",
        "        ).days\n",
        "        if days_to_auto_close > 5:\n",
        "            continue        \n",
        "        \n",
        "        # Make a continuation\n",
        "        continuation = continuous_future(\n",
        "                held_contract.root_symbol, \n",
        "                offset=0, \n",
        "                roll='volume', \n",
        "                adjustment='mul'\n",
        "                )\n",
        "        \n",
        "        # Get the current contract of the continuation\n",
        "        continuation_contract = data.current(continuation, 'contract')\n",
        "        \n",
        "        if continuation_contract != held_contract:\n",
        "            # Check how many contracts we hold\n",
        "            pos_size = context.portfolio.positions[held_contract].amount         \n",
        "            # Close current position\n",
        "            order_target(held_contract, 0)\n",
        "            # Open new position\n",
        "            order_target(continuation_contract, pos_size)     \n",
        "            \n",
        "def position_size(portfolio_value, std, point_value):\n",
        "    target_variation = portfolio_value * risk_factor\n",
        "    contract_variation = std * point_value\n",
        "    contracts = target_variation / contract_variation\n",
        "    return int(np.nan_to_num(contracts)) \n",
        "    \n",
        "def initialize(context):\n",
        "    \n",
        "    \"\"\"\n",
        "    Cost Settings\n",
        "    \"\"\"\n",
        "    if enable_commission:\n",
        "        comm_model = PerContract(cost=0.85, exchange_fee=1.5)\n",
        "    else:\n",
        "        comm_model = PerTrade(cost=0.0)\n",
        "        \n",
        "    set_commission(us_futures=comm_model)\n",
        "    \n",
        "    if enable_slippage:\n",
        "        slippage_model=VolatilityVolumeShare(volume_limit=0.2)\n",
        "    else:\n",
        "        slippage_model=FixedSlippage(spread=0.0)      \n",
        "        \n",
        "    set_slippage(us_futures=slippage_model)\n",
        "    \n",
        "    \"\"\"\n",
        "    Markets to trade\n",
        "    \"\"\" \n",
        "    currencies = [\n",
        "        'AD',\n",
        "        'BP',\n",
        "        'CD',\n",
        "        'CU',\n",
        "        'DX',\n",
        "        'JY',\n",
        "        'NE',\n",
        "        'SF',\n",
        "    ]\n",
        "    \n",
        "    agricultural = [\n",
        "        '_C',\n",
        "        'CT',\n",
        "        'FC',\n",
        "        'KC',\n",
        "        'LR',\n",
        "        'LS',\n",
        "        '_O',\n",
        "        '_S',\n",
        "        'SB',\n",
        "        'SM',\n",
        "        '_W',\n",
        "    ]\n",
        "    nonagricultural = [\n",
        "        'CL',\n",
        "        'GC',\n",
        "        'HG',\n",
        "        'HO',\n",
        "        'LG',\n",
        "        'NG',\n",
        "        'PA',\n",
        "        'PL',\n",
        "        'RB',\n",
        "        'SI',\n",
        "    ]\n",
        "    equities = [\n",
        "        'ES',\n",
        "        'NK',\n",
        "        'NQ',\n",
        "        'TW',\n",
        "        'VX',\n",
        "        'YM',\n",
        "    ]\n",
        "    rates = [\n",
        "        'ED',\n",
        "        'FV',\n",
        "        'TU',\n",
        "        'TY',\n",
        "        'US',\n",
        "    ]\n",
        "\n",
        "    # Make a list of all the markets\n",
        "    markets = currencies + agricultural + nonagricultural + equities + rates\n",
        "    \n",
        "    # Make a list of all continuations\n",
        "    context.universe = [\n",
        "        continuous_future(market, offset=0, roll='volume', adjustment='mul')\n",
        "            for market in markets\n",
        "    ]\n",
        "    \n",
        "    # We'll use these to keep track of best position reading\n",
        "    # Used to calculate stop points.\n",
        "    context.highest_in_position = {market: 0 for market in markets} \n",
        "    context.lowest_in_position = {market: 0 for market in markets}    \n",
        "    \n",
        "    # Schedule the daily trading\n",
        "    schedule_function(daily_trade, date_rules.every_day(), time_rules.market_close())\n",
        "    \n",
        "    # We'll just use this for the progress output\n",
        "    # during the backtest. Doesn't impact anything.\n",
        "    context.months = 0    \n",
        "    \n",
        "    # Schedule monthly report output\n",
        "    schedule_function(\n",
        "        func=report_result,\n",
        "        date_rule=date_rules.month_start(),\n",
        "        time_rule=time_rules.market_open()\n",
        "    ) \n",
        "    \n",
        "def analyze(context, perf):\n",
        "    returns, positions, transactions = pf.utils.extract_rets_pos_txn_from_zipline(perf)\n",
        "    pf.create_returns_tear_sheet(returns, benchmark_rets=None)\n",
        "    \n",
        "def daily_trade(context, data):\n",
        "    # Get continuation data\n",
        "    hist = data.history(\n",
        "        context.universe, \n",
        "        fields=['close','volume'], \n",
        "        frequency='1d', \n",
        "        bar_count=250,\n",
        "    )\n",
        "    \n",
        "    # Calculate trend\n",
        "    hist['trend'] = hist['close'].ewm(span=fast_ma).mean() > hist['close'].ewm(span=slow_ma).mean()    \n",
        "    \n",
        "    # Make dictionary of open positions\n",
        "    open_pos = {\n",
        "        pos.root_symbol: pos \n",
        "        for pos in context.portfolio.positions\n",
        "    } \n",
        "    \n",
        "    # Iterate markets, check for trades\n",
        "    for continuation in context.universe:\n",
        "        \n",
        "        # Get root symbol of continuation\n",
        "        root = continuation.root_symbol\n",
        "        \n",
        "        # Slice off history for just this market\n",
        "        h = hist.xs(continuation, 2)\n",
        "        \n",
        "        # Get standard deviation\n",
        "        std = h.close.diff()[-vola_window:].std()\n",
        "\n",
        "        if root in open_pos: # Position is open\n",
        "\n",
        "            # Get position\n",
        "            p = context.portfolio.positions[open_pos[root]]\n",
        "            \n",
        "            if p.amount > 0: # Position is long\n",
        "                if context.highest_in_position[root] == 0: # First day holding the position\n",
        "                    context.highest_in_position[root] = p.cost_basis\n",
        "                else:\n",
        "                    context.highest_in_position[root] = max(\n",
        "                        h['close'].iloc[-1], context.highest_in_position[root]\n",
        "                    ) \n",
        "                    \n",
        "                # Calculate stop point\n",
        "                stop = context.highest_in_position[root] - (std  * stop_distance)\n",
        "                # Check if stop is hit\n",
        "                if h.iloc[-1]['close'] < stop:\n",
        "                    contract = open_pos[root]\n",
        "                    order_target(contract, 0)\n",
        "                    context.highest_in_position[root] = 0\n",
        "                # Check if trend has flipped\n",
        "                elif h['trend'].iloc[-1] == False:\n",
        "                    contract = open_pos[root]\n",
        "                    order_target(contract, 0)\n",
        "                    context.highest_in_position[root] = 0\n",
        "                    \n",
        "            else: # Position is short\n",
        "                if context.lowest_in_position[root] == 0: # First day holding the position\n",
        "                    context.lowest_in_position[root] = p.cost_basis\n",
        "                else:\n",
        "                    context.lowest_in_position[root] = min(\n",
        "                        h['close'].iloc[-1], context.lowest_in_position[root]\n",
        "                    )\n",
        "                \n",
        "                # Calculate stop point\n",
        "                stop = context.lowest_in_position[root] + (std  * stop_distance)\n",
        "                \n",
        "                # Check if stop is hit\n",
        "                if h.iloc[-1]['close'] > stop:\n",
        "                    contract = open_pos[root]\n",
        "                    order_target(contract, 0)\n",
        "                    context.lowest_in_position[root] = 0\n",
        "                # Check if trend has flipped\n",
        "                elif h['trend'].iloc[-1] == True:\n",
        "                    contract = open_pos[root]\n",
        "                    order_target(contract, 0)\n",
        "                    context.lowest_in_position[root] = 0                         \n",
        "        \n",
        "        else: # No position on\n",
        "            if h['trend'].iloc[-1]: # Bull trend\n",
        "                # Check if we just made a new high\n",
        "                if h['close'][-1] == h[-breakout_window:]['close'].max(): \n",
        "                    contract = data.current(continuation, 'contract')\n",
        "\n",
        "                    contracts_to_trade = position_size( \\\n",
        "                                                       context.portfolio.portfolio_value, \\\n",
        "                                                       std, \\\n",
        "                                                       contract.price_multiplier)\n",
        "                    \n",
        "                    # Limit size to 20% of avg. daily volume\n",
        "                    contracts_cap = int(h['volume'][-20:].mean() * 0.2)\n",
        "                    contracts_to_trade = min(contracts_to_trade, contracts_cap)\n",
        "                    \n",
        "                    # Place the order\n",
        "                    order_target(contract, contracts_to_trade)\n",
        "             \n",
        "            else: # Bear trend\n",
        "                # Check if we just made a new low\n",
        "                if h['close'][-1] == h[-breakout_window:]['close'].min(): \n",
        "                    contract = data.current(continuation, 'contract')\n",
        "\n",
        "                    contracts_to_trade = position_size( \\\n",
        "                                                       context.portfolio.portfolio_value, \\\n",
        "                                                       std, \\\n",
        "                                                       contract.price_multiplier)\n",
        "                    \n",
        "                    # Limit size to 20% of avg. daily volume\n",
        "                    contracts_cap = int(h['volume'][-20:].mean() * 0.2)\n",
        "                    contracts_to_trade = min(contracts_to_trade, contracts_cap)\n",
        "                    \n",
        "                    # Place the order\n",
        "                    order_target(contract, -1 * contracts_to_trade)\n",
        "    \n",
        "    # If we have open positions, check for rolls\n",
        "    if len(open_pos) > 0:   \n",
        "        roll_futures(context, data)                \n",
        "                        \n",
        "\n",
        "start = pd.Timestamp('2015-01-05', tz='utc')\n",
        "end = pd.Timestamp('2017-12-31', tz='utc')\n",
        "\n",
        "perf = zipline.run_algorithm(\n",
        "    start=start, end=end, \n",
        "    initialize=initialize, \n",
        "    analyze=analyze,\n",
        "    capital_base=starting_portfolio,  \n",
        "    data_frequency = 'daily', \n",
        "    bundle='random_futures_data' ) \n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "sponWV8ZKDJv",
        "outputId": "05540f7f-ecca-4f88-cf9c-4ff944a85740",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "77fec636d3954e9bad017b71779b1225",
            "69ee373d8e504d0d92bc966293cd7ea2",
            "cbc7915c31274e1aa7e43760699c8de2"
          ]
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "HTML(value='')"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "77fec636d3954e9bad017b71779b1225"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "LookupError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-23d21eb7a31c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    313\u001b[0m     \u001b[0mcapital_base\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstarting_portfolio\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m     \u001b[0mdata_frequency\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'daily'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 315\u001b[0;31m     bundle='random_futures_data' ) \n\u001b[0m\u001b[1;32m    316\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/zipline/utils/run_algo.py\u001b[0m in \u001b[0;36mrun_algorithm\u001b[0;34m(start, end, initialize, capital_base, handle_data, before_trading_start, analyze, data_frequency, bundle, bundle_timestamp, trading_calendar, metrics_set, benchmark_returns, default_extension, extensions, strict_extensions, environ, custom_loader, blotter)\u001b[0m\n\u001b[1;32m    417\u001b[0m         \u001b[0mblotter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mblotter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m         \u001b[0mcustom_loader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 419\u001b[0;31m         \u001b[0mbenchmark_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbenchmark_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    420\u001b[0m     )\n\u001b[1;32m    421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/zipline/utils/run_algo.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(handle_data, initialize, before_trading_start, analyze, algofile, algotext, defines, data_frequency, capital_base, bundle, bundle_timestamp, start, end, output, trading_calendar, print_algo, metrics_set, local_namespace, environ, blotter, custom_loader, benchmark_spec)\u001b[0m\n\u001b[1;32m    223\u001b[0m             else {\n\u001b[1;32m    224\u001b[0m                 \u001b[0;34m\"algo_filename\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malgofile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"name\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"<algorithm>\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 225\u001b[0;31m                 \u001b[0;34m\"script\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0malgotext\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    226\u001b[0m             },\n\u001b[1;32m    227\u001b[0m         ).run()\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/zipline/algorithm.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, data_portal)\u001b[0m\n\u001b[1;32m    621\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m             \u001b[0mperfs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 623\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mperf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    624\u001b[0m                 \u001b[0mperfs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mperf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    625\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/zipline/gens/tradesimulation.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    226\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mdt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0maction\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mBAR\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 228\u001b[0;31m                     \u001b[0;32mfor\u001b[0m \u001b[0mcapital_change_packet\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mevery_bar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    229\u001b[0m                         \u001b[0;32myield\u001b[0m \u001b[0mcapital_change_packet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0maction\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mSESSION_START\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/zipline/gens/tradesimulation.py\u001b[0m in \u001b[0;36mevery_bar\u001b[0;34m(dt_to_use, current_data, handle_data)\u001b[0m\n\u001b[1;32m    141\u001b[0m                 \u001b[0mmetrics_tracker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_commission\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommission\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m             \u001b[0mhandle_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malgo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurrent_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdt_to_use\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m             \u001b[0;31m# grab any new orders from the blotter, then clear the list.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/zipline/utils/events.py\u001b[0m in \u001b[0;36mhandle_data\u001b[0;34m(self, context, data, dt)\u001b[0m\n\u001b[1;32m    207\u001b[0m                     \u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m                     \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m                     \u001b[0mdt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m                 )\n\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/zipline/utils/events.py\u001b[0m in \u001b[0;36mhandle_data\u001b[0;34m(self, context, data, dt)\u001b[0m\n\u001b[1;32m    227\u001b[0m         \"\"\"\n\u001b[1;32m    228\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_trigger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-8-23d21eb7a31c>\u001b[0m in \u001b[0;36mdaily_trade\u001b[0;34m(context, data)\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0mfields\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'close'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'volume'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m         \u001b[0mfrequency\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'1d'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m         \u001b[0mbar_count\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m250\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    201\u001b[0m     )\n\u001b[1;32m    202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32msrc/zipline/_protocol.pyx\u001b[0m in \u001b[0;36mzipline._protocol.check_parameters.__call__.assert_keywords_and_call\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32msrc/zipline/_protocol.pyx\u001b[0m in \u001b[0;36mzipline._protocol.BarData.history\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/zipline/data/data_portal.py\u001b[0m in \u001b[0;36mget_history_window\u001b[0;34m(self, assets, end_dt, bar_count, frequency, field, data_frequency, ffill)\u001b[0m\n\u001b[1;32m    907\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    908\u001b[0m                 df = self._get_history_daily_window(\n\u001b[0;32m--> 909\u001b[0;31m                     \u001b[0massets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_dt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbar_count\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfield\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_frequency\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    910\u001b[0m                 )\n\u001b[1;32m    911\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mfrequency\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"1m\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/zipline/data/data_portal.py\u001b[0m in \u001b[0;36m_get_history_daily_window\u001b[0;34m(self, assets, end_dt, bar_count, field_to_use, data_frequency)\u001b[0m\n\u001b[1;32m    777\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m         data = self._get_history_daily_window_data(\n\u001b[0;32m--> 779\u001b[0;31m             \u001b[0massets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdays_for_window\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_dt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfield_to_use\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_frequency\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m         )\n\u001b[1;32m    781\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdays_for_window\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0massets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/zipline/data/data_portal.py\u001b[0m in \u001b[0;36m_get_history_daily_window_data\u001b[0;34m(self, assets, days_for_window, end_dt, field_to_use, data_frequency)\u001b[0m\n\u001b[1;32m    790\u001b[0m             \u001b[0;31m# last trading day, use daily data for the whole range.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m             return self._get_daily_window_data(\n\u001b[0;32m--> 792\u001b[0;31m                 \u001b[0massets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfield_to_use\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdays_for_window\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextra_slot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    793\u001b[0m             )\n\u001b[1;32m    794\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/zipline/data/data_portal.py\u001b[0m in \u001b[0;36m_get_daily_window_data\u001b[0;34m(self, assets, field, days_in_window, extra_slot)\u001b[0m\n\u001b[1;32m   1048\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbar_count\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1049\u001b[0m             data = self._history_loader.history(\n\u001b[0;32m-> 1050\u001b[0;31m                 \u001b[0massets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdays_in_window\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfield\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextra_slot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1051\u001b[0m             )\n\u001b[1;32m   1052\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_slot\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/zipline/data/history_loader.py\u001b[0m in \u001b[0;36mhistory\u001b[0;34m(self, assets, dts, field, is_perspective_after)\u001b[0m\n\u001b[1;32m    537\u001b[0m         \"\"\"\n\u001b[1;32m    538\u001b[0m         block = self._ensure_sliding_windows(\n\u001b[0;32m--> 539\u001b[0;31m             \u001b[0massets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfield\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_perspective_after\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    540\u001b[0m         )\n\u001b[1;32m    541\u001b[0m         \u001b[0mend_ix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_calendar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearchsorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/zipline/data/history_loader.py\u001b[0m in \u001b[0;36m_ensure_sliding_windows\u001b[0;34m(self, assets, dts, field, is_perspective_after)\u001b[0m\n\u001b[1;32m    408\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mneeded_assets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m             \u001b[0moffset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 410\u001b[0;31m             \u001b[0mstart_ix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_in_sorted_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    411\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    412\u001b[0m             \u001b[0mprefetch_end_ix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_ix\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prefetch_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcal\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/zipline/utils/pandas_utils.py\u001b[0m in \u001b[0;36mfind_in_sorted_index\u001b[0;34m(dts, dt)\u001b[0m\n\u001b[1;32m    142\u001b[0m     \u001b[0mix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearchsorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mix\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdts\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mdts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mix\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mdt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"{dt} is not in {dts}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mLookupError\u001b[0m: 2014-01-08 00:00:00+00:00 is not in DatetimeIndex(['2015-01-02 00:00:00+00:00', '2015-01-05 00:00:00+00:00',\n               '2015-01-06 00:00:00+00:00', '2015-01-07 00:00:00+00:00',\n               '2015-01-08 00:00:00+00:00', '2015-01-09 00:00:00+00:00',\n               '2015-01-12 00:00:00+00:00', '2015-01-13 00:00:00+00:00',\n               '2015-01-14 00:00:00+00:00', '2015-01-15 00:00:00+00:00',\n               ...\n               '2023-07-24 00:00:00+00:00', '2023-07-25 00:00:00+00:00',\n               '2023-07-26 00:00:00+00:00', '2023-07-27 00:00:00+00:00',\n               '2023-07-28 00:00:00+00:00', '2023-07-31 00:00:00+00:00',\n               '2023-08-01 00:00:00+00:00', '2023-08-02 00:00:00+00:00',\n               '2023-08-03 00:00:00+00:00', '2023-08-04 00:00:00+00:00'],\n              dtype='datetime64[ns, UTC]', length=2164, freq='C')"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "universe"
      ],
      "metadata": {
        "id": "KE6J4pHSux2g",
        "outputId": "964d147b-d4a7-409a-a546-82293b737321",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-9e38d7d080d0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0muniverse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'universe' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### üíª**MODEL TESTING**"
      ],
      "metadata": {
        "id": "8gWXJGjGBDbs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**DIGITAL ASSETS PROGRAMME**\n",
        "\n"
      ],
      "metadata": {
        "id": "tIM7wTXOAarM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Systems**\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "TycKaYmxuCVl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Single Asset Backtest"
      ],
      "metadata": {
        "id": "ySxEKidEU606"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This ensures that our graphs will be shown properly in the notebook.\n",
        "%matplotlib inline\n",
        "\n",
        "# Import libraries\n",
        "import zipline\n",
        "from zipline import run_algorithm\n",
        "from zipline.api import order_target_percent, symbol\n",
        "from datetime import datetime\n",
        "import pytz\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "def initialize(context):\n",
        "  # Which asset to trade\n",
        "  context.asset = symbol('btc')\n",
        "  \n",
        "  # Moving average window\n",
        "  context.index_average_window = 100\n",
        "\n",
        "def handle_data(context, data):\n",
        "  # Request history for the stock\n",
        "  btc_hist = data.history(context.asset, \"close\",\n",
        "                               context.index_average_window, \"1d\")\n",
        "  \n",
        "  # Check if price is above moving average\n",
        "  if btc_hist[-1] > btc_hist.mean():\n",
        "    asset_weight = 1.0\n",
        "  else:\n",
        "    asset_weight = 0.0\n",
        "    # Place order\n",
        "    order_target_percent(context.asset, asset_weight)\n",
        "\n",
        "def analyze(context, perf):\n",
        "  \n",
        "  fig = plt.figure(figsize=(12, 8))\n",
        "  \n",
        "    # First char\n",
        "  ax = fig.add_subplot(311)\n",
        "  ax.set_title('Strategy Results')\n",
        "  ax.semilogy(perf['portfolio_value'], linestyle='-',\n",
        "              label='Equity Curve', linewidth=3.0)\n",
        "  ax.legend()\n",
        "  ax.grid(False)\n",
        "\n",
        "  # Second chart\n",
        "  ax = fig.add_subplot(312)\n",
        "  ax.plot(perf['gross_leverage'],\n",
        "  label='Exposure', linestyle='-', linewidth=1.0)\n",
        "  ax.legend()\n",
        "  ax.grid(True)\n",
        "\n",
        "  # Third chart\n",
        "  ax = fig.add_subplot(313)\n",
        "  ax.plot(perf['returns'], label='Returns', linestyle='-.',\n",
        "          linewidth=1.0)"
      ],
      "metadata": {
        "id": "kcHu_Gsb7cll"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Equal Weight Model"
      ],
      "metadata": {
        "id": "_tfGWw1gYDlo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This ensures that our graphs will be shown properly in the notebook.\n",
        "%matplotlib inline\n",
        "\n",
        "# Import a few libraries we need\n",
        "from zipline import run_algorithm\n",
        "from zipline.api import order_target_percent, record, symbol, set_benchmark\n",
        "import pyfolio as pf\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "def initialize(context):\n",
        "\n",
        "  # Which stock to trade\n",
        "\n",
        "  \"\"\"\n",
        "  dji = [\"JEC\",\"BBY\",\"MSFT\",\"MCHP\",\"PEP\",\n",
        "         \"RAD\",\"PTC\",\"GCO\",\"FAST\",\"CTL\",\n",
        "         \"APA\",\"EL\",\"TMK\",\"VVI\",\"HPQ\",\n",
        "         \"CMCSA\",\"JCI\",\"T\"]\n",
        "\n",
        "  dji = [\"aave\",\"ada\",\"algo\",\"alpha\",\"ant\",\n",
        "         \"bal\",\"bat\",\"bch\",\"bnb\",\"bsv\",\n",
        "         \"btc\"]\n",
        "  \"\"\"\n",
        "\n",
        "  dji = [\"btc\"]\n",
        "\n",
        "\n",
        "  # Make a list of symbols from the list of tickers\n",
        "  context.dji_symbols = [symbol(s) for s in dji]\n",
        "\n",
        "  # Moving average window\n",
        "  context.index_average_window = 52\n",
        "  \n",
        "def handle_data(context, data):\n",
        "  \n",
        "  # Get history for all the stocks\n",
        "  stock_hist = data.history(context.dji_symbols, \"close\", context.index_average_window, \"1d\")\n",
        "\n",
        "  # Make an empty DataFrame to start with\n",
        "  stock_analytics = pd.DataFrame()\n",
        "\n",
        "  # Add column for above or below average\n",
        "  stock_analytics['above_mean'] = stock_hist.iloc[-1] > stock_hist.mean()\n",
        "\n",
        "  # Set weight for stocks to buy\n",
        "  stock_analytics.loc[stock_analytics['above_mean'] == True, 'weight'] = 1/len(context.dji_symbols)\n",
        "\n",
        "  # Set weight to zero for the rest\n",
        "  stock_analytics.loc[stock_analytics['above_mean'] == False, 'weight'] = 0.0\n",
        "\n",
        "  # Iterate each row and place trades\n",
        "  for stock, analytics in stock_analytics.iterrows():\n",
        "\n",
        "    # Check if the stock can be traded\n",
        "    if data.can_trade(stock):\n",
        "\n",
        "      # Place the trade\n",
        "      order_target_percent(stock, analytics['weight'])\n",
        "\n",
        "def analyze(context, perf):\n",
        "\n",
        "  # Use PyFolio to generate a performance report\n",
        "  returns, positions, transactions = pf.utils.extract_rets_pos_txn_from_zipline(perf)\n",
        "\n",
        "  benchmark_period_return = perf['benchmark_period_return']\n",
        "\n",
        "  daily_benchmark_returns = np.exp(np.log(benchmark_period_return + 1.0).diff()) - 1\n",
        "\n",
        "  # Create tear sheet\n",
        "  pf.create_full_tear_sheet(returns, positions=positions, transactions=transactions, benchmark_rets=None)\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "def analyze(context, perf):\n",
        "\n",
        "  fig = plt.figure(figsize=(12, 8))\n",
        "\n",
        "  # First chart\n",
        "  ax = fig.add_subplot(311)\n",
        "  ax.set_title('Strategy Results')\n",
        "  ax.plot(perf['portfolio_value'], linestyle='-',\n",
        "          label='Equity Curve', linewidth=3.0)\n",
        "  ax.legend()\n",
        "  ax.grid(False)\n",
        "\n",
        "  # Second chart\n",
        "  ax = fig.add_subplot(312)\n",
        "  ax.plot(perf['gross_leverage'],label='Exposure',\n",
        "          linestyle='-', linewidth=1.0)\n",
        "  ax.legend()\n",
        "  ax.grid(True)\n",
        "  \n",
        "  # Third chart\n",
        "  ax = fig.add_subplot(313)\n",
        "  ax.plot(perf['returns'], label='Returns', linestyle='-.',\n",
        "          linewidth=1.0)\n",
        "  ax.legend()\n",
        "  ax.grid(True)\n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "# Set start and end date\n",
        "start_date = pd.Timestamp('2016-05-02', tz='utc')\n",
        "end_date = pd.Timestamp('2020-05-02', tz='utc')\n",
        "\n",
        "# Fire off the backtest\n",
        "perf = run_algorithm(\n",
        "start=start_date,\n",
        "end=end_date,\n",
        "initialize=initialize,\n",
        "analyze=analyze,\n",
        "handle_data=handle_data,\n",
        "capital_base=10000,\n",
        "data_frequency = 'daily', \n",
        "bundle= 'crypto',)"
      ],
      "metadata": {
        "id": "JEtmR8GjFANc",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Export performance results to disk in csv file\n",
        "\n",
        "perf.portfolio_value.to_csv('ewm_momentum_model.csv')"
      ],
      "metadata": {
        "id": "BU2OOl30YXe1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Momentum Model"
      ],
      "metadata": {
        "id": "1V0GCt2_92BD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "import zipline\n",
        "from zipline import run_algorithm\n",
        "from zipline.api import order_target_percent, symbol, set_commission, set_slippage, schedule_function, date_rules, time_rules\n",
        "import matplotlib.pyplot as plt \n",
        "import pyfolio as pf\n",
        "import pandas as pd \n",
        "import numpy as np\n",
        "from scipy import stats\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "from zipline.finance.commission import PerDollar\n",
        "from zipline.finance.slippage import VolumeShareSlippage, FixedSlippage\n",
        "\n",
        "\n",
        "initial_portfolio = 10000\n",
        "minimum_momentum = 10\n",
        "portfolio_size = 1\n",
        "vola_window = 30\n",
        "\n",
        "def momentum_score(ts):\n",
        "\n",
        "  #Input: Price time series.Output: Annualized exponential regression slope, multiplied by the R2\n",
        "\n",
        "  # Make a list of consecutive numbers \n",
        "  x = np.arange(len(ts))\n",
        "  # Get logs\n",
        "  log_ts = np.log(ts)\n",
        "  # Calculate regression values\n",
        "  slope, intercept, r_value, p_value, std_err = stats.linregress(x, log_ts) \n",
        "  # Annualize percent\n",
        "  annualized_slope = (np.power(np.exp(slope), 252) - 1) * 100 \n",
        "  #Adjust for fitness\n",
        "  score = annualized_slope * (r_value ** 2) \n",
        "  return score\n",
        "\n",
        "def volatility(ts):\n",
        "  return ts.pct_change().rolling(vola_window).std().iloc[-1]\n",
        "\n",
        "\n",
        "#Initialization and trading logic\n",
        "\n",
        "\n",
        "def initialize(context):\n",
        "\n",
        "  context.rolling_window = 100\n",
        "\n",
        "  #Commission and Slippage Settings\n",
        "\n",
        "  enable_commission = True \n",
        "  commission_pct = 0.001 \n",
        "  enable_slippage = True \n",
        "  slippage_volume_limit = 0.025\n",
        "  slippage_impact = 0.05\n",
        "\n",
        "  \"\"\"\n",
        "  dji = [\"AAVE\",\"ADA\",\"ALPHA\",\"BCH\",\"BTC\",\n",
        "          \"DOGE\",\"DOT\",\"ETH\",\"LTC\",\"USDT\",\n",
        "          \"XLM\",\"XMR\",\"XRP\"]\n",
        "  \"\"\"\n",
        "  dji = [\"btc\",\"ltc\",\"eth\"]\n",
        "\n",
        "  \n",
        "  # Make a list of symbols from the list of tickers\n",
        "  context.dji_symbols = [symbol(s) for s in dji]\n",
        "\n",
        "  # Set commission and slippage.\n",
        "  if enable_commission:\n",
        "    comm_model = PerDollar(cost=commission_pct) \n",
        "  else:\n",
        "    comm_model = PerDollar(cost=0.0) \n",
        "  set_commission(comm_model)\n",
        "  if enable_slippage: slippage_model=VolumeShareSlippage(volume_limit=slippage_volume_limit,\n",
        "price_impact=slippage_impact) \n",
        "  else:\n",
        "    slippage_model=FixedSlippage(spread=0.0) \n",
        "  set_slippage(slippage_model)\n",
        "\n",
        "\n",
        "  #Schedule rebalance monthly. \n",
        "  schedule_function(\n",
        "    func=rebalance, \n",
        "    date_rule=date_rules.month_start(), \n",
        "    time_rule=time_rules.market_open()\n",
        "  )\n",
        "\n",
        "def rebalance(context, data):\n",
        "\n",
        "  # Get historical data\n",
        "  hist = data.history(context.dji_symbols, \"close\", context.rolling_window, \"1d\")\n",
        "\n",
        "  # Make momentum ranking table\n",
        "  ranking_table = hist.apply(momentum_score).sort_values(ascending=False)\n",
        "\n",
        "  #Sell Logic\n",
        "  #First we check if any existing position should be sold.\n",
        "    #Sell if stock is no longer part of index.\n",
        "    #Sell if stock has too low momentum value.\n",
        "\n",
        "  kept_positions = list(context.portfolio.positions.keys()) \n",
        "  for security in context.portfolio.positions:\n",
        "    if ranking_table[security] < minimum_momentum: \n",
        "      order_target_percent(security, 0.0)\n",
        "      kept_positions.remove(security)\n",
        " \n",
        "  #Stock Selection Logic\n",
        "  #Check how many stocks we are keeping from last month.\n",
        "  #Fill from top of ranking list, until we reach the desired total number of portfolio holdings.\n",
        "\n",
        "  replacement_stocks = portfolio_size - len(kept_positions) \n",
        "  buy_list = ranking_table.loc[\n",
        "    ~ranking_table.index.isin(kept_positions)][:replacement_stocks]\n",
        "  new_portfolio = pd.concat(\n",
        "    (buy_list,\n",
        "    ranking_table.loc[ranking_table.index.isin(kept_positions)])\n",
        "  )\n",
        "  buy_list = ranking_table.loc[\n",
        "    ~ranking_table.index.isin(kept_positions)][:replacement_stocks]\n",
        "\n",
        "  #Calculate inverse volatility for stocks, and make target position weights.\n",
        "\n",
        "  vola_table = hist[new_portfolio.index].apply(volatility) \n",
        "  inv_vola_table = 1 / vola_table\n",
        "  sum_inv_vola = np.sum(inv_vola_table) \n",
        "  vola_target_weights = inv_vola_table / sum_inv_vola\n",
        "  for security, rank in new_portfolio.iteritems(): \n",
        "    weight = vola_target_weights[security]\n",
        "    if security in kept_positions:\n",
        "      order_target_percent(security, weight)\n",
        "    else:\n",
        "      if ranking_table[security] > minimum_momentum: \n",
        "        order_target_percent(security, weight)\n",
        "\n",
        "\n",
        "def analyze(context, perf):\n",
        "    \n",
        "  # Use PyFolio to generate a performance report\n",
        "  returns, positions, transactions = pf.utils.extract_rets_pos_txn_from_zipline(perf)\n",
        "\n",
        "  benchmark_period_return = perf['benchmark_period_return']\n",
        "\n",
        "  daily_benchmark_returns = np.exp(np.log(benchmark_period_return + 1.0).diff()) - 1\n",
        "\n",
        "  # Create tear sheet\n",
        "  pf.create_full_tear_sheet(returns, positions=positions, transactions=transactions, benchmark_rets=None)\n",
        "\n",
        "start= pd.Timestamp('2015-5-1', tz='utc')\n",
        "end = pd.Timestamp('2022-5-2', tz='utc')\n",
        "\n",
        "perf = zipline.run_algorithm(start=start, \n",
        "                             end=end, \n",
        "                             initialize=initialize, \n",
        "                             analyze=analyze, \n",
        "                             capital_base=initial_portfolio, \n",
        "                             data_frequency='daily',\n",
        "                             bundle='crypto')"
      ],
      "metadata": {
        "id": "OfmZYBZ4p4nv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Export Performance Result to disk in csv file\n",
        "\n",
        "perf.portfolio_value.to_csv('crypto_momentum.csv')"
      ],
      "metadata": {
        "id": "M18L5KZe3rQr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Model Performance**"
      ],
      "metadata": {
        "id": "kPK0-JU_Y1Ke"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "%matplotlib inline\n",
        "\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import empyrical as em\n",
        "from IPython.core.display import display, HTML\n",
        "import pandas as pd\n",
        "import numpy\n",
        "from datetime import datetime\n",
        "\"\"\"\n",
        "import mpld3\n",
        "mpld3.enable_notebook()\n",
        "\"\"\"\n",
        "\n",
        "base_path = '/content/drive/MyDrive/Colab Notebooks/My Project Folder/Backtests/'\n",
        "\n",
        "bm = 'SPCBDM_test3'\n",
        "bm_name = 'S&P Cryptocurrency Broad Digital Market Index'\n",
        "\n",
        "\n",
        "strat_names = {\n",
        "    \"core_trend\" : \"Core Trend Strategy\",    \n",
        "    \"time_return\" : \"Time Return Strategy\",\n",
        "    \"counter_trend\" : \"Counter Trend Strategy\",\n",
        "    \"curve_trading\" : \"Curve Trading Strategy\",\n",
        "    \"equity_momentum\" : \"Equity Momentum Strategy\",\n",
        "    \"crypto_equal_weight_model_2\" : \"crypto_Equal Weight Strategy\",\n",
        "    \"crypto_momentum_2\" : \"Crypto Momentum Strategy\"\n",
        "    \n",
        "}\n",
        "\n",
        "strat = 'crypto_momentum_2'\n",
        "strat_name = strat_names[strat]\n",
        "\n",
        "df = pd.read_csv(base_path + strat + '.csv', index_col=0, parse_dates=True, names=[strat] )\n",
        "df[bm_name] = pd.read_csv(base_path + bm + '.csv', index_col=0, parse_dates=[0] )\n",
        "\n",
        "df = df.loc[:'2022/05/02'].dropna()\n",
        "\n",
        "print(\"Fetched: {}\".format(strat_name))\n",
        "\n",
        "yr_periods = 252\n",
        "\n",
        "# Format for book display\n",
        "font = {'family' : 'eurostile',\n",
        "        'weight' : 'normal',\n",
        "        'size'   : 12}\n",
        "matplotlib.rc('font', **font)\n",
        "\"\"\"\n",
        "# Format for book display\n",
        "font = {'family' : 'DejaVu Sans',\n",
        "        'weight' : 'normal',\n",
        "        'size'   : 8}\n",
        "matplotlib.rc('font', **font)\n",
        "\"\"\"\n",
        "def equity_graph(df):\n",
        "    df = df / df.iloc[0]\n",
        "    df['Correlation'] = df[strat].pct_change().rolling(window=int(yr_periods / 1)).corr(df[bm_name].pct_change())\n",
        "    \n",
        "    df['Drawdown'] = (df[strat] / df[strat].cummax()) - 1\n",
        "    \n",
        "    df.fillna(0, inplace=True) # make sure no NA values are in there\n",
        "\n",
        "    fig = plt.figure(figsize=(18, 20))\n",
        "\n",
        "    # First chart\n",
        "    ax = fig.add_subplot(311)\n",
        "    ax.set_title('Strategy Comparisons')\n",
        "    ax.semilogy(df[strat], '-',label=strat_name, color='navy', linewidth=2.0)\n",
        "    ax.semilogy(df[bm_name], '-',label=bm_name, color='grey', linewidth=1)\n",
        "    spacing = 500\n",
        "    visible = ax.xaxis.get_ticklabels()[::spacing]\n",
        "    for label in ax.xaxis.get_ticklabels():\n",
        "        if label not in visible:\n",
        "            label.set_visible(True)\n",
        "    ax.set_ylabel('Returns')\n",
        "    ax.set_xlabel('Duration')\n",
        "    plt.xticks(rotation=None)\n",
        "    ax.legend()\n",
        "    \n",
        "    # Second chart\n",
        "    ax = fig.add_subplot(312)\n",
        "    ax.fill_between(df.index, df['Drawdown'], label='Drawdown', color='navy', linewidth=1.0)\n",
        "    spacing = 500\n",
        "    visible = ax.xaxis.get_ticklabels()[::spacing]\n",
        "    for label in ax.xaxis.get_ticklabels():\n",
        "        if label not in visible:\n",
        "            label.set_visible(True)\n",
        "    plt.xticks(rotation=None)\n",
        "    ax.legend()\n",
        "\n",
        "    # Third chart\n",
        "    ax = fig.add_subplot(313)\n",
        "    ax.fill_between(df.index,df['Correlation'], label='12M Rolling Correlation', color='navy')\n",
        "    spacing = 500\n",
        "    visible = ax.xaxis.get_ticklabels()[::spacing]\n",
        "    for label in ax.xaxis.get_ticklabels():\n",
        "        if label not in visible:\n",
        "            label.set_visible(True)\n",
        "    plt.xticks(rotation=None)\n",
        "    ax.legend()\n",
        "    \n",
        "equity_graph(df)\n",
        "\n",
        "monthly_data = em.aggregate_returns(df[strat].pct_change(),'monthly')\n",
        "yearly_data = em.aggregate_returns(df[strat].pct_change(),'yearly')\n",
        "\n",
        "table = \"\"\"\n",
        "<table class='table table-hover table-condensed table-striped'>\n",
        "<thead>\n",
        "<tr>\n",
        "<th style=\"text-align:right\">Year</th>\n",
        "<th style=\"text-align:right\">Jan</th>\n",
        "<th style=\"text-align:right\">Feb</th>\n",
        "<th style=\"text-align:right\">Mar</th>\n",
        "<th style=\"text-align:right\">Apr</th>\n",
        "<th style=\"text-align:right\">May</th>\n",
        "<th style=\"text-align:right\">Jun</th>\n",
        "<th style=\"text-align:right\">Jul</th>\n",
        "<th style=\"text-align:right\">Aug</th>\n",
        "<th style=\"text-align:right\">Sep</th>\n",
        "<th style=\"text-align:right\">Oct</th>\n",
        "<th style=\"text-align:right\">Nov</th>\n",
        "<th style=\"text-align:right\">Dec</th>\n",
        "<th style=\"text-align:right\">Year</th>\n",
        "</tr>\n",
        "</thead>\n",
        "<tbody>\n",
        "<tr>\"\"\"\n",
        "\n",
        "first_year = True\n",
        "first_month = True\n",
        "yr = 0\n",
        "mnth = 0\n",
        "for m, val in monthly_data.iteritems():\n",
        "    yr = m[0]\n",
        "    mnth = m[1]\n",
        "\n",
        "    if(first_month):\n",
        "        table += \"<td align='right'><b>{}</b></td>\\n\".format(yr)\n",
        "        first_month = False\n",
        "\n",
        "    if(first_year): # pad empty months for first year if sim doesn't start in January\n",
        "        first_year = False\n",
        "        if(mnth > 1):\n",
        "            for i in range(1, mnth):\n",
        "                table += \"<td align='right'>-</td>\\n\"\n",
        "\n",
        "    table += \"<td align='right'>{:+.1f}</td>\\n\".format(val * 100)\n",
        "\n",
        "    if(mnth==12): # check for dec, add yearly\n",
        "        table += \"<td align='right'><b>{:+.1f}</b></td>\\n\".format(yearly_data[yr] * 100)     \n",
        "        table += '</tr>\\n <tr> \\n'    \n",
        "        first_month = True\n",
        "\n",
        "# add padding for empty months and last year's value\n",
        "if(mnth != 12):\n",
        "    for i in range(mnth+1, 13):\n",
        "        table += \"<td align='right'>-</td>\\n\"\n",
        "        if(i==12):\n",
        "            table += \"<td align='right'><b>{:+.1f}</b></td>\\n\".format(\n",
        "                yearly_data[yr] * 100\n",
        "            ) \n",
        "            table += '</tr>\\n <tr> \\n'\n",
        "table += '</tr>\\n </tbody> \\n </table>'\n",
        "\n",
        "display(HTML(table))\n",
        "\n",
        "\n",
        "def holding_period_map(df):\n",
        "    yr = em.aggregate_returns(df[strat].pct_change(), 'yearly')\n",
        "    df = pd.DataFrame(columns=range(1,len(yr)+1), index=yr.index)\n",
        "\n",
        "    yr_start = 0\n",
        "    \n",
        "    table = \"<table class='table table-hover table-condensed table-striped'>\"\n",
        "    table += \"<tr><th>Years</th>\"\n",
        "    \n",
        "    for i in range(len(yr)):\n",
        "        table += \"<th>{}</th>\".format(i+1)\n",
        "    table += \"</tr>\"\n",
        "\n",
        "    for the_year, value in yr.iteritems(): # Iterates years\n",
        "        table += \"<tr><th>{}</th>\".format(the_year) # New table row\n",
        "        \n",
        "        for yrs_held in (range(1, len(yr)+1)): # Iterates yrs held \n",
        "            if yrs_held   <= len(yr[yr_start:yr_start + yrs_held]):\n",
        "                ret = em.annual_return(yr[yr_start:yr_start + yrs_held], 'yearly' )\n",
        "                table += \"<td>{:+.0f}</td>\".format(ret * 100)\n",
        "        table += \"</tr>\"    \n",
        "        yr_start+=1\n",
        "    return table\n",
        "\n",
        "table = holding_period_map(df)\n",
        "display(HTML(table))\n",
        "\n"
      ],
      "metadata": {
        "id": "gyaPFiaykaNm",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **DATA CLEANING**\n",
        "\n"
      ],
      "metadata": {
        "id": "wOl0psqAtAal"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Futures"
      ],
      "metadata": {
        "id": "leJ4xVj0cUmi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import modules\n",
        "import nasdaqdatalink\n",
        "import quandl\n",
        "# Get the data for Futures, Continuous Contract #6.\n",
        "import matplotlib.pyplot as plt\n",
        "data = quandl.get(\"CHRIS/CME_YM1\",start_date=\"2017-12-03\", end_date=\"2018-12-03\", api_key='WDDHaLh3eG6vrEgiCCqy')"
      ],
      "metadata": {
        "id": "RC5tgJ5vmc7a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the prices\n",
        "data.Settle.plot()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "84lZG881mitG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#import required libraries\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "import numpy as np\n",
        "\n",
        "data = data.rename(columns={'Open': 'open','High':'high',\n",
        "                                'Low':'low','Last':'close',\n",
        "                                'Volume':'volume','Previous Day Open Interest': 'openinterest'}, index=None)\n",
        "\n",
        "data['expiration_date'] = '2018-12-21'\n",
        "data['root_symbol'] = 'YM'\n",
        "data['symbol'] = 'YMZ18'\n",
        "\n",
        "new_data = data.drop(['Change', 'Settle',], axis=1)\n",
        "\n",
        "print(new_data.head())\n",
        "\n"
      ],
      "metadata": {
        "id": "6aDFt_ctctAx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_data.to_csv('/content/drive/MyDrive/Colab Notebooks/My Project Folder/TESTS FILES/YMZ18.csv')"
      ],
      "metadata": {
        "id": "U-luxklmprlL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Digital assets"
      ],
      "metadata": {
        "id": "j9Isr0HFaAKD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Adjusting model performace csv data for comparison"
      ],
      "metadata": {
        "id": "xkG3Yi2EHM4P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "A = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/My Project Folder/Backtests/Raw Model Performance Data/Digital Assets/crypto_momentum.csv', parse_dates=True, index_col=0)\n",
        "\n",
        "A.index = A.index.strftime('%Y/%m/%d')\n",
        "\n",
        "header_row = 1\n",
        "\n",
        "A.columns = A.iloc[header_row]\n",
        "\n",
        "A"
      ],
      "metadata": {
        "id": "HkR-LQr5HUfA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "A.info()"
      ],
      "metadata": {
        "id": "dwSpgXWbjPHq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "A.to_csv('/content/drive/MyDrive/Colab Notebooks/My Project Folder/Backtests/crypto_momentum_2.csv')\n"
      ],
      "metadata": {
        "id": "zpol9KKPOz0m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Adjusting crypto indices csv data for comparison"
      ],
      "metadata": {
        "id": "xcAQevGKs8jc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#import required libraries\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "import exchange_calendars as xcals\n",
        "from zipline import get_calendar\n",
        "import numpy as np\n",
        "\n",
        "df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/My Project Folder/crypto/indices/SPCBDM.csv', encoding='cp1252')\n",
        "df.info()\n",
        "print(df)"
      ],
      "metadata": {
        "id": "Ui2xKWSwvQsK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "df.drop([1355],axis=0, inplace = True )\n",
        "\n",
        "#Convert 'date' Column to datetime\n",
        "df['2/28/2017'] = pd.to_datetime(df['2/28/2017'], utc=True)\n",
        "\n",
        "#Set 'date' column as index\n",
        "df.set_index('2/28/2017', inplace=True)\n",
        "\n",
        "# Get all expected trading sessions in new dataframe.\n",
        "sessions = get_calendar('NYSE').sessions_in_range('2017-02-28', '2022-05-05')\n",
        "\n",
        "df.index = df.index.strftime('%Y/%m/%d')\n",
        "\n",
        "header_row = 1\n",
        "\n",
        "df.columns = df.iloc[header_row]\n",
        "\n",
        "df.tail(5)\n",
        "df.info()\n",
        "df"
      ],
      "metadata": {
        "id": "ccCas1-YyplH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df[~df.index.duplicated()]\n",
        "df"
      ],
      "metadata": {
        "id": "6_L-MWp3pbMV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv('/content/drive/MyDrive/Colab Notebooks/My Project Folder/Backtests/SPCBDM_test3.csv')"
      ],
      "metadata": {
        "id": "YxGN_p0ckuRC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Removing weekends from timeseries"
      ],
      "metadata": {
        "id": "wyel-4htJj0U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "#Import statements\n",
        "%matplotlib inline\n",
        "import pandas as pd\n",
        "import datetime as dt\n",
        "import numpy as np\n",
        "\n",
        "#Load csv file from disc\n",
        "df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/My Project Folder/crypto/crypto_data/DOGE.csv')\n",
        "\n",
        "#Set date column to datetime\n",
        "df['time'] = pd.to_datetime(df['time'], errors='coerce')\n",
        "\n",
        "#Remove weekends from data\n",
        "df = df[df.time.dt.weekday < 5]\n",
        "\n",
        "#Set 'date' columns as Index\n",
        "df.set_index(\"time\", inplace = True)\n",
        "\n",
        "#display weekday dataframe\n",
        "df\n"
      ],
      "metadata": {
        "id": "LcR4uk8SJ3mT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#inspect dataframe\n",
        "df.info()"
      ],
      "metadata": {
        "id": "b2HfyHCXUYBR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Save dataframe to csv\n",
        "\n",
        "df.to_csv('/content/drive/MyDrive/Colab Notebooks/My Project Folder/crypto/crypto weekday data/DODGE_weekday.csv')"
      ],
      "metadata": {
        "id": "t91Kk-vQRL8Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Load final data to file to dataframe\n",
        "dodge = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/My Project Folder/crypto/crypto weekday data/DODGE_weekday.csv')\n",
        "\n",
        "print(dodge)\n",
        "\n"
      ],
      "metadata": {
        "id": "biKqcgmYUzrI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Remove weekends from dataframe\n",
        "btc = usholidays[usholidays.date.dt.weekday < 5]\n",
        "\n",
        "#Set 'date' column as index\n",
        "btc.set_index('date', inplace = True)\n",
        "\n",
        "btc"
      ],
      "metadata": {
        "id": "z2i2hsa_DPOz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#import US holiday calender\n",
        "from pandas.tseries.holiday import USFederalHolidayCalendar as calendar\n",
        "\n",
        "#Set period between start and end date in dataframe to identify and remove holidays\n",
        "holidays = calendar().holidays(start='2009-01-05', end='2022-05-24') \n",
        "m = raw_data['date'].isin(holidays)\n",
        "usholidays = raw_data[~m].copy()\n",
        "\n",
        "#print new dataframe with holidays removed\n",
        "usholidays"
      ],
      "metadata": {
        "id": "CBI8-xSAAoRb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Adjusting crypto data from **Yahoo Finance** for testing with NYSE trading calender."
      ],
      "metadata": {
        "id": "apiTpYe_fJXQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#import required libraries\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "import exchange_calendars as xcals\n",
        "from zipline import get_calendar\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "62ohBdKTfmjU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/My Project Folder/crypto/yahoo_data/yahoo raw data/BTC-USD.csv', parse_dates=True, index_col=0)\n",
        "\n",
        "# Remove Adj Close Column\n",
        "new_df = df.drop(['Adj Close'], axis=1)\n",
        "\n",
        "new_df[\"Volume\"] = new_df[\"Volume\"].astype(float)\n",
        "\n",
        "#Reset index\n",
        "new_df.reset_index(inplace = True)\n",
        "\n",
        "#Convert 'date' Column to datetime\n",
        "new_df['Date'] = pd.to_datetime(new_df['Date'], utc=True)\n",
        "\n",
        "#Set 'date' column as index\n",
        "new_df.set_index('Date', inplace=True)\n",
        "\n",
        "# Get all expected trading sessions in new dataframe.\n",
        "sessions = get_calendar('NYSE').sessions_in_range('2009-01-05', '2022-07-07')\n",
        "\n",
        "# To set the trading session in  new dataframe to the NYSE Calender\n",
        "btc = new_df.reindex(sessions)\n",
        "\n",
        "#Reset index again to change the index name\n",
        "btc.reset_index(inplace = True)\n",
        "\n",
        "#Rename index column to 'date'\n",
        "btc = btc.rename(columns={'index': 'trading_date'}, index=None)\n",
        "\n",
        "#Change date format to Year-Month-Day\n",
        "btc['trading_date'] =  pd.to_datetime(btc['trading_date']).dt.strftime('%Y-%m-%d')\n",
        "\n",
        "crypto = btc.dropna()\n",
        "\n",
        "#Change 'PriceUSD' columns to 'close'\n",
        "crypto.rename(columns = {'Open':'open',\n",
        "                      'High':'high',\n",
        "                      'Low':'low',\n",
        "                      'Close':'close',\n",
        "                      'Volume':'volume'}, inplace = True)\n",
        "\n",
        "crypto.set_index('trading_date', inplace=True)\n",
        "\n",
        "crypto.info()\n",
        "\n",
        "crypto.to_csv('/content/drive/MyDrive/Colab Notebooks/My Project Folder/crypto/yahoo_data/yahoo cleaned data/btc.csv')\n",
        "\n",
        "crypto"
      ],
      "metadata": {
        "id": "9Zw_h3y8fQBV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Adjusting crypto data from **Coinmetrics** for testing with NYSE trading calender."
      ],
      "metadata": {
        "id": "ZoZBFEZFb1JM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#import required libraries\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "import exchange_calendars as xcals\n",
        "from zipline import get_calendar\n",
        "import numpy as np\n",
        "\n",
        "#load raw data from file\n",
        "raw_data = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/My Project Folder/crypto/coinmetrics_data/btc.csv', parse_dates=True, index_col=0)\n",
        "\n",
        "new = raw_data.drop(raw_data.loc[:, :'PriceBTC'].columns, axis=1)\n",
        "\n",
        "\n",
        "#drop columns not needed. Only closing prices required\n",
        "new.drop(new.iloc[:, 1:76], inplace = True, axis = 1)\n",
        "\n",
        "#Add new columns\n",
        "new['high'] =0\n",
        "new['low'] =0\n",
        "new['open'] =0\n",
        "new['volume'] =0\n",
        "\n",
        "# Rearrange columns to set timestamp as first column\n",
        "new = new[['high','open','low','PriceUSD','volume']]\n",
        "\n",
        "#Change 'PriceUSD' columns to 'close'\n",
        "new.rename(columns = {'PriceUSD':'close'}, inplace = True)\n",
        "\n",
        "\"\"\"\n",
        "#Drop row (date) not needed\n",
        "new=new.drop(['2022-05-25'])\n",
        "\"\"\"\n",
        "\n",
        "#Fill 'close' column with integer values '0'\n",
        "new[\"close\"].fillna(0, inplace=True)\n",
        "\n",
        "#Reset index\n",
        "new.reset_index(inplace = True)\n",
        "\n",
        "#Rename time columns to date\n",
        "new = new.rename(columns={'time': 'date'}, index=None)\n",
        "\n",
        "#Drop all NaN values from dataframe\n",
        "new.dropna()\n",
        "\n",
        "#Convert columns datatype from integer to float\n",
        "new[\"high\"] = new[\"high\"].astype(float)\n",
        "new[\"open\"] = new[\"open\"].astype(float)\n",
        "new[\"low\"] = new[\"low\"].astype(float)\n",
        "new[\"volume\"] = new[\"volume\"].astype(float)\n",
        "\n",
        "#Convert 'date' Column to datetime\n",
        "new['date'] = pd.to_datetime(new['date'], utc=True)\n",
        "\n",
        "#Set 'date' column as index\n",
        "new.set_index('date', inplace=True)\n",
        "\n",
        "# Get all expected trading sessions in new dataframe.\n",
        "sessions = get_calendar('NYSE').sessions_in_range('2009-01-05', '2022-05-24')\n",
        "\n",
        "# To set the trading session in  new dataframe to the NYSE Calender\n",
        "btc = new.reindex(sessions)\n",
        "\n",
        "#Reset index again to change the index name\n",
        "btc.reset_index(inplace = True)\n",
        "\n",
        "#Rename index column to 'date'\n",
        "btc = btc.rename(columns={'index': 'date'}, index=None)\n",
        "\n",
        "#Change date format to Year-Month-Day\n",
        "btc['date'] =  pd.to_datetime(btc['date']).dt.strftime('%Y-%m-%d')\n",
        "\n",
        "\"\"\"\n",
        "btc.set_index('date', inplace=True)\n",
        "\"\"\"\n",
        "\n",
        "# Remove two columns name is 'C' and 'D'\n",
        "df = btc.drop(['high', 'open','low'], axis=1)\n",
        "\n",
        "df['open'] = df['close'] - (0 * df ['close'])\n",
        "df['high'] = df['open'] - (0 * df ['open'])\n",
        "df['low'] = df['high'] - (0 * df ['high'])\n",
        "\n",
        "# Rearrange columns\n",
        "df = df[['date','open','high','low','close','volume']]\n",
        "\n",
        "df.set_index('date', inplace=True)\n",
        "\n",
        "crypto = df.dropna()\n",
        "\n",
        "crypto.to_csv('/content/drive/MyDrive/Colab Notebooks/My Project Folder/crypto/final crypto bundle/btc.csv')\n",
        "\n"
      ],
      "metadata": {
        "id": "UQOZCRgetfon"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "# Count total null values in dataframe\n",
        "print(\"Total Number of null values in the DataFrame : \" +\n",
        "\tstr(raw_data.isnull().sum().sum()))\n"
      ],
      "metadata": {
        "id": "DvPNoDDTBsT9",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "#@ show number of null for each column\n",
        "display(raw_data.isnull().sum())\n"
      ],
      "metadata": {
        "id": "_yiqje4xB4Be",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "#display null values\n",
        "raw_data[raw_data['close'].isnull()]"
      ],
      "metadata": {
        "id": "B2kpdW3bC2Ph",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "gDZuhdt9s2dd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exploratory Data Analyses (EDA)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "OlM6TGBPVSmL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mpld3"
      ],
      "metadata": {
        "id": "s14iuKoDf7rk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy import stats\n",
        "import seaborn as sn\n",
        "import matplotlib.pyplot as plt\n",
        "\"\"\"\n",
        "import mpld3\n",
        "mpld3.enable_notebook()\n",
        "\"\"\"\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "pd.set_option('display.max_rows', 2)"
      ],
      "metadata": {
        "id": "i5waJ-BLVR5U"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "index_members = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/My Project Folder/index members/sp500.csv', index_col=0, parse_dates=[0], engine='python', error_bad_lines=False)\n",
        "\n",
        "index_members"
      ],
      "metadata": {
        "id": "RX7671I6xNRk",
        "outputId": "5c2cf020-a271-472b-a0ca-46a37236a8a4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Skipping line 1552: unexpected end of data\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                      tickers\n",
              "date                                                         \n",
              "1996-01-02  TMC-200006,AAL-199702,AAMRQ-201312,AAPL,ABI-20...\n",
              "...                                                       ...\n",
              "2009-07-27  A,AABA,AAPL,ABC,ABT,ACS-201002,ADBE,ADI,ADM,AD...\n",
              "\n",
              "[1550 rows x 1 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-61450d80-df7d-4937-98e0-8750610d0eae\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tickers</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>date</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1996-01-02</th>\n",
              "      <td>TMC-200006,AAL-199702,AAMRQ-201312,AAPL,ABI-20...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2009-07-27</th>\n",
              "      <td>A,AABA,AAPL,ABC,ABT,ACS-201002,ADBE,ADI,ADM,AD...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1550 rows √ó 1 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-61450d80-df7d-4937-98e0-8750610d0eae')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-61450d80-df7d-4937-98e0-8750610d0eae button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-61450d80-df7d-4937-98e0-8750610d0eae');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "B = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/My Project Folder/random_futures/YMZ18.csv', parse_dates=True, index_col=0)\n",
        "\n",
        "B.info()\n",
        "\n",
        "print(B.head(5))"
      ],
      "metadata": {
        "id": "7TIUEc7qhsCf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_data.info()\n",
        "\n",
        "print(new_data.head(5))"
      ],
      "metadata": {
        "id": "oUbM6EXUVORX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.set_option('display.max_rows', None)\n",
        "\n",
        "B.describe()"
      ],
      "metadata": {
        "id": "-ACTvJDKWq-y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.set_option('display.max_rows', None)\n",
        "\n",
        "new_data.describe()"
      ],
      "metadata": {
        "id": "FmQpnRucXA1t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(B)\n",
        "print(new_data)"
      ],
      "metadata": {
        "id": "sCkdD2lanjzn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "B['Open'].plot(figsize=(12,6), \n",
        "                  linestyle='--',color='black',\n",
        "                  legend='Open')\n",
        "\n",
        "B['High'].plot(figsize=(12,6),\n",
        "                   linestyle='-',color='grey',\n",
        "                   legend='High')\n",
        "\"\"\"\n",
        "B['close'].plot(figsize=(12,6),\n",
        "                 linestyle=':',color='black',\n",
        "                 legend='Low')\n",
        "\n",
        "new_data['close'].plot(figsize=(12,6),\n",
        "                  linestyle='-',color='black',\n",
        "                  legend='Close')\n"
      ],
      "metadata": {
        "id": "aPN9i9h3Ydbd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "no_outlier_prices = B[(np.abs(stats.zscore(B)) <\n",
        "6).all(axis=1)]"
      ],
      "metadata": {
        "id": "yGFt1GskpsGJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "no_outlier_prices['100'].plot(figsize=(12,6), linestyle='--',\n",
        "color='black', legend='Close')"
      ],
      "metadata": {
        "id": "kSie4BpYqa8R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.set_option('display.max_rows', None)\n",
        "\n",
        "no_outlier_prices[['533.95']].describe()"
      ],
      "metadata": {
        "id": "_7kJ7-_Mw1pa"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}