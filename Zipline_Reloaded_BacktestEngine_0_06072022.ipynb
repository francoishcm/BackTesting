{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Zipline_Reloaded_BacktestEngine.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/francoishcm/BackTesting/blob/master/Zipline_Reloaded_BacktestEngine_0_06072022.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üß∞**INSTALL PACKAGES**"
      ],
      "metadata": {
        "id": "xRTs1_SK0Scj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive \n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "ABrWrt1q06gq",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1tlwk44QhErd"
      },
      "source": [
        "# Install ta-lib v0.4.0\n",
        "%%bash\n",
        "wget http://prdownloads.sourceforge.net/ta-lib/ta-lib-0.4.0-src.tar.gz\n",
        "tar -xzf ta-lib-0.4.0-src.tar.gz\n",
        "cd ta-lib/\n",
        "./configure\n",
        "make\n",
        "make install"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JSwN3Ywihz3r",
        "collapsed": true
      },
      "source": [
        "# Install zipline\n",
        "%pip install zipline-reloaded"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Install Pyfolio\n",
        "!pip install pyfolio"
      ],
      "metadata": {
        "id": "m-y07xfPTFVK",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Install matplot library\n",
        "!pip install matplotlib"
      ],
      "metadata": {
        "collapsed": true,
        "id": "zoV1_FSc_5MW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Install data bundle 'Quandl'\n",
        "!pip install quandl"
      ],
      "metadata": {
        "collapsed": true,
        "id": "8-pgTCGp2XzF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üíΩ**SET WORKING DIRECTORY**"
      ],
      "metadata": {
        "id": "4Ixua2eyz0Hr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os \n",
        "\n",
        "# Set your working directory to a folder in your Google Drive. This way, if your notebook times out,\n",
        "# your files will be saved in your Google Drive!\n",
        "\n",
        "# the base Google Drive directory\n",
        "root_dir = \"/content/drive/\"\n"
      ],
      "metadata": {
        "id": "eWtZZXQol34j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os \n",
        "\n",
        "# Set your working directory to a folder in your Google Drive. This way, if your notebook times out,\n",
        "# your files will be saved in your Google Drive!\n",
        "\n",
        "\n",
        "# choose where you want your project files to be saved\n",
        "project_folder = \"MyDrive/Colab Notebooks/My Project Folder\"\n"
      ],
      "metadata": {
        "id": "c4jxNssSmApK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_and_set_working_directory(project_folder):\n",
        "  # check if your project folder exists. if not, it will be created.\n",
        "  if os.path.isdir(root_dir + project_folder) == False:\n",
        "    os.mkdir(root_dir + project_folder)\n",
        "    print(root_dir + project_folder + ' did not exist but was created.')\n",
        "\n",
        "  # change the OS to use your project folder as the working directory\n",
        "  os.chdir(root_dir + project_folder)\n",
        "\n",
        "  # create a test file to make sure it shows up in the right place\n",
        "  !touch 'new_file_in_working_directory.txt'\n",
        "  print('\\nYour working directory was changed to ' + root_dir + project_folder + \\\n",
        "        \"\\n\\nAn empty text file was created there. You can also run !pwd to confirm the current working directory.\" )\n",
        "\n",
        "create_and_set_working_directory(project_folder)"
      ],
      "metadata": {
        "id": "Y0PGKB_SmAR5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Confirm current working directory\n",
        "!pwd"
      ],
      "metadata": {
        "id": "Q4_HSs4HneUa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "for f in os.listdir(\"//content/drive/MyDrive/Colab Notebooks/My Project Folder\"):\n",
        "\tprint(f)"
      ],
      "metadata": {
        "id": "8HB8gDZGqsfB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ‚è≥**REGISTER & INGEST DATA**"
      ],
      "metadata": {
        "id": "z5Y1KYNHeqeu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ingest custom bundle\n",
        "!zipline ingest --bundle 'random_stock_data'"
      ],
      "metadata": {
        "id": "CvMaJ1U1eVhB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd1a8bd3-ce99-4660-88a8-c6d8f7cbd696"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2022-07-06 20:47:33.653520] INFO: zipline.data.bundles.core: Ingesting random_stock_data.\n",
            "Loading JEC...\n",
            "Loading BBY...\n",
            "Loading MSFT...\n",
            "Loading MCHP...\n",
            "Loading PEP...\n",
            "Loading RAD...\n",
            "Loading PTC...\n",
            "Loading GCO...\n",
            "Loading FAST...\n",
            "Loading CTL...\n",
            "Loading APA...\n",
            "Loading EL...\n",
            "Loading TMK...\n",
            "Loading VVI...\n",
            "Loading HPQ...\n",
            "Loading CMCSA...\n",
            "Loading JCI...\n",
            "Loading T...\n",
            "Loading .ipynb_checkpo...\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/zipline\", line 8, in <module>\n",
            "    sys.exit(main())\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/click/core.py\", line 829, in __call__\n",
            "    return self.main(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/click/core.py\", line 782, in main\n",
            "    rv = self.invoke(ctx)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/click/core.py\", line 1259, in invoke\n",
            "    return _process_result(sub_ctx.command.invoke(sub_ctx))\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/click/core.py\", line 1066, in invoke\n",
            "    return ctx.invoke(self.callback, **ctx.params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/click/core.py\", line 610, in invoke\n",
            "    return callback(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/zipline/__main__.py\", line 394, in ingest\n",
            "    show_progress,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/zipline/data/bundles/core.py\", line 456, in ingest\n",
            "    pth.data_path([name, timestr], environ=environ),\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/zipline/data/bundles/random_stock_data.py\", line 63, in random_stock_data\n",
            "    process_stocks(symbols, sessions, metadata, divs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/zipline/data/bcolz_daily_bars.py\", line 209, in write\n",
            "    return self._write_internal(it, assets)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/zipline/data/bcolz_daily_bars.py\", line 269, in _write_internal\n",
            "    for asset_id, table in iterator:\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/zipline/data/bcolz_daily_bars.py\", line 202, in <genexpr>\n",
            "    ((sid, self.to_ctable(df, invalid_data_behavior)) for sid, df in data),\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/zipline/data/bundles/random_stock_data.py\", line 85, in process_stocks\n",
            "    df = pd.read_csv('{}/{}.csv'.format(path, symbol), index_col=[0], parse_dates=[0]) \n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pandas/util/_decorators.py\", line 311, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\", line 586, in read_csv\n",
            "    return _read(filepath_or_buffer, kwds)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\", line 482, in _read\n",
            "    parser = TextFileReader(filepath_or_buffer, **kwds)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\", line 811, in __init__\n",
            "    self._engine = self._make_engine(self.engine)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\", line 1040, in _make_engine\n",
            "    return mapping[engine](self.f, **self.options)  # type: ignore[call-arg]\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/c_parser_wrapper.py\", line 51, in __init__\n",
            "    self._open_handles(src, kwds)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/base_parser.py\", line 229, in _open_handles\n",
            "    errors=kwds.get(\"encoding_errors\", \"strict\"),\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pandas/io/common.py\", line 707, in get_handle\n",
            "    newline=\"\",\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/Colab Notebooks/My Project Folder/random_stocks/.ipynb_checkpo.csv'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Confirm existing bundles\n",
        "!zipline bundles"
      ],
      "metadata": {
        "id": "Ol2e01cH_O3z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "# clean everything older than <date>\n",
        "!zipline clean -b random_stock_data --after 2022-07-06"
      ],
      "metadata": {
        "id": "mzYjOy4meAx3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "03jbJlv-OZYg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "'''\n",
        "INGEST QUANDL STOCK BUNDLE\n",
        "'''\n",
        "\n",
        "#Suppress Warning messages\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Ingest bundle API\n",
        "!QUANDL_API_KEY=KUnssHvVERHb5XYu9C1- zipline ingest -b 'quandl'"
      ],
      "metadata": {
        "id": "KiUF_IBQCSlm",
        "collapsed": true,
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Confirm existing bundle that were ingested\n",
        "!zipline bundles"
      ],
      "metadata": {
        "id": "n-0pfBmOJVq5",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üìä**ANDREAS CLENOW MODELS**"
      ],
      "metadata": {
        "id": "r6pHOCkwUJOo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Clenow Momentum Model"
      ],
      "metadata": {
        "id": "EHQUpvbK0RNj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "%matplotlib inline\n",
        "\n",
        "import zipline\n",
        "from zipline import run_algorithm\n",
        "from zipline.api import order_target_percent, symbol, set_commission, set_slippage, schedule_function, date_rules, time_rules\n",
        "from pandas import Timestamp\n",
        "from datetime import datetime\n",
        "import pytz\n",
        "import matplotlib.pyplot as plt \n",
        "import pyfolio as pf\n",
        "import pandas as pd \n",
        "import numpy as np \n",
        "from scipy import stats\n",
        "from zipline.finance.commission import PerDollar\n",
        "from zipline.finance.slippage import VolumeShareSlippage, FixedSlippage\n",
        "\n",
        "#Model Settings\n",
        "\n",
        "intial_portfolio = 100000\n",
        "momentum_window = 125\n",
        "minimum_momentum = 40\n",
        "portfolio_size = 30\n",
        "vola_window = 20\n",
        "\n",
        "#Commission and Slippage Settings\n",
        "\n",
        "enable_commission = True \n",
        "commission_pct = 0.001 \n",
        "enable_slippage = True \n",
        "slippage_volume_limit = 0.025\n",
        "slippage_impact = 0.05\n",
        "\n",
        "def momentum_score(ts):\n",
        "\n",
        "  #Input: Price time series.Output: Annualized exponential regression slope, multiplied by the R2\n",
        "\n",
        "  # Make a list of consecutive numbers \n",
        "  x = np.arange(len(ts))\n",
        "  # Get logs\n",
        "  log_ts = np.log(ts)\n",
        "  # Calculate regression values\n",
        "  slope, intercept, r_value, p_value, std_err = stats.linregress(x, log_ts) \n",
        "  # Annualize percent\n",
        "  annualized_slope = (np.power(np.exp(slope), 252) - 1) * 100 \n",
        "  #Adjust for fitness\n",
        "  score = annualized_slope * (r_value ** 2) \n",
        "  return score\n",
        "\n",
        "def volatility(ts):\n",
        "  return ts.pct_change().rolling(vola_window).std().iloc[-1]\n",
        "\n",
        "def output_progress(context):\n",
        "\n",
        "  #Output some performance numbers during backtest run \n",
        "  #This code just prints out the past month's performance,\n",
        "  # so that we have something to look at while the backtest runs.\n",
        "\n",
        "  # Get today's date\n",
        "  today = zipline.api.get_datetime().date()\n",
        "\n",
        "  # Calculate percent difference since last month\n",
        "  perf_pct = (context.portfolio.portfolio_value / context.last_month) - 1\n",
        "\n",
        "  # Print performance, format as percent with two decimals. \n",
        "  print(\"{} - Last Month Result: {:.2%}\".format(today, perf_pct))\n",
        "\n",
        "  # Remember today's portfolio value for next month's calculation \n",
        "  context.last_month = context.portfolio.portfolio_value\n",
        "\n",
        "#Initialization and trading logic\n",
        "\n",
        "\n",
        "def initialize(context):\n",
        "\n",
        "  # Set commission and slippage.\n",
        "  if enable_commission:\n",
        "    comm_model = PerDollar(cost=commission_pct) \n",
        "  else:\n",
        "    comm_model = PerDollar(cost=0.0) \n",
        "  set_commission(comm_model)\n",
        "  if enable_slippage: slippage_model=VolumeShareSlippage(volume_limit=slippage_volume_limit,\n",
        "price_impact=slippage_impact) \n",
        "  else:\n",
        "    slippage_model=FixedSlippage(spread=0.0) \n",
        "  set_slippage(slippage_model)\n",
        "\n",
        "  # Used only for progress output. \n",
        "  context.last_month = intial_portfolio\n",
        "\n",
        "  # Store index membership\n",
        "  context.index_members = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/My Project Folder/index members/sp500.csv', engine='python', error_bad_lines=False)\n",
        "\n",
        "\n",
        "  #Schedule rebalance monthly. \n",
        "  schedule_function(\n",
        "    func=rebalance, \n",
        "    date_rule=date_rules.month_start(), \n",
        "    time_rule=time_rules.market_open()\n",
        "  )\n",
        "\n",
        "def rebalance(context, data):\n",
        "  # Write some progress output during the backtest \n",
        "  output_progress(context)\n",
        "\n",
        "  # First, get today's date\n",
        "  today = zipline.api.get_datetime().date()\n",
        "\n",
        "  # Second, get the index makeup for all days prior to today.\n",
        "  all_prior = context.index_members.loc[context.index_members.index < today]\n",
        "\n",
        "  todays_universe = [ \n",
        "    symbol(ticker) for ticker in\n",
        "    context.index_members.loc[context.index_members.index < today].iloc[-1,0].split(',')\n",
        "  ]\n",
        "\n",
        "  # Get historical data\n",
        "  hist = data.history(todays_universe, \"close\", momentum_window, \"1d\")\n",
        "\n",
        "  # Make momentum ranking table\n",
        "  ranking_table = hist.apply(momentum_score).sort_values(ascending=False)\n",
        "\n",
        "  #Sell Logic\n",
        "  #First we check if any existing position should be sold.\n",
        "    #Sell if stock is no longer part of index.\n",
        "    #Sell if stock has too low momentum value.\n",
        "\n",
        "  kept_positions = list(context.portfolio.positions.keys()) \n",
        "  for security in context.portfolio.positions:\n",
        "    if (security not in todays_universe): \n",
        "      order_target_percent(security, 0.0) \n",
        "      kept_positions.remove(security)\n",
        "    elif ranking_table[security] < minimum_momentum: \n",
        "      order_target_percent(security, 0.0) \n",
        "      kept_positions.remove(security)\n",
        "\n",
        "  #Stock Selection Logic\n",
        "  #Check how many stocks we are keeping from last month.\n",
        "  #Fill from top of ranking list, until we reach the desired total number of portfolio holdings.\n",
        "\n",
        "  replacement_stocks = portfolio_size - len(kept_positions) \n",
        "  buy_list = ranking_table.loc[\n",
        "    ~ranking_table.index.isin(kept_positions)][:replacement_stocks]\n",
        "  new_portfolio = pd.concat(\n",
        "    (buy_list,\n",
        "    ranking_table.loc[ranking_table.index.isin(kept_positions)])\n",
        "  )\n",
        "  buy_list = ranking_table.loc[\n",
        "    ~ranking_table.index.isin(kept_positions)][:replacement_stocks]\n",
        "\n",
        "  #Calculate inverse volatility for stocks, and make target position weights.\n",
        "\n",
        "  vola_table = hist[new_portfolio.index].apply(volatility) \n",
        "  inv_vola_table = 1 / vola_table\n",
        "  sum_inv_vola = np.sum(inv_vola_table) \n",
        "  vola_target_weights = inv_vola_table / sum_inv_vola\n",
        "  for security, rank in new_portfolio.iteritems(): \n",
        "    weight = vola_target_weights[security]\n",
        "    if security in kept_positions:\n",
        "      order_target_percent(security, weight)\n",
        "    else:\n",
        "      if ranking_table[security] > minimum_momentum: \n",
        "        order_target_percent(security, weight)\n",
        "\n",
        "def analyze(context, perf):\n",
        "  perf['max'] = perf.portfolio_value.cummax() \n",
        "  perf['dd'] = (perf.portfolio_value / perf['max']) - 1 \n",
        "  maxdd = perf['dd'].min()\n",
        "\n",
        "  ann_ret = (np.power((perf.portfolio_value.iloc[-1] / perf.portfolio_value.iloc[0]),(252 / len(perf)))) - 1\n",
        "\n",
        "  print(\"Annualized Return: {:.2%} Max Drawdown: {:.2%}\".format(ann_ret, maxdd))\n",
        "\n",
        "  return\n",
        "'''\n",
        "start = datetime(1997, 1, 1, 8, 15, 12, 0, pytz.UTC)\n",
        "end = datetime(2018, 12, 31, 8, 15, 12, 0, pytz.UTC)\n",
        "'''\n",
        "\n",
        "start = pd.Timestamp('1997-1-1', tz='utc')\n",
        "end = pd.Timestamp('2018-12-31', tz='utc')\n",
        "\n",
        "perf = zipline.run_algorithm(start=start, end=end, \n",
        "                             initialize=initialize, \n",
        "                             analyze=analyze, \n",
        "                             capital_base=intial_portfolio, \n",
        "                             data_frequency = 'daily', \n",
        "                             bundle='quandl' )"
      ],
      "metadata": {
        "id": "6aRGAkzKLH88",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Clenow Trend Model"
      ],
      "metadata": {
        "id": "x83jcz1QUFDe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "%matplotlib inline\n",
        "\n",
        "import zipline\n",
        "from zipline.api import future_symbol,  \\\n",
        "    set_commission, set_slippage, schedule_function, date_rules, \\\n",
        "    time_rules, continuous_future, order_target\n",
        "from pandas import Timestamp\n",
        "import pytz\n",
        "import datetime as datetime\n",
        "import matplotlib.pyplot as plt\n",
        "import pyfolio as pf\n",
        "import pandas as pd\n",
        "import numpy as np  \n",
        "from zipline.finance.commission import PerTrade, PerContract\n",
        "from zipline.finance.slippage import VolumeShareSlippage, \\\n",
        "    FixedSlippage, VolatilityVolumeShare\n",
        "\n",
        "# These lines are for the dynamic text reporting\n",
        "from IPython.display import display\n",
        "import ipywidgets as widgets\n",
        "out = widgets.HTML()\n",
        "display(out)\n",
        "\n",
        "\"\"\"\n",
        "Model Settings\n",
        "\"\"\"\n",
        "starting_portfolio = 50000000\n",
        "risk_factor = 0.0015\n",
        "stop_distance = 3\n",
        "breakout_window = 50\n",
        "vola_window = 40\n",
        "slow_ma = 80\n",
        "fast_ma = 40\n",
        "enable_commission = True\n",
        "enable_slippage = True  \n",
        "\n",
        "\n",
        "def report_result(context, data):\n",
        "    context.months += 1\n",
        "    today = zipline.api.get_datetime().date()\n",
        "    # Calculate annualized return so far\n",
        "    ann_ret = np.power(context.portfolio.portfolio_value / starting_portfolio, \n",
        "                   12 / context.months) - 1\n",
        "    \n",
        "    # Update the text\n",
        "    out.value = \"\"\"{} We have traded <b>{}</b> months \n",
        "    and the annualized return is <b>{:.2%}</b>\"\"\".format(today, context.months, ann_ret)\n",
        "\n",
        "def roll_futures(context, data):\n",
        "    open_orders = zipline.api.get_open_orders()\n",
        "    \n",
        "    for held_contract in context.portfolio.positions:\n",
        "        # don't roll positions that are set to change by core logic\n",
        "        if held_contract in open_orders: \n",
        "            continue\n",
        "        \n",
        "        # Save some time by only checking rolls for\n",
        "        # contracts stopping trading in the next days\n",
        "        days_to_auto_close = (\n",
        "            held_contract.auto_close_date.date() - data.current_session.date()\n",
        "        ).days\n",
        "        if days_to_auto_close > 5:\n",
        "            continue        \n",
        "        \n",
        "        # Make a continuation\n",
        "        continuation = continuous_future(\n",
        "                held_contract.root_symbol, \n",
        "                offset=0, \n",
        "                roll='volume', \n",
        "                adjustment='mul'\n",
        "                )\n",
        "        \n",
        "        # Get the current contract of the continuation\n",
        "        continuation_contract = data.current(continuation, 'contract')\n",
        "        \n",
        "        if continuation_contract != held_contract:\n",
        "            # Check how many contracts we hold\n",
        "            pos_size = context.portfolio.positions[held_contract].amount         \n",
        "            # Close current position\n",
        "            order_target(held_contract, 0)\n",
        "            # Open new position\n",
        "            order_target(continuation_contract, pos_size)     \n",
        "            \n",
        "def position_size(portfolio_value, std, point_value):\n",
        "    target_variation = portfolio_value * risk_factor\n",
        "    contract_variation = std * point_value\n",
        "    contracts = target_variation / contract_variation\n",
        "    return int(np.nan_to_num(contracts)) \n",
        "    \n",
        "def initialize(context):\n",
        "    \n",
        "    \"\"\"\n",
        "    Cost Settings\n",
        "    \"\"\"\n",
        "    if enable_commission:\n",
        "        comm_model = PerContract(cost=0.85, exchange_fee=1.5)\n",
        "    else:\n",
        "        comm_model = PerTrade(cost=0.0)\n",
        "        \n",
        "    set_commission(us_futures=comm_model)\n",
        "    \n",
        "    if enable_slippage:\n",
        "        slippage_model=VolatilityVolumeShare(volume_limit=0.2)\n",
        "    else:\n",
        "        slippage_model=FixedSlippage(spread=0.0)      \n",
        "        \n",
        "    set_slippage(us_futures=slippage_model)\n",
        "    \n",
        "    \"\"\"\n",
        "    Markets to trade\n",
        "    \"\"\" \n",
        "    currencies = [\n",
        "        'AD',\n",
        "        'BP',\n",
        "        'CD',\n",
        "        'CU',\n",
        "        'DX',\n",
        "        'JY',\n",
        "        'NE',\n",
        "        'SF',\n",
        "    ]\n",
        "    \n",
        "    agricultural = [\n",
        "        '_C',\n",
        "        'CT',\n",
        "        'FC',\n",
        "        'KC',\n",
        "        'LR',\n",
        "        'LS',\n",
        "        '_O',\n",
        "        '_S',\n",
        "        'SB',\n",
        "        'SM',\n",
        "        '_W',\n",
        "    ]\n",
        "    nonagricultural = [\n",
        "        'CL',\n",
        "        'GC',\n",
        "        'HG',\n",
        "        'HO',\n",
        "        'LG',\n",
        "        'NG',\n",
        "        'PA',\n",
        "        'PL',\n",
        "        'RB',\n",
        "        'SI',\n",
        "    ]\n",
        "    equities = [\n",
        "        'ES',\n",
        "        'NK',\n",
        "        'NQ',\n",
        "        'TW',\n",
        "        'VX',\n",
        "        'YM',\n",
        "    ]\n",
        "    rates = [\n",
        "        'ED',\n",
        "        'FV',\n",
        "        'TU',\n",
        "        'TY',\n",
        "        'US',\n",
        "    ]\n",
        "    \n",
        "    # Make a list of all the markets\n",
        "    markets = currencies + agricultural + nonagricultural + equities + rates\n",
        "    \n",
        "    # Make a list of all continuations\n",
        "    context.universe = [\n",
        "        continuous_future(market, offset=0, roll='volume', adjustment='mul')\n",
        "            for market in markets\n",
        "    ]\n",
        "    \n",
        "    # We'll use these to keep track of best position reading\n",
        "    # Used to calculate stop points.\n",
        "    context.highest_in_position = {market: 0 for market in markets} \n",
        "    context.lowest_in_position = {market: 0 for market in markets}    \n",
        "    \n",
        "    # Schedule the daily trading\n",
        "    schedule_function(daily_trade, date_rules.every_day(), time_rules.market_close())\n",
        "    \n",
        "    # We'll just use this for the progress output\n",
        "    # during the backtest. Doesn't impact anything.\n",
        "    context.months = 0    \n",
        "    \n",
        "    # Schedule monthly report output\n",
        "    schedule_function(\n",
        "        func=report_result,\n",
        "        date_rule=date_rules.month_start(),\n",
        "        time_rule=time_rules.market_open()\n",
        "    ) \n",
        "    \n",
        "def analyze(context, perf):\n",
        "    returns, positions, transactions = pf.utils.extract_rets_pos_txn_from_zipline(perf)\n",
        "    pf.create_returns_tear_sheet(returns, benchmark_rets=None)\n",
        "    \n",
        "def daily_trade(context, data):\n",
        "    # Get continuation data\n",
        "    hist = data.history(\n",
        "        context.universe, \n",
        "        fields=['close','volume'], \n",
        "        frequency='1d', \n",
        "        bar_count=250,\n",
        "    )\n",
        "    \n",
        "    # Calculate trend\n",
        "    hist['trend'] = hist['close'].ewm(span=fast_ma).mean() > hist['close'].ewm(span=slow_ma).mean()    \n",
        "    \n",
        "    # Make dictionary of open positions\n",
        "    open_pos = {\n",
        "        pos.root_symbol: pos \n",
        "        for pos in context.portfolio.positions\n",
        "    } \n",
        "    \n",
        "    # Iterate markets, check for trades\n",
        "    for continuation in context.universe:\n",
        "        \n",
        "        # Get root symbol of continuation\n",
        "        root = continuation.root_symbol\n",
        "        \n",
        "        # Slice off history for just this market\n",
        "        h = hist.xs(continuation, 2)\n",
        "        \n",
        "        # Get standard deviation\n",
        "        std = h.close.diff()[-vola_window:].std()\n",
        "\n",
        "        if root in open_pos: # Position is open\n",
        "\n",
        "            # Get position\n",
        "            p = context.portfolio.positions[open_pos[root]]\n",
        "            \n",
        "            if p.amount > 0: # Position is long\n",
        "                if context.highest_in_position[root] == 0: # First day holding the position\n",
        "                    context.highest_in_position[root] = p.cost_basis\n",
        "                else:\n",
        "                    context.highest_in_position[root] = max(\n",
        "                        h['close'].iloc[-1], context.highest_in_position[root]\n",
        "                    ) \n",
        "                    \n",
        "                # Calculate stop point\n",
        "                stop = context.highest_in_position[root] - (std  * stop_distance)\n",
        "                # Check if stop is hit\n",
        "                if h.iloc[-1]['close'] < stop:\n",
        "                    contract = open_pos[root]\n",
        "                    order_target(contract, 0)\n",
        "                    context.highest_in_position[root] = 0\n",
        "                # Check if trend has flipped\n",
        "                elif h['trend'].iloc[-1] == False:\n",
        "                    contract = open_pos[root]\n",
        "                    order_target(contract, 0)\n",
        "                    context.highest_in_position[root] = 0\n",
        "                    \n",
        "            else: # Position is short\n",
        "                if context.lowest_in_position[root] == 0: # First day holding the position\n",
        "                    context.lowest_in_position[root] = p.cost_basis\n",
        "                else:\n",
        "                    context.lowest_in_position[root] = min(\n",
        "                        h['close'].iloc[-1], context.lowest_in_position[root]\n",
        "                    )\n",
        "                \n",
        "                # Calculate stop point\n",
        "                stop = context.lowest_in_position[root] + (std  * stop_distance)\n",
        "                \n",
        "                # Check if stop is hit\n",
        "                if h.iloc[-1]['close'] > stop:\n",
        "                    contract = open_pos[root]\n",
        "                    order_target(contract, 0)\n",
        "                    context.lowest_in_position[root] = 0\n",
        "                # Check if trend has flipped\n",
        "                elif h['trend'].iloc[-1] == True:\n",
        "                    contract = open_pos[root]\n",
        "                    order_target(contract, 0)\n",
        "                    context.lowest_in_position[root] = 0                         \n",
        "        \n",
        "        else: # No position on\n",
        "            if h['trend'].iloc[-1]: # Bull trend\n",
        "                # Check if we just made a new high\n",
        "                if h['close'][-1] == h[-breakout_window:]['close'].max(): \n",
        "                    contract = data.current(continuation, 'contract')\n",
        "\n",
        "                    contracts_to_trade = position_size( \\\n",
        "                                                       context.portfolio.portfolio_value, \\\n",
        "                                                       std, \\\n",
        "                                                       contract.price_multiplier)\n",
        "                    \n",
        "                    # Limit size to 20% of avg. daily volume\n",
        "                    contracts_cap = int(h['volume'][-20:].mean() * 0.2)\n",
        "                    contracts_to_trade = min(contracts_to_trade, contracts_cap)\n",
        "                    \n",
        "                    # Place the order\n",
        "                    order_target(contract, contracts_to_trade)\n",
        "             \n",
        "            else: # Bear trend\n",
        "                # Check if we just made a new low\n",
        "                if h['close'][-1] == h[-breakout_window:]['close'].min(): \n",
        "                    contract = data.current(continuation, 'contract')\n",
        "\n",
        "                    contracts_to_trade = position_size( \\\n",
        "                                                       context.portfolio.portfolio_value, \\\n",
        "                                                       std, \\\n",
        "                                                       contract.price_multiplier)\n",
        "                    \n",
        "                    # Limit size to 20% of avg. daily volume\n",
        "                    contracts_cap = int(h['volume'][-20:].mean() * 0.2)\n",
        "                    contracts_to_trade = min(contracts_to_trade, contracts_cap)\n",
        "                    \n",
        "                    # Place the order\n",
        "                    order_target(contract, -1 * contracts_to_trade)\n",
        "    \n",
        "    # If we have open positions, check for rolls\n",
        "    if len(open_pos) > 0:   \n",
        "        roll_futures(context, data)                \n",
        "                        \n",
        "\n",
        "start = pd.Timestamp('2003-01-01', tz='utc')\n",
        "end = pd.Timestamp('2017-12-31', tz='utc')\n",
        "\n",
        "perf = zipline.run_algorithm(\n",
        "    start=start, end=end, \n",
        "    initialize=initialize, \n",
        "    analyze=analyze,\n",
        "    capital_base=starting_portfolio,  \n",
        "    data_frequency = 'daily', \n",
        "    bundle='random_futures_data' ) \n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "sponWV8ZKDJv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üíª**MODEL TESTING**"
      ],
      "metadata": {
        "id": "8gWXJGjGBDbs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## My Tests"
      ],
      "metadata": {
        "id": "ySxEKidEU606"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DOW Jones Momentum Model"
      ],
      "metadata": {
        "id": "1V0GCt2_92BD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "%matplotlib inline\n",
        "\n",
        "import zipline\n",
        "from zipline import run_algorithm\n",
        "from zipline.api import order_target_percent, symbol, set_commission, set_slippage, schedule_function, date_rules, time_rules\n",
        "import matplotlib.pyplot as plt \n",
        "import pyfolio as pf\n",
        "import pandas as pd \n",
        "import numpy as np\n",
        "from scipy import stats\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "from zipline.finance.commission import PerDollar\n",
        "from zipline.finance.slippage import VolumeShareSlippage, FixedSlippage\n",
        "\n",
        "\n",
        "initial_portfolio = 10000\n",
        "minimum_momentum = 62\n",
        "portfolio_size = 5\n",
        "vola_window = 15\n",
        "\n",
        "def momentum_score(ts):\n",
        "\n",
        "  #Input: Price time series.Output: Annualized exponential regression slope, multiplied by the R2\n",
        "\n",
        "  # Make a list of consecutive numbers \n",
        "  x = np.arange(len(ts))\n",
        "  # Get logs\n",
        "  log_ts = np.log(ts)\n",
        "  # Calculate regression values\n",
        "  slope, intercept, r_value, p_value, std_err = stats.linregress(x, log_ts) \n",
        "  # Annualize percent\n",
        "  annualized_slope = (np.power(np.exp(slope), 252) - 1) * 100 \n",
        "  #Adjust for fitness\n",
        "  score = annualized_slope * (r_value ** 2) \n",
        "  return score\n",
        "\n",
        "def volatility(ts):\n",
        "  return ts.pct_change().rolling(vola_window).std().iloc[-1]\n",
        "\n",
        "\n",
        "#Initialization and trading logic\n",
        "\n",
        "\n",
        "def initialize(context):\n",
        "\n",
        "  context.rolling_window = 100\n",
        "\n",
        "  #Commission and Slippage Settings\n",
        "\n",
        "  enable_commission = True \n",
        "  commission_pct = 0.001 \n",
        "  enable_slippage = True \n",
        "  slippage_volume_limit = 0.025\n",
        "  slippage_impact = 0.05\n",
        "\n",
        "  dji = ['aave','ada','algo',\n",
        "         'alpha','ant','bal',\n",
        "         'bat','bch','bnb',\n",
        "         'bsv','btc']\n",
        "  \n",
        "  # Make a list of symbols from the list of tickers\n",
        "  context.dji_symbols = [symbol(s) for s in dji]\n",
        "\n",
        "  # Set commission and slippage.\n",
        "  if enable_commission:\n",
        "    comm_model = PerDollar(cost=commission_pct) \n",
        "  else:\n",
        "    comm_model = PerDollar(cost=0.0) \n",
        "  set_commission(comm_model)\n",
        "  if enable_slippage: slippage_model=VolumeShareSlippage(volume_limit=slippage_volume_limit,\n",
        "price_impact=slippage_impact) \n",
        "  else:\n",
        "    slippage_model=FixedSlippage(spread=0.0) \n",
        "  set_slippage(slippage_model)\n",
        "\n",
        "\n",
        "  #Schedule rebalance monthly. \n",
        "  schedule_function(\n",
        "    func=rebalance, \n",
        "    date_rule=date_rules.month_start(), \n",
        "    time_rule=time_rules.market_open()\n",
        "  )\n",
        "\n",
        "def rebalance(context, data):\n",
        "\n",
        "  # Get historical data\n",
        "  hist = data.history(context.dji_symbols, \"close\", context.rolling_window, \"1d\")\n",
        "\n",
        "  # Make momentum ranking table\n",
        "  ranking_table = hist.apply(momentum_score).sort_values(ascending=False)\n",
        "\n",
        "  #Sell Logic\n",
        "  #First we check if any existing position should be sold.\n",
        "    #Sell if stock is no longer part of index.\n",
        "    #Sell if stock has too low momentum value.\n",
        "\n",
        "  kept_positions = list(context.portfolio.positions.keys()) \n",
        "  for security in context.portfolio.positions:\n",
        "    if ranking_table[security] < minimum_momentum: \n",
        "      order_target_percent(security, 0.0)\n",
        "      kept_positions.remove(security)\n",
        " \n",
        "  #Stock Selection Logic\n",
        "  #Check how many stocks we are keeping from last month.\n",
        "  #Fill from top of ranking list, until we reach the desired total number of portfolio holdings.\n",
        "\n",
        "  replacement_stocks = portfolio_size - len(kept_positions) \n",
        "  buy_list = ranking_table.loc[\n",
        "    ~ranking_table.index.isin(kept_positions)][:replacement_stocks]\n",
        "  new_portfolio = pd.concat(\n",
        "    (buy_list,\n",
        "    ranking_table.loc[ranking_table.index.isin(kept_positions)])\n",
        "  )\n",
        "  buy_list = ranking_table.loc[\n",
        "    ~ranking_table.index.isin(kept_positions)][:replacement_stocks]\n",
        "\n",
        "  #Calculate inverse volatility for stocks, and make target position weights.\n",
        "\n",
        "  vola_table = hist[new_portfolio.index].apply(volatility) \n",
        "  inv_vola_table = 1 / vola_table\n",
        "  sum_inv_vola = np.sum(inv_vola_table) \n",
        "  vola_target_weights = inv_vola_table / sum_inv_vola\n",
        "  for security, rank in new_portfolio.iteritems(): \n",
        "    weight = vola_target_weights[security]\n",
        "    if security in kept_positions:\n",
        "      order_target_percent(security, weight)\n",
        "    else:\n",
        "      if ranking_table[security] > minimum_momentum: \n",
        "        order_target_percent(security, weight)\n",
        "\n",
        "\n",
        "def analyze(context, perf):\n",
        "    \n",
        "  # Use PyFolio to generate a performance report\n",
        "  returns, positions, transactions = pf.utils.extract_rets_pos_txn_from_zipline(perf)\n",
        "\n",
        "  benchmark_period_return = perf['benchmark_period_return']\n",
        "\n",
        "  daily_benchmark_returns = np.exp(np.log(benchmark_period_return + 1.0).diff()) - 1\n",
        "\n",
        "  # Create tear sheet\n",
        "  pf.create_full_tear_sheet(returns, positions=positions, transactions=transactions, benchmark_rets=None)\n",
        "\n",
        "start= pd.Timestamp('2010-2-2', tz='utc')\n",
        "end = pd.Timestamp('2014-2-2', tz='utc')\n",
        "\n",
        "perf = zipline.run_algorithm(start=start, \n",
        "                             end=end, \n",
        "                             initialize=initialize, \n",
        "                             analyze=analyze, \n",
        "                             capital_base=initial_portfolio, \n",
        "                             data_frequency='daily',\n",
        "                             bundle='crypto')"
      ],
      "metadata": {
        "id": "OfmZYBZ4p4nv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Export Performance Result to disk in csv file\n",
        "\n",
        "perf.portfolio_value.to_csv('dji_momentum_model.csv')"
      ],
      "metadata": {
        "id": "M18L5KZe3rQr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Equal Weight Momementum Model"
      ],
      "metadata": {
        "id": "_tfGWw1gYDlo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This ensures that our graphs will be shown properly in the notebook.\n",
        "%matplotlib inline\n",
        "\n",
        "# Import a few libraries we need\n",
        "from zipline import run_algorithm\n",
        "from zipline.api import order_target_percent, record, symbol, set_benchmark\n",
        "import pyfolio as pf\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "def initialize(context):\n",
        "  # Which stock to trade\n",
        "\n",
        "  \"\"\"\n",
        "  dji = [\"aave\",\"ada\",\"algo\",\"alpha\",\"ant\",\n",
        "         \"bal\",\"bat\",\"bch\",\"bnb\",\"bsv\",\n",
        "         \"btc\"]\n",
        "  \"\"\"\n",
        "  dji = [\"APA\",\"BBY\",\"CMCSA\",\"CTL\",\"EL\",\n",
        "         \"FAST\",\"GCO\",\"HPQ\",\"JCI\",\"JEC\",\n",
        "         \"MCHP\"]\n",
        " \n",
        "  # Make a list of symbols from the list of tickers\n",
        "  context.dji_symbols = [symbol(s) for s in dji]\n",
        "\n",
        "  # Moving average window\n",
        "  context.index_average_window = 62\n",
        "  \n",
        "def handle_data(context, data):\n",
        "  \n",
        "  # Get history for all the stocks\n",
        "  stock_hist = data.history(context.dji_symbols, \"close\", context.index_average_window, \"1d\")\n",
        "\n",
        "  # Make an empty DataFrame to start with\n",
        "  stock_analytics = pd.DataFrame()\n",
        "\n",
        "  # Add column for above or below average\n",
        "  stock_analytics['above_mean'] = stock_hist.iloc[-1] > stock_hist.mean()\n",
        "\n",
        "  # Set weight for stocks to buy\n",
        "  stock_analytics.loc[stock_analytics['above_mean'] == True, 'weight'] = 1/len(context.dji_symbols)\n",
        "\n",
        "  # Set weight to zero for the rest\n",
        "  stock_analytics.loc[stock_analytics['above_mean'] == False, 'weight'] = 0.0\n",
        "\n",
        "  # Iterate each row and place trades\n",
        "  for stock, analytics in stock_analytics.iterrows():\n",
        "\n",
        "    # Check if the stock can be traded\n",
        "    if data.can_trade(stock):\n",
        "\n",
        "      # Place the trade\n",
        "      order_target_percent(stock, analytics['weight'])\n",
        "\n",
        "def analyze(context, perf):\n",
        "\n",
        "  fig = plt.figure(figsize=(12, 8))\n",
        "\"\"\"\n",
        "  # First chart\n",
        "  ax = fig.add_subplot(311)\n",
        "  ax.set_title('Strategy Results')\n",
        "  ax.plot(perf['portfolio_value'], linestyle='-',\n",
        "          label='Equity Curve', linewidth=3.0)\n",
        "  ax.legend()\n",
        "  ax.grid(False)\n",
        "  # Second chart\n",
        "  ax = fig.add_subplot(312)\n",
        "  ax.plot(perf['gross_leverage'],label='Exposure',\n",
        "          linestyle='-', linewidth=1.0)\n",
        "  ax.legend()\n",
        "  ax.grid(True)\n",
        "\n",
        "  # Third chart\n",
        "  ax = fig.add_subplot(313)\n",
        "  ax.plot(perf['returns'], label='Returns',\n",
        "          linestyle='-.', linewidth=1.0)\n",
        "  ax.legend()\n",
        "  ax.grid(True)\n",
        "\"\"\"\n",
        "\n",
        "def analyze(context, perf):\n",
        "  # Use PyFolio to generate a performance report\n",
        "  returns, positions, transactions = pf.utils.extract_rets_pos_txn_from_zipline(perf)\n",
        "\n",
        "  pf.create_returns_tear_sheet(returns, benchmark_rets=None)\n",
        "\n",
        "# Set start and end date\n",
        "start_date = pd.Timestamp('2016-1-2', tz='utc')\n",
        "end_date = pd.Timestamp('2020-12-31', tz='utc')\n",
        "\n",
        "# Fire off the backtest\n",
        "perf = run_algorithm(\n",
        "start=start_date,\n",
        "end=end_date,\n",
        "initialize=initialize,\n",
        "analyze=analyze,\n",
        "handle_data=handle_data,\n",
        "capital_base=10000,\n",
        "data_frequency = 'daily', \n",
        "bundle= 'stocks',)"
      ],
      "metadata": {
        "id": "JEtmR8GjFANc",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Export performance results to disk in csv file\n",
        "\n",
        "perf.portfolio_value.to_csv('ewm_momentum_model.csv')"
      ],
      "metadata": {
        "id": "BU2OOl30YXe1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Compare Performance Results to Bencmark"
      ],
      "metadata": {
        "id": "kPK0-JU_Y1Ke"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import empyrical as em\n",
        "from IPython.core.display import display, HTML\n",
        "import pandas as pd\n",
        "import numpy\n",
        "\n",
        "base_path = '/content/drive/MyDrive/Colab Notebooks/My Project Folder/Backtests/'\n",
        "\n",
        "benchmark_name = {\"SPXTR\" : \"S&P 500 Total Return Index\"}\n",
        "bm = \"SPXTR\"\n",
        "bm_name = benchmark_name[bm]\n",
        "\n",
        "strat_names = {\n",
        "    \"dji_momentum_model\" : \"Dow Jones 30 Momentum Strategy\",\n",
        "    \"core_trend\" : \"Core Trend Strategy\",    \n",
        "    \"time_return\" : \"Time Return Strategy\",\n",
        "    \"counter_trend\" : \"Counter Trend Strategy\",\n",
        "    \"curve_trading\" : \"Curve Trading Strategy\",\n",
        "    \"equity_momentum\" : \"Equity Momentum Strategy\",\n",
        "    \"dow_model\" : \"Dow_Strategy\",\n",
        "    \"EWM_momentum_model\" : \"Equal Weight Momentum Strategy\"\n",
        "}\n",
        "\n",
        "\n",
        "strat = 'dji_momentum_model' #change line of code to desired model name of strategy\n",
        "strat_name = strat_names[strat]\n",
        "\n",
        "df = pd.read_csv(base_path + strat + '.csv', index_col=0, parse_dates=True, names=[strat] )\n",
        "'''\n",
        "df[bm_name] = pd.read_csv(base_path + bm + '.csv', index_col=0,parse_dates=True, names=[bm])\n",
        "'''\n",
        "\n",
        "\n",
        "df.index = df.index.strftime('%d/%m/%Y')\n",
        "\n",
        "\n",
        "bm_name = pd.read_csv(base_path + bm + '.csv', index_col=0,parse_dates=True, names=[bm])\n",
        "bm_name\n",
        "bm_name.index = bm_name.index.strftime('%d/%m/%Y')\n",
        "\n",
        "new_df = pd.concat([df, bm_name], axis=1, join='inner')\n",
        "\n",
        "#change line of code to desired model name of strategy\n",
        "new_df['dji_momentum_model'] = new_df['dji_momentum_model'].astype(float) #change\n",
        "new_df['SPXTR'] = new_df['SPXTR'].astype(float)\n",
        "\n",
        "yr_periods = 252\n",
        "\n",
        "# Format for book display\n",
        "font = {'family' : 'DejaVu Sans',\n",
        "        'weight' : 'normal',\n",
        "        'size'   : 8}\n",
        "matplotlib.rc('font', **font)\n",
        "\n",
        "def equity_graph(new_df):\n",
        "    new_df = new_df / new_df.iloc[0]\n",
        "\n",
        "    # Calculate correlation\n",
        "    new_df['Correlation'] = new_df[strat].pct_change().rolling(window=int(yr_periods / 1)).corr(new_df[bm].pct_change())    \n",
        "    new_df['Drawdown'] = (new_df[strat] / new_df[strat].cummax()) - 1\n",
        "    \n",
        "    fig = plt.figure(figsize=(15,15))\n",
        "\n",
        "    # First chart\n",
        "    ax = fig.add_subplot(311)\n",
        "    ax.set_title('Strategy Comparisons')\n",
        "    ax.semilogy(new_df[strat], '-',label=strat_name, color='red', linewidth=1.0)\n",
        "    ax.semilogy(new_df[bm], '-',label='SPXTR', color='grey', linewidth=1.0)\n",
        "    spacing = 500\n",
        "    visible = ax.xaxis.get_ticklabels()[::spacing]\n",
        "    for label in ax.xaxis.get_ticklabels():\n",
        "        if label not in visible:\n",
        "            label.set_visible(False)\n",
        "    ax.set_ylabel('Returns')\n",
        "    ax.set_xlabel('Duration')\n",
        "    plt.xticks(rotation=None)\n",
        "    ax.legend()\n",
        "    \n",
        "    # Second chart\n",
        "    ax = fig.add_subplot(312)\n",
        "    ax.fill_between(new_df.index, new_df['Drawdown'], label='Drawdown', color='blue',linewidth=1.0)\n",
        "    spacing = 500\n",
        "    visible = ax.xaxis.get_ticklabels()[::spacing]\n",
        "    for label in ax.xaxis.get_ticklabels():\n",
        "        if label not in visible:\n",
        "            label.set_visible(False)\n",
        "    plt.xticks(rotation=None)\n",
        "    ax.legend()\n",
        "\n",
        "    # Third chart\n",
        "    ax = fig.add_subplot(313)\n",
        "    ax.fill_between(new_df.index, new_df['Correlation'], label='6M Rolling Correlation', color='teal', linewidth=1.0)\n",
        "    spacing = 500\n",
        "    visible = ax.xaxis.get_ticklabels()[::spacing]\n",
        "    for label in ax.xaxis.get_ticklabels():\n",
        "        if label not in visible:\n",
        "            label.set_visible(False)\n",
        "    plt.xticks(rotation=None)\n",
        "    ax.legend()\n",
        "\n",
        "equity_graph(new_df)\n",
        "\n",
        "strat = 'counter_trend'\n",
        "strat_name = strat_names[strat]\n",
        "\n",
        "df = pd.read_csv(base_path + strat + '.csv', index_col=0, parse_dates=True, names=[strat] )\n",
        "\n",
        "monthly_data = em.aggregate_returns(df[strat].pct_change(),'monthly')\n",
        "yearly_data = em.aggregate_returns(df[strat].pct_change(),'yearly')\n",
        "\n",
        "# Start off an HTML table for display \n",
        "table = \"\"\"\n",
        "<table id='monthlyTable' class='table table-hover table-condensed table-striped'>\n",
        "\n",
        "<th style=\"text-align:top\">Year</th>\n",
        "<th style=\"text-align:top\">Jan</th>\n",
        "<th style=\"text-align:top\">Feb</th>\n",
        "<th style=\"text-align:top\">Mar</th>\n",
        "<th style=\"text-align:top\">Apr</th>\n",
        "<th style=\"text-align:top\">May</th>\n",
        "<th style=\"text-align:top\">Jun</th>\n",
        "<th style=\"text-align:top\">Jul</th>\n",
        "<th style=\"text-align:top\">Aug</th>\n",
        "<th style=\"text-align:top\">Sep</th>\n",
        "<th style=\"text-align:top\">Oct</th>\n",
        "<th style=\"text-align:top\">Nov</th>\n",
        "<th style=\"text-align:top\">Dec</th>\n",
        "<th style=\"text-align:top\">Year</th>\n",
        "\n",
        "<tr>\"\"\"\n",
        "\n",
        "first_year = True\n",
        "first_month = True\n",
        "yr = 0\n",
        "mnth = 0\n",
        "for m, val in monthly_data.iteritems():\n",
        "    yr = m[0]\n",
        "    mnth = m[1]\n",
        "\n",
        "    if(first_month):\n",
        "        table += \"<td align='right'><b>{}</b></td>\\n\".format(yr)\n",
        "        first_month = False\n",
        "\n",
        "    if(first_year): # pad empty months for first year if sim doesn't start in January\n",
        "        first_year = False\n",
        "        if(mnth > 1):\n",
        "            for i in range(1, mnth):\n",
        "                table += \"<td align='right'>-</td>\\n\"\n",
        "\n",
        "    table += \"<td align='right'>{:+.1f}</td>\\n\".format(val * 100)\n",
        "\n",
        "    if(mnth==12): # check for dec, add yearly\n",
        "        table += \"<td align='right'><b>{:+.1f}</b></td>\\n\".format(yearly_data[yr] * 100)     \n",
        "        table += '</tr>\\n <tr> \\n'    \n",
        "        first_month = True\n",
        "\n",
        "# add padding for empty months and last year's value\n",
        "if(mnth != 12):\n",
        "    for i in range(mnth+1, 13):\n",
        "        table += \"<td align='right'>-</td>\\n\"\n",
        "        if(i==12):\n",
        "            table += \"<td align='right'><b>{:+.1f}</b></td>\\n\".format(\n",
        "                yearly_data[yr] * 100\n",
        "            ) \n",
        "            table += '</tr>\\n <tr> \\n'\n",
        "table += '</tr>\\n </tbody> \\n </table>'\n",
        "\n",
        "display(HTML(table))\n",
        "\n",
        "def holding_period_map(new_df):\n",
        "    yr = em.aggregate_returns(new_df[strat].pct_change(), 'yearly')\n",
        "    new_df = pd.DataFrame(columns=range(1,len(yr)+1), index=yr.index)\n",
        "\n",
        "    yr_start = 0\n",
        "    \n",
        "    table = \"<table class='table table-hover table-condensed table-striped'>\"\n",
        "    table += \"<tr><th>Years</th>\"\n",
        "    \n",
        "    for i in range(len(yr)):\n",
        "        table += \"<th>{}</th>\".format(i+1)\n",
        "    table += \"</tr>\"\n",
        "\n",
        "    for the_year, value in yr.iteritems(): # Iterates years\n",
        "        table += \"<tr><th>{}</th>\".format(the_year) # New table row\n",
        "        \n",
        "        for yrs_held in (range(1, len(yr)+1)): # Iterates yrs held \n",
        "            if yrs_held   <= len(yr[yr_start:yr_start + yrs_held]):\n",
        "                ret = em.annual_return(yr[yr_start:yr_start + yrs_held], 'yearly' )\n",
        "                table += \"<td>{:+.0f}</td>\".format(ret * 100)\n",
        "        table += \"</tr>\"    \n",
        "        yr_start+=1\n",
        "    return table\n",
        "\n",
        "table = holding_period_map(df)\n",
        "display(HTML(table))\n"
      ],
      "metadata": {
        "id": "DlTNGXcHZBUN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_df"
      ],
      "metadata": {
        "id": "-tVVJAEB8WWd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_df['dow_model'] = new_df['dow_model'].astype(float)\n",
        "new_df['SPXTR'] = new_df['SPXTR'].astype(float)"
      ],
      "metadata": {
        "id": "OrxbQQ738pdz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üí≤**DIGITAL ASSETS PROGRAMME**\n",
        "\n"
      ],
      "metadata": {
        "id": "tIM7wTXOAarM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading and manipulating data\n"
      ],
      "metadata": {
        "id": "hzDwZjphbIW0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from datetime import datetime as dt\n",
        "from scipy import stats\n",
        "import seaborn as sn\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "metadata": {
        "id": "RbOv06qSaMnk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "A = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/My Project Folder/random_stocks/APA.csv', parse_dates=True, index_col=0)\n",
        "print(A.head(5))\n",
        "A.info()"
      ],
      "metadata": {
        "id": "tLwh_CcOa9pW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "A2 = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/My Project Folder/random_stocks/APA.csv')\n",
        "print(A2.head(5))\n",
        "A2.info()"
      ],
      "metadata": {
        "id": "C2KHZzjzmMkz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BTC = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/My Project Folder/crypto/crypto_bundl/BTC.csv',parse_dates=True, index_col=0)\n",
        "\n",
        "print(BTC.head(5))\n",
        "BTC.info()"
      ],
      "metadata": {
        "id": "puKmXbuOfGfz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/My Project Folder/crypto_data/coin_Aave_1.csv', parse_dates=True, index_col=0)\n",
        "\n",
        "#Set date fomat 'dd-mm-yy'\n",
        "'''\n",
        "df['Date']= pd.to_datetime(df['Date']).dt.strftime('%d-%m-%y')\n",
        "\n",
        "raw_data['Mycol'] =  pd.to_datetime(raw_data['Mycol'], format='%d%b%Y:%H:%M:%S.%f')\n",
        "\n",
        "'''\n",
        "#Drop columns not needed\n",
        "df= df.drop(columns =['Name', 'Symbol','Marketcap'])\n",
        "\n",
        "# Rearrange columns\n",
        "df = df[['Date','Open','High','Low','Close','Volume']]\n",
        "\n",
        "# Rename columns\n",
        "df.rename(columns = {'Date':'trade_date','Open':'open', 'High':'high',\n",
        "                     'Low':'low','Close':'close',\n",
        "                     'Volume':'volume'}, inplace = True)\n",
        "\n",
        "# reset 'trade_date' column to index\n",
        "df.set_index(\"trade_date\", inplace = True)\n",
        "\n",
        "\n",
        "print(df)\n",
        "df.info()\n"
      ],
      "metadata": {
        "id": "M1BlRUWQbhXa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv('/content/drive/MyDrive/Colab Notebooks/My Project Folder/crypto/AAVE_1.csv')"
      ],
      "metadata": {
        "id": "Iu9KV-1XoiPE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Adjusting timeseries data for NYSE (US) Calender"
      ],
      "metadata": {
        "id": "ZoZBFEZFb1JM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#import required libraries\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "import exchange_calendars as xcals\n",
        "from zipline import get_calendar\n",
        "import numpy as np\n",
        "\n",
        "#load raw data from file\n",
        "raw_data = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/My Project Folder/crypto/coinmetrics_data/btc.csv', parse_dates=True, index_col=0)\n",
        "\n",
        "new = raw_data.drop(raw_data.loc[:, :'PriceBTC'].columns, axis=1)\n",
        "\n",
        "\n",
        "#drop columns not needed. Only closing prices required\n",
        "new.drop(new.iloc[:, 1:76], inplace = True, axis = 1)\n",
        "\n",
        "#Add new columns\n",
        "new['high'] =0\n",
        "new['low'] =0\n",
        "new['open'] =0\n",
        "new['volume'] =0\n",
        "\n",
        "# Rearrange columns to set timestamp as first column\n",
        "new = new[['high','open','low','PriceUSD','volume']]\n",
        "\n",
        "#Change 'PriceUSD' columns to 'close'\n",
        "new.rename(columns = {'PriceUSD':'close'}, inplace = True)\n",
        "\n",
        "\"\"\"\n",
        "#Drop row (date) not needed\n",
        "new=new.drop(['2022-05-25'])\n",
        "\"\"\"\n",
        "\n",
        "#Fill 'close' column with integer values '0'\n",
        "new[\"close\"].fillna(0, inplace=True)\n",
        "\n",
        "#Reset index\n",
        "new.reset_index(inplace = True)\n",
        "\n",
        "#Rename time columns to date\n",
        "new = new.rename(columns={'time': 'date'}, index=None)\n",
        "\n",
        "#Drop all NaN values from dataframe\n",
        "new.dropna()\n",
        "\n",
        "#Convert columns datatype from integer to float\n",
        "new[\"high\"] = new[\"high\"].astype(float)\n",
        "new[\"open\"] = new[\"open\"].astype(float)\n",
        "new[\"low\"] = new[\"low\"].astype(float)\n",
        "new[\"volume\"] = new[\"volume\"].astype(float)\n",
        "\n",
        "#Convert 'date' Column to datetime\n",
        "new['date'] = pd.to_datetime(new['date'], utc=True)\n",
        "\n",
        "#Set 'date' column as index\n",
        "new.set_index('date', inplace=True)\n",
        "\n",
        "# Get all expected trading sessions in new dataframe.\n",
        "sessions = get_calendar('NYSE').sessions_in_range('2009-01-05', '2022-05-24')\n",
        "\n",
        "# To set the trading session in  new dataframe to the NYSE Calender\n",
        "btc = new.reindex(sessions)\n",
        "\n",
        "#Reset index again to change the index name\n",
        "btc.reset_index(inplace = True)\n",
        "\n",
        "#Rename index column to 'date'\n",
        "btc = btc.rename(columns={'index': 'date'}, index=None)\n",
        "\n",
        "#Change date format to Year-Month-Day\n",
        "btc['date'] =  pd.to_datetime(btc['date']).dt.strftime('%Y-%m-%d')\n",
        "\n",
        "\"\"\"\n",
        "btc.set_index('date', inplace=True)\n",
        "\"\"\"\n",
        "\n",
        "# Remove two columns name is 'C' and 'D'\n",
        "df = btc.drop(['high', 'open','low'], axis=1)\n",
        "\n",
        "df['open'] = df['close'] - (0 * df ['close'])\n",
        "df['high'] = df['open'] - (0 * df ['open'])\n",
        "df['low'] = df['high'] - (0 * df ['high'])\n",
        "\n",
        "# Rearrange columns\n",
        "df = df[['date','open','high','low','close','volume']]\n",
        "\n",
        "df.set_index('date', inplace=True)\n",
        "\n",
        "crypto = df.dropna()\n",
        "\n",
        "crypto.to_csv('/content/drive/MyDrive/Colab Notebooks/My Project Folder/crypto/crypto bundle/btc.csv')\n",
        "\n"
      ],
      "metadata": {
        "id": "UQOZCRgetfon"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "# Count total null values in dataframe\n",
        "print(\"Total Number of null values in the DataFrame : \" +\n",
        "\tstr(raw_data.isnull().sum().sum()))\n"
      ],
      "metadata": {
        "id": "DvPNoDDTBsT9",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "#@ show number of null for each column\n",
        "display(raw_data.isnull().sum())\n"
      ],
      "metadata": {
        "id": "_yiqje4xB4Be",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "#display null values\n",
        "raw_data[raw_data['close'].isnull()]"
      ],
      "metadata": {
        "id": "B2kpdW3bC2Ph",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "A = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/My Project Folder/crypto/crypto bundle/alpha.csv', parse_dates=True, index_col=0)\n",
        "print(A)\n",
        "A.info()"
      ],
      "metadata": {
        "id": "IDuCzTIe14q9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Removing weekends from timeseries"
      ],
      "metadata": {
        "id": "wyel-4htJj0U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "#Import statements\n",
        "%matplotlib inline\n",
        "import pandas as pd\n",
        "import datetime as dt\n",
        "import numpy as np\n",
        "\n",
        "#Load csv file from disc\n",
        "df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/My Project Folder/crypto/crypto_data/DOGE.csv')\n",
        "\n",
        "#Set date column to datetime\n",
        "df['time'] = pd.to_datetime(df['time'], errors='coerce')\n",
        "\n",
        "#Remove weekends from data\n",
        "df = df[df.time.dt.weekday < 5]\n",
        "\n",
        "#Set 'date' columns as Index\n",
        "df.set_index(\"time\", inplace = True)\n",
        "\n",
        "#display weekday dataframe\n",
        "df\n"
      ],
      "metadata": {
        "id": "LcR4uk8SJ3mT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#inspect dataframe\n",
        "df.info()"
      ],
      "metadata": {
        "id": "b2HfyHCXUYBR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Save dataframe to csv\n",
        "\n",
        "df.to_csv('/content/drive/MyDrive/Colab Notebooks/My Project Folder/crypto/crypto weekday data/DODGE_weekday.csv')"
      ],
      "metadata": {
        "id": "t91Kk-vQRL8Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Load final data to file to dataframe\n",
        "dodge = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/My Project Folder/crypto/crypto weekday data/DODGE_weekday.csv')\n",
        "\n",
        "print(dodge)\n",
        "\n"
      ],
      "metadata": {
        "id": "biKqcgmYUzrI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Remove weekends from dataframe\n",
        "btc = usholidays[usholidays.date.dt.weekday < 5]\n",
        "\n",
        "#Set 'date' column as index\n",
        "btc.set_index('date', inplace = True)\n",
        "\n",
        "btc"
      ],
      "metadata": {
        "id": "z2i2hsa_DPOz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#import US holiday calender\n",
        "from pandas.tseries.holiday import USFederalHolidayCalendar as calendar\n",
        "\n",
        "#Set period between start and end date in dataframe to identify and remove holidays\n",
        "holidays = calendar().holidays(start='2009-01-05', end='2022-05-24') \n",
        "m = raw_data['date'].isin(holidays)\n",
        "usholidays = raw_data[~m].copy()\n",
        "\n",
        "#print new dataframe with holidays removed\n",
        "usholidays"
      ],
      "metadata": {
        "id": "CBI8-xSAAoRb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create Timeseries with random values"
      ],
      "metadata": {
        "id": "adzm0zEb1OBS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Import liabraries\n",
        "from pandas.tseries.holiday import USFederalHolidayCalendar\n",
        "from pandas.tseries.offsets import CustomBusinessDay\n",
        "\n",
        "#Set variable for US holidays\n",
        "usb = CustomBusinessDay(calendar = USFederalHolidayCalendar())\n",
        "\n",
        "#Period between start and end date in data to remove non business days\n",
        "rng = pd.date_range('2009-01-05', '2022-05-24', freq=usb)\n",
        "\n",
        "#Print timeseries\n",
        "rng"
      ],
      "metadata": {
        "id": "fC_diBNHoY-a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Set index as 'date' column\n",
        "df1 = rng.to_frame(index = True)\n",
        "\n",
        "#Add OHLC and Volume columns and fill with integer values \n",
        "df1['high'] = 0\n",
        "df1['open'] = 0\n",
        "df1['low'] = 0\n",
        "df1['close'] = 0\n",
        "df1['volume'] = 0\n",
        "\n",
        "#Drop date column\n",
        "df1.drop(df1.columns[[0]], axis = 1, inplace = True)\n",
        "\n",
        "\n",
        "#Reset index and pass data2 variable as new dataframe\n",
        "data2 = df1.reset_index()\n",
        "\n",
        "\n",
        "#Rename date column from 'time' to 'date'\n",
        "df_new = data2.rename(columns={'index': 'date'}, index=None)\n",
        "\n",
        "print(df_new.head(5))\n",
        "df_new.info()"
      ],
      "metadata": {
        "id": "9qxMLQm77QzM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#save dataframe to csv. File name is the date and time it was saved/created\n",
        "df_new.to_csv('/content/drive/MyDrive/Colab Notebooks/My Project Folder/crypto/Random Data/300620222306.csv')"
      ],
      "metadata": {
        "id": "bnsrtKgU4dsg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Load csv. Variable name is the date and time the csv file was loaded\n",
        "dodge = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/My Project Folder/crypto/crypto weekday data/DODGE_weekday.csv')\n",
        "\n",
        "print(dodge)\n",
        "test300620221107 = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/My Project Folder/crypto/crypto weekday data/DODGE_weekday.csv')\n",
        "\n",
        "print(test300620221107)"
      ],
      "metadata": {
        "id": "H_TjjhGScIhc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}