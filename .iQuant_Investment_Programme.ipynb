{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Zipline_Reloaded_BacktestEngine.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/francoishcm/BackTesting/blob/master/.iQuant_Investment_Programme.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üß∞**INSTALL MODULES**"
      ],
      "metadata": {
        "id": "xRTs1_SK0Scj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive \n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "ABrWrt1q06gq",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1tlwk44QhErd"
      },
      "source": [
        "# Install ta-lib v0.4.0\n",
        "%%bash\n",
        "wget http://prdownloads.sourceforge.net/ta-lib/ta-lib-0.4.0-src.tar.gz\n",
        "tar -xzf ta-lib-0.4.0-src.tar.gz\n",
        "cd ta-lib/\n",
        "./configure\n",
        "make\n",
        "make install"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JSwN3Ywihz3r",
        "collapsed": true
      },
      "source": [
        "# Install zipline\n",
        "%pip install zipline-reloaded"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install iso3166==2.0.2"
      ],
      "metadata": {
        "id": "w2cgjqTU8TKt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Install Pyfolio\n",
        "!pip install pyfolio-reloaded"
      ],
      "metadata": {
        "id": "m-y07xfPTFVK",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Install matplot library\n",
        "!pip install matplotlib"
      ],
      "metadata": {
        "collapsed": true,
        "id": "zoV1_FSc_5MW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Install data bundle 'Quandl'\n",
        "!pip install quandl"
      ],
      "metadata": {
        "collapsed": true,
        "id": "8-pgTCGp2XzF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import zipline\n",
        "zipline.__version__"
      ],
      "metadata": {
        "id": "C9erwAEdVunF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import IPython\n",
        "js_code = '''\n",
        "document.querySelector(\"#output-area\").appendChild(document.createTextNode(\"hello world!\"));\n",
        "'''\n",
        "display(IPython.display.Javascript(js_code))"
      ],
      "metadata": {
        "id": "m6GVOvJnXPQr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nasdaq-data-link"
      ],
      "metadata": {
        "id": "jjqASrBOT4Rc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üíΩ**SET WORKING DIRECTORY**"
      ],
      "metadata": {
        "id": "4Ixua2eyz0Hr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os \n",
        "\n",
        "# Set your working directory to a folder in your Google Drive. This way, if your notebook times out,\n",
        "# your files will be saved in your Google Drive!\n",
        "\n",
        "# the base Google Drive directory\n",
        "root_dir = \"/content/drive/\"\n"
      ],
      "metadata": {
        "id": "eWtZZXQol34j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os \n",
        "\n",
        "# Set your working directory to a folder in your Google Drive. This way, if your notebook times out,\n",
        "# your files will be saved in your Google Drive!\n",
        "\n",
        "\n",
        "# choose where you want your project files to be saved\n",
        "project_folder = \"MyDrive/Colab Notebooks/My Project Folder\"\n"
      ],
      "metadata": {
        "id": "c4jxNssSmApK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_and_set_working_directory(project_folder):\n",
        "  # check if your project folder exists. if not, it will be created.\n",
        "  if os.path.isdir(root_dir + project_folder) == False:\n",
        "    os.mkdir(root_dir + project_folder)\n",
        "    print(root_dir + project_folder + ' did not exist but was created.')\n",
        "\n",
        "  # change the OS to use your project folder as the working directory\n",
        "  os.chdir(root_dir + project_folder)\n",
        "\n",
        "  # create a test file to make sure it shows up in the right place\n",
        "  !touch 'new_file_in_working_directory.txt'\n",
        "  print('\\nYour working directory was changed to ' + root_dir + project_folder + \\\n",
        "        \"\\n\\nAn empty text file was created there. You can also run !pwd to confirm the current working directory.\" )\n",
        "\n",
        "create_and_set_working_directory(project_folder)"
      ],
      "metadata": {
        "id": "Y0PGKB_SmAR5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Confirm current working directory\n",
        "!pwd"
      ],
      "metadata": {
        "id": "Q4_HSs4HneUa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "for f in os.listdir(\"//content/drive/MyDrive/Colab Notebooks/My Project Folder\"):\n",
        "\tprint(f)"
      ],
      "metadata": {
        "id": "8HB8gDZGqsfB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ‚è≥**INGEST DATA**"
      ],
      "metadata": {
        "id": "z5Y1KYNHeqeu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ingest custom bundle\n",
        "!zipline ingest --bundle 'crypto'"
      ],
      "metadata": {
        "id": "CvMaJ1U1eVhB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ingest custom bundle\n",
        "!zipline ingest --bundle 'equities_csvdir'"
      ],
      "metadata": {
        "id": "okd6vU6j5iPt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ingest custom bundle\n",
        "!zipline ingest --bundle 'random_futures_data'"
      ],
      "metadata": {
        "id": "1tKhQWGK5Z8T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ingest custom bundle\n",
        "!zipline ingest --bundle 'random_stock_data'"
      ],
      "metadata": {
        "id": "lvSZVAHNJDW4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "INGEST QUANDL STOCK BUNDLE\n",
        "'''\n",
        "# Ingest bundle API\n",
        "!QUANDL_API_KEY=KUnssHvVERHb5XYu9C1- zipline ingest -b 'quandl'"
      ],
      "metadata": {
        "id": "KiUF_IBQCSlm",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Confirm existing bundles\n",
        "!zipline bundles"
      ],
      "metadata": {
        "id": "Ol2e01cH_O3z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# clean everything older than <date>\n",
        "!zipline clean -b crypto --after 2022-04-13"
      ],
      "metadata": {
        "id": "mzYjOy4meAx3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üìä**ANDREAS CLENOW MODELS**"
      ],
      "metadata": {
        "id": "r6pHOCkwUJOo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Clenow Momentum Model**\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "EHQUpvbK0RNj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "%matplotlib inline\n",
        "\n",
        "import zipline\n",
        "from zipline import run_algorithm\n",
        "from zipline.api import order_target_percent, symbol, set_commission, set_slippage, schedule_function, date_rules, time_rules\n",
        "from pandas import Timestamp\n",
        "from datetime import datetime\n",
        "import pytz\n",
        "import matplotlib.pyplot as plt \n",
        "import pyfolio as pf\n",
        "import pandas as pd \n",
        "import numpy as np \n",
        "from scipy import stats\n",
        "from zipline.finance.commission import PerDollar\n",
        "from zipline.finance.slippage import VolumeShareSlippage, FixedSlippage\n",
        "\n",
        "#Model Settings\n",
        "\n",
        "intial_portfolio = 100000\n",
        "momentum_window = 125\n",
        "minimum_momentum = 40\n",
        "portfolio_size = 30\n",
        "vola_window = 20\n",
        "\n",
        "#Commission and Slippage Settings\n",
        "\n",
        "enable_commission = True \n",
        "commission_pct = 0.001 \n",
        "enable_slippage = True \n",
        "slippage_volume_limit = 0.025\n",
        "slippage_impact = 0.05\n",
        "\n",
        "def momentum_score(ts):\n",
        "\n",
        "  #Input: Price time series.Output: Annualized exponential regression slope, multiplied by the R2\n",
        "\n",
        "  # Make a list of consecutive numbers \n",
        "  x = np.arange(len(ts))\n",
        "  # Get logs\n",
        "  log_ts = np.log(ts)\n",
        "  # Calculate regression values\n",
        "  slope, intercept, r_value, p_value, std_err = stats.linregress(x, log_ts) \n",
        "  # Annualize percent\n",
        "  annualized_slope = (np.power(np.exp(slope), 252) - 1) * 100 \n",
        "  #Adjust for fitness\n",
        "  score = annualized_slope * (r_value ** 2) \n",
        "  return score\n",
        "\n",
        "def volatility(ts):\n",
        "  return ts.pct_change().rolling(vola_window).std().iloc[-1]\n",
        "\n",
        "def output_progress(context):\n",
        "\n",
        "  #Output some performance numbers during backtest run \n",
        "  #This code just prints out the past month's performance,\n",
        "  # so that we have something to look at while the backtest runs.\n",
        "\n",
        "  # Get today's date\n",
        "  today = zipline.api.get_datetime().date()\n",
        "\n",
        "  # Calculate percent difference since last month\n",
        "  perf_pct = (context.portfolio.portfolio_value / context.last_month) - 1\n",
        "\n",
        "  # Print performance, format as percent with two decimals. \n",
        "  print(\"{} - Last Month Result: {:.2%}\".format(today, perf_pct))\n",
        "\n",
        "  # Remember today's portfolio value for next month's calculation \n",
        "  context.last_month = context.portfolio.portfolio_value\n",
        "\n",
        "#Initialization and trading logic\n",
        "\n",
        "\n",
        "def initialize(context):\n",
        "\n",
        "  # Set commission and slippage.\n",
        "  if enable_commission:\n",
        "    comm_model = PerDollar(cost=commission_pct) \n",
        "  else:\n",
        "    comm_model = PerDollar(cost=0.0) \n",
        "  set_commission(comm_model)\n",
        "  if enable_slippage: slippage_model=VolumeShareSlippage(volume_limit=slippage_volume_limit,\n",
        "price_impact=slippage_impact) \n",
        "  else:\n",
        "    slippage_model=FixedSlippage(spread=0.0) \n",
        "  set_slippage(slippage_model)\n",
        "\n",
        "  # Used only for progress output. \n",
        "  context.last_month = intial_portfolio\n",
        "\n",
        "  # Store index membership\n",
        "  context.index_members = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/My Project Folder/index members/sp500.csv', engine='python', error_bad_lines=False)\n",
        "\n",
        "\n",
        "  #Schedule rebalance monthly. \n",
        "  schedule_function(\n",
        "    func=rebalance, \n",
        "    date_rule=date_rules.month_start(), \n",
        "    time_rule=time_rules.market_open()\n",
        "  )\n",
        "\n",
        "def rebalance(context, data):\n",
        "  # Write some progress output during the backtest \n",
        "  output_progress(context)\n",
        "\n",
        "  # First, get today's date\n",
        "  today = zipline.api.get_datetime().date()\n",
        "\n",
        "  # Second, get the index makeup for all days prior to today.\n",
        "  all_prior = context.index_members.loc[context.index_members.index < today]\n",
        "\n",
        "  todays_universe = [ \n",
        "    symbol(ticker) for ticker in\n",
        "    context.index_members.loc[context.index_members.index < today].iloc[-1,0].split(',')\n",
        "  ]\n",
        "\n",
        "  # Get historical data\n",
        "  hist = data.history(todays_universe, \"close\", momentum_window, \"1d\")\n",
        "\n",
        "  # Make momentum ranking table\n",
        "  ranking_table = hist.apply(momentum_score).sort_values(ascending=False)\n",
        "\n",
        "  #Sell Logic\n",
        "  #First we check if any existing position should be sold.\n",
        "    #Sell if stock is no longer part of index.\n",
        "    #Sell if stock has too low momentum value.\n",
        "\n",
        "  kept_positions = list(context.portfolio.positions.keys()) \n",
        "  for security in context.portfolio.positions:\n",
        "    if (security not in todays_universe): \n",
        "      order_target_percent(security, 0.0) \n",
        "      kept_positions.remove(security)\n",
        "    elif ranking_table[security] < minimum_momentum: \n",
        "      order_target_percent(security, 0.0) \n",
        "      kept_positions.remove(security)\n",
        "\n",
        "  #Stock Selection Logic\n",
        "  #Check how many stocks we are keeping from last month.\n",
        "  #Fill from top of ranking list, until we reach the desired total number of portfolio holdings.\n",
        "\n",
        "  replacement_stocks = portfolio_size - len(kept_positions) \n",
        "  buy_list = ranking_table.loc[\n",
        "    ~ranking_table.index.isin(kept_positions)][:replacement_stocks]\n",
        "  new_portfolio = pd.concat(\n",
        "    (buy_list,\n",
        "    ranking_table.loc[ranking_table.index.isin(kept_positions)])\n",
        "  )\n",
        "  buy_list = ranking_table.loc[\n",
        "    ~ranking_table.index.isin(kept_positions)][:replacement_stocks]\n",
        "\n",
        "  #Calculate inverse volatility for stocks, and make target position weights.\n",
        "\n",
        "  vola_table = hist[new_portfolio.index].apply(volatility) \n",
        "  inv_vola_table = 1 / vola_table\n",
        "  sum_inv_vola = np.sum(inv_vola_table) \n",
        "  vola_target_weights = inv_vola_table / sum_inv_vola\n",
        "  for security, rank in new_portfolio.iteritems(): \n",
        "    weight = vola_target_weights[security]\n",
        "    if security in kept_positions:\n",
        "      order_target_percent(security, weight)\n",
        "    else:\n",
        "      if ranking_table[security] > minimum_momentum: \n",
        "        order_target_percent(security, weight)\n",
        "\n",
        "def analyze(context, perf):\n",
        "  perf['max'] = perf.portfolio_value.cummax() \n",
        "  perf['dd'] = (perf.portfolio_value / perf['max']) - 1 \n",
        "  maxdd = perf['dd'].min()\n",
        "\n",
        "  ann_ret = (np.power((perf.portfolio_value.iloc[-1] / perf.portfolio_value.iloc[0]),(252 / len(perf)))) - 1\n",
        "\n",
        "  print(\"Annualized Return: {:.2%} Max Drawdown: {:.2%}\".format(ann_ret, maxdd))\n",
        "\n",
        "  return\n",
        "'''\n",
        "start = datetime(1997, 1, 1, 8, 15, 12, 0, pytz.UTC)\n",
        "end = datetime(2018, 12, 31, 8, 15, 12, 0, pytz.UTC)\n",
        "'''\n",
        "\n",
        "start = pd.Timestamp('1997-1-1', tz='utc')\n",
        "end = pd.Timestamp('2018-12-31', tz='utc')\n",
        "\n",
        "perf = zipline.run_algorithm(start=start, end=end, \n",
        "                             initialize=initialize, \n",
        "                             analyze=analyze, \n",
        "                             capital_base=intial_portfolio, \n",
        "                             data_frequency = 'daily', \n",
        "                             bundle='quandl' )"
      ],
      "metadata": {
        "id": "6aRGAkzKLH88",
        "collapsed": true,
        "cellView": "code"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Clenow Trend Model**"
      ],
      "metadata": {
        "id": "x83jcz1QUFDe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "%matplotlib inline\n",
        "\n",
        "import zipline\n",
        "from zipline.api import future_symbol,  \\\n",
        "    set_commission, set_slippage, schedule_function, date_rules, \\\n",
        "    time_rules, continuous_future, order_target\n",
        "from pandas import Timestamp\n",
        "import pytz\n",
        "import datetime as datetime\n",
        "import matplotlib.pyplot as plt\n",
        "import pyfolio as pf\n",
        "import pandas as pd\n",
        "import numpy as np  \n",
        "from zipline.finance.commission import PerTrade, PerContract\n",
        "from zipline.finance.slippage import VolumeShareSlippage, \\\n",
        "    FixedSlippage, VolatilityVolumeShare\n",
        "\n",
        "# These lines are for the dynamic text reporting\n",
        "from IPython.display import display\n",
        "import ipywidgets as widgets\n",
        "out = widgets.HTML()\n",
        "display(out)\n",
        "\n",
        "\"\"\"\n",
        "Model Settings\n",
        "\"\"\"\n",
        "starting_portfolio = 50000000\n",
        "risk_factor = 0.0015\n",
        "stop_distance = 3\n",
        "breakout_window = 50\n",
        "vola_window = 40\n",
        "slow_ma = 80\n",
        "fast_ma = 40\n",
        "enable_commission = True\n",
        "enable_slippage = True  \n",
        "\n",
        "\n",
        "def report_result(context, data):\n",
        "    context.months += 1\n",
        "    today = zipline.api.get_datetime().date()\n",
        "    # Calculate annualized return so far\n",
        "    ann_ret = np.power(context.portfolio.portfolio_value / starting_portfolio, \n",
        "                   12 / context.months) - 1\n",
        "    \n",
        "    # Update the text\n",
        "    out.value = \"\"\"{} We have traded <b>{}</b> months \n",
        "    and the annualized return is <b>{:.2%}</b>\"\"\".format(today, context.months, ann_ret)\n",
        "\n",
        "def roll_futures(context, data):\n",
        "    open_orders = zipline.api.get_open_orders()\n",
        "    \n",
        "    for held_contract in context.portfolio.positions:\n",
        "        # don't roll positions that are set to change by core logic\n",
        "        if held_contract in open_orders: \n",
        "            continue\n",
        "        \n",
        "        # Save some time by only checking rolls for\n",
        "        # contracts stopping trading in the next days\n",
        "        days_to_auto_close = (\n",
        "            held_contract.auto_close_date.date() - data.current_session.date()\n",
        "        ).days\n",
        "        if days_to_auto_close > 5:\n",
        "            continue        \n",
        "        \n",
        "        # Make a continuation\n",
        "        continuation = continuous_future(\n",
        "                held_contract.root_symbol, \n",
        "                offset=0, \n",
        "                roll='volume', \n",
        "                adjustment='mul'\n",
        "                )\n",
        "        \n",
        "        # Get the current contract of the continuation\n",
        "        continuation_contract = data.current(continuation, 'contract')\n",
        "        \n",
        "        if continuation_contract != held_contract:\n",
        "            # Check how many contracts we hold\n",
        "            pos_size = context.portfolio.positions[held_contract].amount         \n",
        "            # Close current position\n",
        "            order_target(held_contract, 0)\n",
        "            # Open new position\n",
        "            order_target(continuation_contract, pos_size)     \n",
        "            \n",
        "def position_size(portfolio_value, std, point_value):\n",
        "    target_variation = portfolio_value * risk_factor\n",
        "    contract_variation = std * point_value\n",
        "    contracts = target_variation / contract_variation\n",
        "    return int(np.nan_to_num(contracts)) \n",
        "    \n",
        "def initialize(context):\n",
        "    \n",
        "    \"\"\"\n",
        "    Cost Settings\n",
        "    \"\"\"\n",
        "    if enable_commission:\n",
        "        comm_model = PerContract(cost=0.85, exchange_fee=1.5)\n",
        "    else:\n",
        "        comm_model = PerTrade(cost=0.0)\n",
        "        \n",
        "    set_commission(us_futures=comm_model)\n",
        "    \n",
        "    if enable_slippage:\n",
        "        slippage_model=VolatilityVolumeShare(volume_limit=0.2)\n",
        "    else:\n",
        "        slippage_model=FixedSlippage(spread=0.0)      \n",
        "        \n",
        "    set_slippage(us_futures=slippage_model)\n",
        "    \n",
        "    \"\"\"\n",
        "    Markets to trade\n",
        "    \"\"\" \n",
        "    currencies = [\n",
        "        'AD',\n",
        "        'BP',\n",
        "        'CD',\n",
        "        'CU',\n",
        "        'DX',\n",
        "        'JY',\n",
        "        'NE',\n",
        "        'SF',\n",
        "    ]\n",
        "    \n",
        "    agricultural = [\n",
        "        '_C',\n",
        "        'CT',\n",
        "        'FC',\n",
        "        'KC',\n",
        "        'LR',\n",
        "        'LS',\n",
        "        '_O',\n",
        "        '_S',\n",
        "        'SB',\n",
        "        'SM',\n",
        "        '_W',\n",
        "    ]\n",
        "    nonagricultural = [\n",
        "        'CL',\n",
        "        'GC',\n",
        "        'HG',\n",
        "        'HO',\n",
        "        'LG',\n",
        "        'NG',\n",
        "        'PA',\n",
        "        'PL',\n",
        "        'RB',\n",
        "        'SI',\n",
        "    ]\n",
        "    equities = [\n",
        "        'ES',\n",
        "        'NK',\n",
        "        'NQ',\n",
        "        'TW',\n",
        "        'VX',\n",
        "        'YM',\n",
        "    ]\n",
        "    rates = [\n",
        "        'ED',\n",
        "        'FV',\n",
        "        'TU',\n",
        "        'TY',\n",
        "        'US',\n",
        "    ]\n",
        "    \n",
        "    # Make a list of all the markets\n",
        "    markets = currencies + agricultural + nonagricultural + equities + rates\n",
        "    \n",
        "    # Make a list of all continuations\n",
        "    context.universe = [\n",
        "        continuous_future(market, offset=0, roll='volume', adjustment='mul')\n",
        "            for market in markets\n",
        "    ]\n",
        "    \n",
        "    # We'll use these to keep track of best position reading\n",
        "    # Used to calculate stop points.\n",
        "    context.highest_in_position = {market: 0 for market in markets} \n",
        "    context.lowest_in_position = {market: 0 for market in markets}    \n",
        "    \n",
        "    # Schedule the daily trading\n",
        "    schedule_function(daily_trade, date_rules.every_day(), time_rules.market_close())\n",
        "    \n",
        "    # We'll just use this for the progress output\n",
        "    # during the backtest. Doesn't impact anything.\n",
        "    context.months = 0    \n",
        "    \n",
        "    # Schedule monthly report output\n",
        "    schedule_function(\n",
        "        func=report_result,\n",
        "        date_rule=date_rules.month_start(),\n",
        "        time_rule=time_rules.market_open()\n",
        "    ) \n",
        "    \n",
        "def analyze(context, perf):\n",
        "    returns, positions, transactions = pf.utils.extract_rets_pos_txn_from_zipline(perf)\n",
        "    pf.create_returns_tear_sheet(returns, benchmark_rets=None)\n",
        "    \n",
        "def daily_trade(context, data):\n",
        "    # Get continuation data\n",
        "    hist = data.history(\n",
        "        context.universe, \n",
        "        fields=['close','volume'], \n",
        "        frequency='1d', \n",
        "        bar_count=250,\n",
        "    )\n",
        "    \n",
        "    # Calculate trend\n",
        "    hist['trend'] = hist['close'].ewm(span=fast_ma).mean() > hist['close'].ewm(span=slow_ma).mean()    \n",
        "    \n",
        "    # Make dictionary of open positions\n",
        "    open_pos = {\n",
        "        pos.root_symbol: pos \n",
        "        for pos in context.portfolio.positions\n",
        "    } \n",
        "    \n",
        "    # Iterate markets, check for trades\n",
        "    for continuation in context.universe:\n",
        "        \n",
        "        # Get root symbol of continuation\n",
        "        root = continuation.root_symbol\n",
        "        \n",
        "        # Slice off history for just this market\n",
        "        h = hist.xs(continuation, 2)\n",
        "        \n",
        "        # Get standard deviation\n",
        "        std = h.close.diff()[-vola_window:].std()\n",
        "\n",
        "        if root in open_pos: # Position is open\n",
        "\n",
        "            # Get position\n",
        "            p = context.portfolio.positions[open_pos[root]]\n",
        "            \n",
        "            if p.amount > 0: # Position is long\n",
        "                if context.highest_in_position[root] == 0: # First day holding the position\n",
        "                    context.highest_in_position[root] = p.cost_basis\n",
        "                else:\n",
        "                    context.highest_in_position[root] = max(\n",
        "                        h['close'].iloc[-1], context.highest_in_position[root]\n",
        "                    ) \n",
        "                    \n",
        "                # Calculate stop point\n",
        "                stop = context.highest_in_position[root] - (std  * stop_distance)\n",
        "                # Check if stop is hit\n",
        "                if h.iloc[-1]['close'] < stop:\n",
        "                    contract = open_pos[root]\n",
        "                    order_target(contract, 0)\n",
        "                    context.highest_in_position[root] = 0\n",
        "                # Check if trend has flipped\n",
        "                elif h['trend'].iloc[-1] == False:\n",
        "                    contract = open_pos[root]\n",
        "                    order_target(contract, 0)\n",
        "                    context.highest_in_position[root] = 0\n",
        "                    \n",
        "            else: # Position is short\n",
        "                if context.lowest_in_position[root] == 0: # First day holding the position\n",
        "                    context.lowest_in_position[root] = p.cost_basis\n",
        "                else:\n",
        "                    context.lowest_in_position[root] = min(\n",
        "                        h['close'].iloc[-1], context.lowest_in_position[root]\n",
        "                    )\n",
        "                \n",
        "                # Calculate stop point\n",
        "                stop = context.lowest_in_position[root] + (std  * stop_distance)\n",
        "                \n",
        "                # Check if stop is hit\n",
        "                if h.iloc[-1]['close'] > stop:\n",
        "                    contract = open_pos[root]\n",
        "                    order_target(contract, 0)\n",
        "                    context.lowest_in_position[root] = 0\n",
        "                # Check if trend has flipped\n",
        "                elif h['trend'].iloc[-1] == True:\n",
        "                    contract = open_pos[root]\n",
        "                    order_target(contract, 0)\n",
        "                    context.lowest_in_position[root] = 0                         \n",
        "        \n",
        "        else: # No position on\n",
        "            if h['trend'].iloc[-1]: # Bull trend\n",
        "                # Check if we just made a new high\n",
        "                if h['close'][-1] == h[-breakout_window:]['close'].max(): \n",
        "                    contract = data.current(continuation, 'contract')\n",
        "\n",
        "                    contracts_to_trade = position_size( \\\n",
        "                                                       context.portfolio.portfolio_value, \\\n",
        "                                                       std, \\\n",
        "                                                       contract.price_multiplier)\n",
        "                    \n",
        "                    # Limit size to 20% of avg. daily volume\n",
        "                    contracts_cap = int(h['volume'][-20:].mean() * 0.2)\n",
        "                    contracts_to_trade = min(contracts_to_trade, contracts_cap)\n",
        "                    \n",
        "                    # Place the order\n",
        "                    order_target(contract, contracts_to_trade)\n",
        "             \n",
        "            else: # Bear trend\n",
        "                # Check if we just made a new low\n",
        "                if h['close'][-1] == h[-breakout_window:]['close'].min(): \n",
        "                    contract = data.current(continuation, 'contract')\n",
        "\n",
        "                    contracts_to_trade = position_size( \\\n",
        "                                                       context.portfolio.portfolio_value, \\\n",
        "                                                       std, \\\n",
        "                                                       contract.price_multiplier)\n",
        "                    \n",
        "                    # Limit size to 20% of avg. daily volume\n",
        "                    contracts_cap = int(h['volume'][-20:].mean() * 0.2)\n",
        "                    contracts_to_trade = min(contracts_to_trade, contracts_cap)\n",
        "                    \n",
        "                    # Place the order\n",
        "                    order_target(contract, -1 * contracts_to_trade)\n",
        "    \n",
        "    # If we have open positions, check for rolls\n",
        "    if len(open_pos) > 0:   \n",
        "        roll_futures(context, data)                \n",
        "                        \n",
        "\n",
        "start = pd.Timestamp('2003-01-01', tz='utc')\n",
        "end = pd.Timestamp('2017-12-31', tz='utc')\n",
        "\n",
        "perf = zipline.run_algorithm(\n",
        "    start=start, end=end, \n",
        "    initialize=initialize, \n",
        "    analyze=analyze,\n",
        "    capital_base=starting_portfolio,  \n",
        "    data_frequency = 'daily', \n",
        "    bundle='random_futures_data' ) \n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "sponWV8ZKDJv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### üíª**MODEL TESTING**"
      ],
      "metadata": {
        "id": "8gWXJGjGBDbs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **DATA CLEANING**\n",
        "\n"
      ],
      "metadata": {
        "id": "wOl0psqAtAal"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Futures"
      ],
      "metadata": {
        "id": "leJ4xVj0cUmi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import modules\n",
        "import nasdaqdatalink\n",
        "import quandl\n",
        "# Get the data for Futures, Continuous Contract #6.\n",
        "import matplotlib.pyplot as plt\n",
        "data = quandl.get(\"CHRIS/CME_YM1\",start_date=\"2017-12-03\", end_date=\"2018-12-03\", api_key='WDDHaLh3eG6vrEgiCCqy')"
      ],
      "metadata": {
        "id": "RC5tgJ5vmc7a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the prices\n",
        "data.Settle.plot()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "84lZG881mitG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#import required libraries\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "import numpy as np\n",
        "\n",
        "data = data.rename(columns={'Open': 'open','High':'high',\n",
        "                                'Low':'low','Last':'close',\n",
        "                                'Volume':'volume','Previous Day Open Interest': 'openinterest'}, index=None)\n",
        "\n",
        "data['expiration_date'] = '2018-12-21'\n",
        "data['root_symbol'] = 'YM'\n",
        "data['symbol'] = 'YMZ18'\n",
        "\n",
        "new_data = data.drop(['Change', 'Settle',], axis=1)\n",
        "\n",
        "print(new_data.head())\n",
        "\n"
      ],
      "metadata": {
        "id": "6aDFt_ctctAx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_data.to_csv('/content/drive/MyDrive/Colab Notebooks/My Project Folder/Futures/YMZ18.csv')"
      ],
      "metadata": {
        "id": "U-luxklmprlL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Digital assets"
      ],
      "metadata": {
        "id": "j9Isr0HFaAKD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Adjusting model performace csv data for comparison"
      ],
      "metadata": {
        "id": "xkG3Yi2EHM4P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "A = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/My Project Folder/Backtests/Raw Model Performance Data/Digital Assets/crypto_momentum.csv', parse_dates=True, index_col=0)\n",
        "\n",
        "A.index = A.index.strftime('%Y/%m/%d')\n",
        "\n",
        "header_row = 1\n",
        "\n",
        "A.columns = A.iloc[header_row]\n",
        "\n",
        "A"
      ],
      "metadata": {
        "id": "HkR-LQr5HUfA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "A.info()"
      ],
      "metadata": {
        "id": "dwSpgXWbjPHq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "A.to_csv('/content/drive/MyDrive/Colab Notebooks/My Project Folder/Backtests/crypto_momentum_2.csv')\n"
      ],
      "metadata": {
        "id": "zpol9KKPOz0m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Adjusting crypto indices csv data for comparison"
      ],
      "metadata": {
        "id": "xcAQevGKs8jc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#import required libraries\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "import exchange_calendars as xcals\n",
        "from zipline import get_calendar\n",
        "import numpy as np\n",
        "\n",
        "df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/My Project Folder/crypto/indices/SPCBDM.csv', encoding='cp1252')\n",
        "df.info()\n",
        "print(df)"
      ],
      "metadata": {
        "id": "Ui2xKWSwvQsK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "df.drop([1355],axis=0, inplace = True )\n",
        "\n",
        "#Convert 'date' Column to datetime\n",
        "df['2/28/2017'] = pd.to_datetime(df['2/28/2017'], utc=True)\n",
        "\n",
        "#Set 'date' column as index\n",
        "df.set_index('2/28/2017', inplace=True)\n",
        "\n",
        "# Get all expected trading sessions in new dataframe.\n",
        "sessions = get_calendar('NYSE').sessions_in_range('2017-02-28', '2022-05-05')\n",
        "\n",
        "df.index = df.index.strftime('%Y/%m/%d')\n",
        "\n",
        "header_row = 1\n",
        "\n",
        "df.columns = df.iloc[header_row]\n",
        "\n",
        "df.tail(5)\n",
        "df.info()\n",
        "df"
      ],
      "metadata": {
        "id": "ccCas1-YyplH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df[~df.index.duplicated()]\n",
        "df"
      ],
      "metadata": {
        "id": "6_L-MWp3pbMV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv('/content/drive/MyDrive/Colab Notebooks/My Project Folder/Backtests/SPCBDM_test3.csv')"
      ],
      "metadata": {
        "id": "YxGN_p0ckuRC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Removing weekends from timeseries"
      ],
      "metadata": {
        "id": "wyel-4htJj0U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "#Import statements\n",
        "%matplotlib inline\n",
        "import pandas as pd\n",
        "import datetime as dt\n",
        "import numpy as np\n",
        "\n",
        "#Load csv file from disc\n",
        "df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/My Project Folder/crypto/crypto_data/DOGE.csv')\n",
        "\n",
        "#Set date column to datetime\n",
        "df['time'] = pd.to_datetime(df['time'], errors='coerce')\n",
        "\n",
        "#Remove weekends from data\n",
        "df = df[df.time.dt.weekday < 5]\n",
        "\n",
        "#Set 'date' columns as Index\n",
        "df.set_index(\"time\", inplace = True)\n",
        "\n",
        "#display weekday dataframe\n",
        "df\n"
      ],
      "metadata": {
        "id": "LcR4uk8SJ3mT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#inspect dataframe\n",
        "df.info()"
      ],
      "metadata": {
        "id": "b2HfyHCXUYBR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Save dataframe to csv\n",
        "\n",
        "df.to_csv('/content/drive/MyDrive/Colab Notebooks/My Project Folder/crypto/crypto weekday data/DODGE_weekday.csv')"
      ],
      "metadata": {
        "id": "t91Kk-vQRL8Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Load final data to file to dataframe\n",
        "dodge = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/My Project Folder/crypto/crypto weekday data/DODGE_weekday.csv')\n",
        "\n",
        "print(dodge)\n",
        "\n"
      ],
      "metadata": {
        "id": "biKqcgmYUzrI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Remove weekends from dataframe\n",
        "btc = usholidays[usholidays.date.dt.weekday < 5]\n",
        "\n",
        "#Set 'date' column as index\n",
        "btc.set_index('date', inplace = True)\n",
        "\n",
        "btc"
      ],
      "metadata": {
        "id": "z2i2hsa_DPOz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#import US holiday calender\n",
        "from pandas.tseries.holiday import USFederalHolidayCalendar as calendar\n",
        "\n",
        "#Set period between start and end date in dataframe to identify and remove holidays\n",
        "holidays = calendar().holidays(start='2009-01-05', end='2022-05-24') \n",
        "m = raw_data['date'].isin(holidays)\n",
        "usholidays = raw_data[~m].copy()\n",
        "\n",
        "#print new dataframe with holidays removed\n",
        "usholidays"
      ],
      "metadata": {
        "id": "CBI8-xSAAoRb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Adjusting crypto data from **Yahoo Finance** for testing with NYSE trading calender."
      ],
      "metadata": {
        "id": "apiTpYe_fJXQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#import required libraries\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "import exchange_calendars as xcals\n",
        "from zipline import get_calendar\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "62ohBdKTfmjU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/My Project Folder/crypto/yahoo_data/yahoo raw data/BTC-USD.csv', parse_dates=True, index_col=0)\n",
        "\n",
        "# Remove Adj Close Column\n",
        "new_df = df.drop(['Adj Close'], axis=1)\n",
        "\n",
        "new_df[\"Volume\"] = new_df[\"Volume\"].astype(float)\n",
        "\n",
        "#Reset index\n",
        "new_df.reset_index(inplace = True)\n",
        "\n",
        "#Convert 'date' Column to datetime\n",
        "new_df['Date'] = pd.to_datetime(new_df['Date'], utc=True)\n",
        "\n",
        "#Set 'date' column as index\n",
        "new_df.set_index('Date', inplace=True)\n",
        "\n",
        "# Get all expected trading sessions in new dataframe.\n",
        "sessions = get_calendar('NYSE').sessions_in_range('2009-01-05', '2022-07-07')\n",
        "\n",
        "# To set the trading session in  new dataframe to the NYSE Calender\n",
        "btc = new_df.reindex(sessions)\n",
        "\n",
        "#Reset index again to change the index name\n",
        "btc.reset_index(inplace = True)\n",
        "\n",
        "#Rename index column to 'date'\n",
        "btc = btc.rename(columns={'index': 'trading_date'}, index=None)\n",
        "\n",
        "#Change date format to Year-Month-Day\n",
        "btc['trading_date'] =  pd.to_datetime(btc['trading_date']).dt.strftime('%Y-%m-%d')\n",
        "\n",
        "crypto = btc.dropna()\n",
        "\n",
        "#Change 'PriceUSD' columns to 'close'\n",
        "crypto.rename(columns = {'Open':'open',\n",
        "                      'High':'high',\n",
        "                      'Low':'low',\n",
        "                      'Close':'close',\n",
        "                      'Volume':'volume'}, inplace = True)\n",
        "\n",
        "crypto.set_index('trading_date', inplace=True)\n",
        "\n",
        "crypto.info()\n",
        "\n",
        "crypto.to_csv('/content/drive/MyDrive/Colab Notebooks/My Project Folder/crypto/yahoo_data/yahoo cleaned data/btc.csv')\n",
        "\n",
        "crypto"
      ],
      "metadata": {
        "id": "9Zw_h3y8fQBV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Adjusting crypto data from **Coinmetrics** for testing with NYSE trading calender."
      ],
      "metadata": {
        "id": "ZoZBFEZFb1JM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#import required libraries\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "import exchange_calendars as xcals\n",
        "from zipline import get_calendar\n",
        "import numpy as np\n",
        "\n",
        "#load raw data from file\n",
        "raw_data = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/My Project Folder/crypto/coinmetrics_data/btc.csv', parse_dates=True, index_col=0)\n",
        "\n",
        "new = raw_data.drop(raw_data.loc[:, :'PriceBTC'].columns, axis=1)\n",
        "\n",
        "\n",
        "#drop columns not needed. Only closing prices required\n",
        "new.drop(new.iloc[:, 1:76], inplace = True, axis = 1)\n",
        "\n",
        "#Add new columns\n",
        "new['high'] =0\n",
        "new['low'] =0\n",
        "new['open'] =0\n",
        "new['volume'] =0\n",
        "\n",
        "# Rearrange columns to set timestamp as first column\n",
        "new = new[['high','open','low','PriceUSD','volume']]\n",
        "\n",
        "#Change 'PriceUSD' columns to 'close'\n",
        "new.rename(columns = {'PriceUSD':'close'}, inplace = True)\n",
        "\n",
        "\"\"\"\n",
        "#Drop row (date) not needed\n",
        "new=new.drop(['2022-05-25'])\n",
        "\"\"\"\n",
        "\n",
        "#Fill 'close' column with integer values '0'\n",
        "new[\"close\"].fillna(0, inplace=True)\n",
        "\n",
        "#Reset index\n",
        "new.reset_index(inplace = True)\n",
        "\n",
        "#Rename time columns to date\n",
        "new = new.rename(columns={'time': 'date'}, index=None)\n",
        "\n",
        "#Drop all NaN values from dataframe\n",
        "new.dropna()\n",
        "\n",
        "#Convert columns datatype from integer to float\n",
        "new[\"high\"] = new[\"high\"].astype(float)\n",
        "new[\"open\"] = new[\"open\"].astype(float)\n",
        "new[\"low\"] = new[\"low\"].astype(float)\n",
        "new[\"volume\"] = new[\"volume\"].astype(float)\n",
        "\n",
        "#Convert 'date' Column to datetime\n",
        "new['date'] = pd.to_datetime(new['date'], utc=True)\n",
        "\n",
        "#Set 'date' column as index\n",
        "new.set_index('date', inplace=True)\n",
        "\n",
        "# Get all expected trading sessions in new dataframe.\n",
        "sessions = get_calendar('NYSE').sessions_in_range('2009-01-05', '2022-05-24')\n",
        "\n",
        "# To set the trading session in  new dataframe to the NYSE Calender\n",
        "btc = new.reindex(sessions)\n",
        "\n",
        "#Reset index again to change the index name\n",
        "btc.reset_index(inplace = True)\n",
        "\n",
        "#Rename index column to 'date'\n",
        "btc = btc.rename(columns={'index': 'date'}, index=None)\n",
        "\n",
        "#Change date format to Year-Month-Day\n",
        "btc['date'] =  pd.to_datetime(btc['date']).dt.strftime('%Y-%m-%d')\n",
        "\n",
        "\"\"\"\n",
        "btc.set_index('date', inplace=True)\n",
        "\"\"\"\n",
        "\n",
        "# Remove two columns name is 'C' and 'D'\n",
        "df = btc.drop(['high', 'open','low'], axis=1)\n",
        "\n",
        "df['open'] = df['close'] - (0 * df ['close'])\n",
        "df['high'] = df['open'] - (0 * df ['open'])\n",
        "df['low'] = df['high'] - (0 * df ['high'])\n",
        "\n",
        "# Rearrange columns\n",
        "df = df[['date','open','high','low','close','volume']]\n",
        "\n",
        "df.set_index('date', inplace=True)\n",
        "\n",
        "crypto = df.dropna()\n",
        "\n",
        "crypto.to_csv('/content/drive/MyDrive/Colab Notebooks/My Project Folder/crypto/final crypto bundle/btc.csv')\n",
        "\n"
      ],
      "metadata": {
        "id": "UQOZCRgetfon"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DvPNoDDTBsT9",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_yiqje4xB4Be",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "B2kpdW3bC2Ph",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "gDZuhdt9s2dd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Stocks"
      ],
      "metadata": {
        "id": "pkft-F-8W1im"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Construct list of stock tickers from investment universe\n",
        "\n",
        "---\n",
        "\n",
        "MarketStack API\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "NNoqmaaIsxav"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Using the Requests library module data ticker data from MarketStack is extracted\n",
        "\n",
        "and saved to disc in json\n",
        "\n",
        "\"\"\"\n",
        "#import libraries\n",
        "import pandas as pd\n",
        "import json\n",
        "import requests\n",
        "\n",
        "#Pass Market API key as parameter. Investmentment universe limit is 350 stock tickers\n",
        "params = {'access_key': 'e52cf3b93696352e880916f8c8adbf0c',\n",
        "          'limit': 350}\n",
        "\n",
        "#passing http link to requests as saving to variable api_result\n",
        "api_result = requests.get('http://api.marketstack.com/v1/exchanges/XJSE/tickers', params)\n",
        "\n",
        "#extracting data for each ticker in json format by looping through each ticker  in api_result variable\n",
        "api_response = api_result.json()\n",
        "print(f\"Exchange Name = {api_response['data']['name']}\")\n",
        "for ticker in api_response['data']['tickers']:\n",
        "  print(f\"{ticker['name']}: {ticker['symbol']}\")\n",
        "\n",
        "  # Serializing json\n",
        "json_object = json.dumps(api_response, indent=4)\n",
        "\n",
        "# Writing to sample.json\n",
        "with open(\"jse.json\", \"w\") as outfile:\n",
        "    outfile.write(json_object)"
      ],
      "metadata": {
        "id": "DCM0ZmyKXD-p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "json ticker data is loaded from disc and converted to a list type under variable \"Stocks\"\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "# Opening JSON file\n",
        "with open('jse.json', 'r') as openfile:\n",
        " \n",
        "    # Reading from json file\n",
        "    json_object = json.load(openfile)\n",
        "\n",
        "data = pd.json_normalize(json_object[\"data\"][\"tickers\"])\n",
        "\n",
        "# dropping null value columns to avoid errors\n",
        "data.dropna(inplace = True)\n",
        " \n",
        "# new data frame with split value columns\n",
        "new = data[\"symbol\"].str.split(\".\", n = 1, expand = True)\n",
        " \n",
        "# making separate first name column from new data frame\n",
        "data[\"ticker\"]= new[0]\n",
        " \n",
        "# Dropping old Name columns\n",
        "data.drop(columns =[\"has_intraday\",\"has_eod\",\"symbol\"], inplace = True)\n",
        "\n",
        "# dropping null value columns to avoid errors\n",
        "data.dropna(inplace = True)\n",
        "\"\"\"\n",
        "# new data frame with split value columns\n",
        "new = data[\"symbol\"].str.split(\".\", n = 1, expand = True)\n",
        "\"\"\" \n",
        "# making separate first name column from new data frame\n",
        "data[\"ticker\"]= new[0]\n",
        "\"\"\"\n",
        "# Dropping old Name columns\n",
        "data.drop(columns =[\"has_intraday\",\"has_eod\",\"symbol\"], inplace = True)\n",
        "\"\"\"\n",
        "Stocks = data['ticker'].to_list()"
      ],
      "metadata": {
        "id": "ZM4Jq4tcGFWU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "import pandas as pd\n",
        "from urllib.request import urlopen\n",
        "import json\n",
        "html = urlopen('https://api.stockdio.com/data/financial/prices/v1/GetHistoricalPrices?app-key=A48E1C73560044A3B2F9DE240899D274&stockExchange=JSE&symbol=TFG&from=2020-08-24&to=2022-08-25&useAdjusted=false').read()\n",
        "\n",
        "data1 = html.decode('utf-8').replace(\"'\", '\"')\n",
        "\n",
        "data = json.loads(data1)\n",
        "s = json.dumps(data, indent=4)\n",
        "print(s)\n",
        "\n",
        "# Writing to sample.json\n",
        "with open(\"TFG.json\", \"w\") as outfile:\n",
        "    outfile.write(s)"
      ],
      "metadata": {
        "id": "l4LhuzHo8GA-",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "import pandas as pd\n",
        "from urllib.request import urlopen\n",
        "import json\n",
        "html = urlopen('https://api.stockdio.com/data/financial/info/v1/GetIndexInfo?app-key=55E6EB9A851947438E97EB72DE3F02B3&index=SPX').read()\n",
        "\n",
        "data1 = html.decode('utf-8')\n",
        "\n",
        "data = json.loads(data1)\n",
        "s = json.dumps(data, indent=4)\n",
        "print(s)"
      ],
      "metadata": {
        "id": "iIj4QHbtqMXd",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "with open(\"naspers.json\", \"r\") as read_it:\n",
        "     data = json.load(read_it)\n",
        "\n",
        "print (data['data'])"
      ],
      "metadata": {
        "id": "2ds6JJzMWuN1",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "df = pd.read_json('/content/naspers.json')\n",
        "df.drop(['code', 'message','symbol', 'company','exchange'], inplace = True )"
      ],
      "metadata": {
        "id": "-9zeAr_HcQzr",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "df_nested_list = pd.json_normalize(df, record_path = ['data'])"
      ],
      "metadata": {
        "id": "PeDP4_2TZ-yt",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "# Opening JSON file\n",
        "with open('naspers.json', 'r') as openfile:\n",
        " \n",
        "    # Reading from json file\n",
        "    naspers = json.load(openfile)\n",
        " \n",
        "print(naspers)\n",
        "print(type(naspers))"
      ],
      "metadata": {
        "id": "f13i67TR7AkY",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Extract timeseries data\n",
        "\n",
        "---\n",
        "Stockdio API\n"
      ],
      "metadata": {
        "id": "OJ6BqFBxtPGu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "The list of tickers passed in the \"Stocks\" variable passed to\n",
        "extract data for each ticker symbol in the list\n",
        "\n",
        "The data is saved to disc in json\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "import pandas as pd\n",
        "from urllib.request import urlopen\n",
        "import json\n",
        "import requests\n",
        "\n",
        "results = []\n",
        "responses = list()\n",
        "for stock in Stocks:\n",
        "  res = requests.get('https://api.stockdio.com/data/financial/prices/v1/GetHistoricalPrices?app-key=A48E1C73560044A3B2F9DE240899D274&stockExchange=JSE&symbol={}&from=2022-09-06&to=2022-09-13&useAdjusted=false'.format(stock))\n",
        "  \n",
        "  if res.status_code == 200:\n",
        "    results.append(res.json())\n",
        "  else:\n",
        "    print('Request to {} failed'.format(stock))\n",
        "\n",
        "# Serializing json\n",
        "jse_data = json.dumps(results, indent=4)\n",
        "\n",
        "# Writing to sample.json\n",
        "with open(\"jse_data.json\", \"w\") as outfile:\n",
        "    outfile.write(jse_data)"
      ],
      "metadata": {
        "id": "PBwOgR-3eV_n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Normalize data & convert to Dataframe"
      ],
      "metadata": {
        "id": "d2cdcBvstzpd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "The json stocks data is loaded from disc\n",
        "\n",
        "The structute of the data is adjusted and saved to disc\n",
        "as seperate csv files for each stock in the list of tickers\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "# Opening JSON file\n",
        "import json\n",
        "import pandas as pd\n",
        "with open('/content/drive/MyDrive/jse_data.json') as openfile:\n",
        " \n",
        "    # Reading from json file\n",
        "    jse_data = json.load(openfile)\n",
        "\n",
        "jse_df = pd.json_normalize(jse_data)\n",
        "jse_new_df = jse_df.drop([\"status.message\", \"status.code\", \"data.exchange\",\"data.prices.columns\" ], axis = 1, inplace = True)\n",
        "jse_new_df = jse_df.dropna()\n",
        "\n",
        "jse_new_df = jse_new_df.set_index(\"data.symbol\")\n",
        "\n",
        "# then loop\n",
        "for idx in jse_new_df.index:\n",
        "    jse_new_df.loc[[idx]].to_csv(f'/content/drive/MyDrive/JSE_Stocks_2/{idx}.csv')"
      ],
      "metadata": {
        "id": "zibc9_h0DVwV"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Rearrange timeseries by loading csv from disc"
      ],
      "metadata": {
        "id": "S7P8o6ZiZoi7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "The csv files for each stock symbol is loaded from disc\n",
        "\n",
        "The data structure and type is converted to final form for further analyisis\n",
        "i.e. The price and volume columns are converted from integer to float\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "#import liabraries\n",
        "import pandas as pf\n",
        "import datetime as datetime\n",
        "from ast import literal_eval\n",
        "\n",
        "#load file from disc\n",
        "A = pd.read_csv('/content/drive/MyDrive/JSE_Stocks_2/AEL.csv', index_col=0)\n",
        "\n",
        "#create column with new rows and convert timeseries to seperate rows\n",
        "A['data.prices.values'] = A['data.prices.values'].apply(literal_eval)\n",
        "A = A.explode('data.prices.values')\n",
        "A['TimeSeries'] = [','.join(map(str, l)) for l in A['data.prices.values']]\n",
        "\n",
        "#Drop columns not needed\n",
        "Times_Series = A.drop([\"data.company\",\"data.prices.values\",], axis = 1)#, inplace = True)\n",
        "\n",
        "#Split timesseries data in seperate columns: OHLC columns\n",
        "new = Times_Series[\"TimeSeries\"].str.split(\",\", n = 6, expand = True)\n",
        " \n",
        "# making separate first name column from new data frame\n",
        "Times_Series[\"date\"]= new[0]\n",
        "Times_Series[\"open\"]= new[1]\n",
        "Times_Series[\"high\"]= new[2]\n",
        "Times_Series[\"low\"]= new[3]\n",
        "Times_Series[\"close\"]= new[4]\n",
        "Times_Series[\"volume\"]= new[5]\n",
        "\n",
        "# Dropping old Name columns\n",
        "Times_Series.drop(columns =[\"TimeSeries\"], inplace = True)\n",
        "\n",
        "#Convert 'date' Column to datetime\n",
        "Times_Series['date'] = pd.to_datetime(Times_Series['date'], utc=True)\n",
        "\n",
        "#Set 'date' column as index\n",
        "Times_Series.set_index('date', inplace=True)\n",
        "\n",
        "#convert datettime column to string\n",
        "Times_Series.index = Times_Series.index.strftime('%Y/%m/%d')\n",
        "\n",
        "# converting price columns to a string\n",
        "Times_Series['open'] = Times_Series['open'].astype(float)\n",
        "Times_Series['high'] = Times_Series['high'].astype(float)\n",
        "Times_Series['low'] = Times_Series['low'].astype(float)\n",
        "Times_Series['close'] = Times_Series['close'].astype(float)\n",
        "Times_Series['volume'] = Times_Series['volume'].astype(float)\n",
        "\n",
        "# df display\n",
        "AEL = Times_Series\n",
        "AEL"
      ],
      "metadata": {
        "id": "_Sr2-cX8htJi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "outputId": "02b652de-b70e-46ad-923c-dbdd03e5ea37"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            open  high   low  close    volume\n",
              "date                                         \n",
              "2022/09/06  8.98  9.04  8.66   8.70  146851.0\n",
              "2022/09/07  8.97  8.97  8.48   8.60  179102.0\n",
              "2022/09/08  8.75  8.85  8.60   8.85   67140.0\n",
              "2022/09/09  8.85  8.88  8.70   8.79  183329.0\n",
              "2022/09/12  8.73  9.00  8.73   8.84  888350.0\n",
              "2022/09/13  8.85  8.88  8.66   8.70  712353.0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-dc33df1a-9236-4527-80e0-a0de5f4920f3\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>open</th>\n",
              "      <th>high</th>\n",
              "      <th>low</th>\n",
              "      <th>close</th>\n",
              "      <th>volume</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2022/09/06</th>\n",
              "      <td>8.98</td>\n",
              "      <td>9.04</td>\n",
              "      <td>8.66</td>\n",
              "      <td>8.70</td>\n",
              "      <td>146851.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022/09/07</th>\n",
              "      <td>8.97</td>\n",
              "      <td>8.97</td>\n",
              "      <td>8.48</td>\n",
              "      <td>8.60</td>\n",
              "      <td>179102.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022/09/08</th>\n",
              "      <td>8.75</td>\n",
              "      <td>8.85</td>\n",
              "      <td>8.60</td>\n",
              "      <td>8.85</td>\n",
              "      <td>67140.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022/09/09</th>\n",
              "      <td>8.85</td>\n",
              "      <td>8.88</td>\n",
              "      <td>8.70</td>\n",
              "      <td>8.79</td>\n",
              "      <td>183329.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022/09/12</th>\n",
              "      <td>8.73</td>\n",
              "      <td>9.00</td>\n",
              "      <td>8.73</td>\n",
              "      <td>8.84</td>\n",
              "      <td>888350.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022/09/13</th>\n",
              "      <td>8.85</td>\n",
              "      <td>8.88</td>\n",
              "      <td>8.66</td>\n",
              "      <td>8.70</td>\n",
              "      <td>712353.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-dc33df1a-9236-4527-80e0-a0de5f4920f3')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-dc33df1a-9236-4527-80e0-a0de5f4920f3 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-dc33df1a-9236-4527-80e0-a0de5f4920f3');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "AEL.info()"
      ],
      "metadata": {
        "id": "tLMJe1SMr8B8",
        "outputId": "1a3f75c6-a77b-4f5f-c0c8-53cee5e3ae64",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 6 entries, 2022/09/06 to 2022/09/13\n",
            "Data columns (total 5 columns):\n",
            " #   Column  Non-Null Count  Dtype  \n",
            "---  ------  --------------  -----  \n",
            " 0   open    6 non-null      float64\n",
            " 1   high    6 non-null      float64\n",
            " 2   low     6 non-null      float64\n",
            " 3   close   6 non-null      float64\n",
            " 4   volume  6 non-null      float64\n",
            "dtypes: float64(5)\n",
            "memory usage: 288.0+ bytes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Construct list of stock tickers from investment universe and extracting timeseries data\n",
        "\n",
        "\n",
        "---\n",
        "Yahoo Finance"
      ],
      "metadata": {
        "id": "r4vVLydQz5FW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import bs4 as bs\n",
        "import requests\n",
        "import yfinance as yf\n",
        "import datetime\n",
        "\n",
        "resp = requests.get('https://sashares.co.za/shares-list/#gs.g1jxc5')\n",
        "soup = bs.BeautifulSoup(resp.text, 'lxml')\n",
        "table = soup.find('table')\n",
        "tickers = []\n",
        "for row in table.findAll('tr')[1:]:\n",
        "    ticker = row.findAll('td')[0].text\n",
        "    tickers.append(ticker)\n",
        "\n",
        "tickers = [s.replace('\\n', '') for s in tickers]\n",
        "start = datetime.datetime(2021,7,25)\n",
        "end = datetime.datetime(2022,8,25)\n",
        "data = yf.download(tickers, start=start, end=end)\n",
        "print(data)"
      ],
      "metadata": {
        "id": "w7U6hi9D3rF_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tickers"
      ],
      "metadata": {
        "id": "z1TtUwxtSj1D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pandas_datareader"
      ],
      "metadata": {
        "id": "__lVrRrOBGOV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# pip install yfinance\n",
        "import yfinance as yf\n",
        "import datetime as datetime\n",
        " \n",
        "# Time starts from here\n",
        "start = \"2020-10-12\"\n",
        "end = \"2022-10-12\" \n",
        " \n",
        "ticker_list = tickers\n",
        " \n",
        "# Here we use yf.download function\n",
        "data = yf.download(\n",
        "    tickers=ticker_list,\n",
        "    threads=True,\n",
        "    group_by='ticker',\n",
        "    start=start, \n",
        "    end=end\n",
        " \n",
        ")\n",
        " \n",
        "# used for making transpose\n",
        "data = data.T\n",
        " \n",
        "for t in ticker_list:\n",
        "    # printing name\n",
        "    print(t)\n",
        "    print('\\n')\n",
        "     \n",
        "    # used data.loc as it takes only index\n",
        "    # labels and returns dataframe\n",
        "    print(data.loc[t]) \n",
        "    print('\\n')\n",
        "# Total time calculated\n",
        "print('The program takes ', time.time()-start, 'seconds.')"
      ],
      "metadata": {
        "id": "2GvM10gGDXD9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **EXPLORATORY DATA ANALYSIS (EDA)**\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "OlM6TGBPVSmL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mpld3"
      ],
      "metadata": {
        "id": "s14iuKoDf7rk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy import stats\n",
        "import seaborn as sn\n",
        "import matplotlib.pyplot as plt\n",
        "\"\"\"\n",
        "import mpld3\n",
        "mpld3.enable_notebook()\n",
        "\"\"\"\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "pd.set_option('display.max_rows', 2)"
      ],
      "metadata": {
        "id": "i5waJ-BLVR5U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "B = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/My Project Folder/random_futures/YMZ18.csv', parse_dates=True, index_col=0)\n",
        "\n",
        "B.info()\n",
        "\n",
        "print(B.head(5))"
      ],
      "metadata": {
        "id": "7TIUEc7qhsCf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.set_option('display.max_rows', None)\n",
        "\n",
        "B.describe()"
      ],
      "metadata": {
        "id": "-ACTvJDKWq-y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "B['Open'].plot(figsize=(12,6), \n",
        "                  linestyle='--',color='black',\n",
        "                  legend='Open')\n",
        "\n",
        "B['High'].plot(figsize=(12,6),\n",
        "                   linestyle='-',color='grey',\n",
        "                   legend='High')\n",
        "\"\"\"\n",
        "B['close'].plot(figsize=(12,6),\n",
        "                 linestyle=':',color='black',\n",
        "                 legend='Low')\n",
        "\n",
        "B['close'].plot(figsize=(12,6),\n",
        "                  linestyle='-',color='black',\n",
        "                  legend='Close')\n"
      ],
      "metadata": {
        "id": "aPN9i9h3Ydbd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "no_outlier_prices = B[(np.abs(stats.zscore(B)) <\n",
        "6).all(axis=1)]"
      ],
      "metadata": {
        "id": "yGFt1GskpsGJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "no_outlier_prices['100'].plot(figsize=(12,6), linestyle='--',\n",
        "color='black', legend='Close')"
      ],
      "metadata": {
        "id": "kSie4BpYqa8R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.set_option('display.max_rows', None)\n",
        "\n",
        "no_outlier_prices[['533.95']].describe()"
      ],
      "metadata": {
        "id": "_7kJ7-_Mw1pa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**DIGITAL ASSETS PROGRAMME**\n",
        "\n"
      ],
      "metadata": {
        "id": "tIM7wTXOAarM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Systems**\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "TycKaYmxuCVl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Single Asset Backtest"
      ],
      "metadata": {
        "id": "ySxEKidEU606"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This ensures that our graphs will be shown properly in the notebook.\n",
        "%matplotlib inline\n",
        "\n",
        "# Import libraries\n",
        "import zipline\n",
        "from zipline import run_algorithm\n",
        "from zipline.api import order_target_percent, symbol\n",
        "from datetime import datetime\n",
        "import pytz\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "def initialize(context):\n",
        "  # Which asset to trade\n",
        "  context.asset = symbol('btc')\n",
        "  \n",
        "  # Moving average window\n",
        "  context.index_average_window = 100\n",
        "\n",
        "def handle_data(context, data):\n",
        "  # Request history for the stock\n",
        "  btc_hist = data.history(context.asset, \"close\",\n",
        "                               context.index_average_window, \"1d\")\n",
        "  \n",
        "  # Check if price is above moving average\n",
        "  if btc_hist[-1] > btc_hist.mean():\n",
        "    asset_weight = 1.0\n",
        "  else:\n",
        "    asset_weight = 0.0\n",
        "    # Place order\n",
        "    order_target_percent(context.asset, asset_weight)\n",
        "\n",
        "def analyze(context, perf):\n",
        "  \n",
        "  fig = plt.figure(figsize=(12, 8))\n",
        "  \n",
        "    # First char\n",
        "  ax = fig.add_subplot(311)\n",
        "  ax.set_title('Strategy Results')\n",
        "  ax.semilogy(perf['portfolio_value'], linestyle='-',\n",
        "              label='Equity Curve', linewidth=3.0)\n",
        "  ax.legend()\n",
        "  ax.grid(False)\n",
        "\n",
        "  # Second chart\n",
        "  ax = fig.add_subplot(312)\n",
        "  ax.plot(perf['gross_leverage'],\n",
        "  label='Exposure', linestyle='-', linewidth=1.0)\n",
        "  ax.legend()\n",
        "  ax.grid(True)\n",
        "\n",
        "  # Third chart\n",
        "  ax = fig.add_subplot(313)\n",
        "  ax.plot(perf['returns'], label='Returns', linestyle='-.',\n",
        "          linewidth=1.0)"
      ],
      "metadata": {
        "id": "kcHu_Gsb7cll"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Equal Weight Model"
      ],
      "metadata": {
        "id": "_tfGWw1gYDlo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This ensures that our graphs will be shown properly in the notebook.\n",
        "%matplotlib inline\n",
        "\n",
        "# Import a few libraries we need\n",
        "from zipline import run_algorithm\n",
        "from zipline.api import order_target_percent, record, symbol, set_benchmark\n",
        "import pyfolio as pf\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "def initialize(context):\n",
        "\n",
        "  # Which stock to trade\n",
        "\n",
        "  \"\"\"\n",
        "  dji = [\"JEC\",\"BBY\",\"MSFT\",\"MCHP\",\"PEP\",\n",
        "         \"RAD\",\"PTC\",\"GCO\",\"FAST\",\"CTL\",\n",
        "         \"APA\",\"EL\",\"TMK\",\"VVI\",\"HPQ\",\n",
        "         \"CMCSA\",\"JCI\",\"T\"]\n",
        "\n",
        "  dji = [\"aave\",\"ada\",\"algo\",\"alpha\",\"ant\",\n",
        "         \"bal\",\"bat\",\"bch\",\"bnb\",\"bsv\",\n",
        "         \"btc\"]\n",
        "  \"\"\"\n",
        "\n",
        "  dji = [\"btc\"]\n",
        "\n",
        "\n",
        "  # Make a list of symbols from the list of tickers\n",
        "  context.dji_symbols = [symbol(s) for s in dji]\n",
        "\n",
        "  # Moving average window\n",
        "  context.index_average_window = 52\n",
        "  \n",
        "def handle_data(context, data):\n",
        "  \n",
        "  # Get history for all the stocks\n",
        "  stock_hist = data.history(context.dji_symbols, \"close\", context.index_average_window, \"1d\")\n",
        "\n",
        "  # Make an empty DataFrame to start with\n",
        "  stock_analytics = pd.DataFrame()\n",
        "\n",
        "  # Add column for above or below average\n",
        "  stock_analytics['above_mean'] = stock_hist.iloc[-1] > stock_hist.mean()\n",
        "\n",
        "  # Set weight for stocks to buy\n",
        "  stock_analytics.loc[stock_analytics['above_mean'] == True, 'weight'] = 1/len(context.dji_symbols)\n",
        "\n",
        "  # Set weight to zero for the rest\n",
        "  stock_analytics.loc[stock_analytics['above_mean'] == False, 'weight'] = 0.0\n",
        "\n",
        "  # Iterate each row and place trades\n",
        "  for stock, analytics in stock_analytics.iterrows():\n",
        "\n",
        "    # Check if the stock can be traded\n",
        "    if data.can_trade(stock):\n",
        "\n",
        "      # Place the trade\n",
        "      order_target_percent(stock, analytics['weight'])\n",
        "\n",
        "def analyze(context, perf):\n",
        "\n",
        "  # Use PyFolio to generate a performance report\n",
        "  returns, positions, transactions = pf.utils.extract_rets_pos_txn_from_zipline(perf)\n",
        "\n",
        "  benchmark_period_return = perf['benchmark_period_return']\n",
        "\n",
        "  daily_benchmark_returns = np.exp(np.log(benchmark_period_return + 1.0).diff()) - 1\n",
        "\n",
        "  # Create tear sheet\n",
        "  pf.create_full_tear_sheet(returns, positions=positions, transactions=transactions, benchmark_rets=None)\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "def analyze(context, perf):\n",
        "\n",
        "  fig = plt.figure(figsize=(12, 8))\n",
        "\n",
        "  # First chart\n",
        "  ax = fig.add_subplot(311)\n",
        "  ax.set_title('Strategy Results')\n",
        "  ax.plot(perf['portfolio_value'], linestyle='-',\n",
        "          label='Equity Curve', linewidth=3.0)\n",
        "  ax.legend()\n",
        "  ax.grid(False)\n",
        "\n",
        "  # Second chart\n",
        "  ax = fig.add_subplot(312)\n",
        "  ax.plot(perf['gross_leverage'],label='Exposure',\n",
        "          linestyle='-', linewidth=1.0)\n",
        "  ax.legend()\n",
        "  ax.grid(True)\n",
        "  \n",
        "  # Third chart\n",
        "  ax = fig.add_subplot(313)\n",
        "  ax.plot(perf['returns'], label='Returns', linestyle='-.',\n",
        "          linewidth=1.0)\n",
        "  ax.legend()\n",
        "  ax.grid(True)\n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "# Set start and end date\n",
        "start_date = pd.Timestamp('2016-05-02', tz='utc')\n",
        "end_date = pd.Timestamp('2020-05-02', tz='utc')\n",
        "\n",
        "# Fire off the backtest\n",
        "perf = run_algorithm(\n",
        "start=start_date,\n",
        "end=end_date,\n",
        "initialize=initialize,\n",
        "analyze=analyze,\n",
        "handle_data=handle_data,\n",
        "capital_base=10000,\n",
        "data_frequency = 'daily', \n",
        "bundle= 'crypto',)"
      ],
      "metadata": {
        "id": "JEtmR8GjFANc",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Export performance results to disk in csv file\n",
        "\n",
        "perf.portfolio_value.to_csv('ewm_momentum_model.csv')"
      ],
      "metadata": {
        "id": "BU2OOl30YXe1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Momentum Model"
      ],
      "metadata": {
        "id": "1V0GCt2_92BD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "import zipline\n",
        "from zipline import run_algorithm\n",
        "from zipline.api import order_target_percent, symbol, set_commission, set_slippage, schedule_function, date_rules, time_rules\n",
        "import matplotlib.pyplot as plt \n",
        "import pyfolio as pf\n",
        "import pandas as pd \n",
        "import numpy as np\n",
        "from scipy import stats\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "from zipline.finance.commission import PerDollar\n",
        "from zipline.finance.slippage import VolumeShareSlippage, FixedSlippage\n",
        "\n",
        "\n",
        "initial_portfolio = 10000\n",
        "minimum_momentum = 10\n",
        "portfolio_size = 1\n",
        "vola_window = 30\n",
        "\n",
        "def momentum_score(ts):\n",
        "\n",
        "  #Input: Price time series.Output: Annualized exponential regression slope, multiplied by the R2\n",
        "\n",
        "  # Make a list of consecutive numbers \n",
        "  x = np.arange(len(ts))\n",
        "  # Get logs\n",
        "  log_ts = np.log(ts)\n",
        "  # Calculate regression values\n",
        "  slope, intercept, r_value, p_value, std_err = stats.linregress(x, log_ts) \n",
        "  # Annualize percent\n",
        "  annualized_slope = (np.power(np.exp(slope), 252) - 1) * 100 \n",
        "  #Adjust for fitness\n",
        "  score = annualized_slope * (r_value ** 2) \n",
        "  return score\n",
        "\n",
        "def volatility(ts):\n",
        "  return ts.pct_change().rolling(vola_window).std().iloc[-1]\n",
        "\n",
        "\n",
        "#Initialization and trading logic\n",
        "\n",
        "\n",
        "def initialize(context):\n",
        "\n",
        "  context.rolling_window = 100\n",
        "\n",
        "  #Commission and Slippage Settings\n",
        "\n",
        "  enable_commission = True \n",
        "  commission_pct = 0.001 \n",
        "  enable_slippage = True \n",
        "  slippage_volume_limit = 0.025\n",
        "  slippage_impact = 0.05\n",
        "\n",
        "  \"\"\"\n",
        "  dji = [\"AAVE\",\"ADA\",\"ALPHA\",\"BCH\",\"BTC\",\n",
        "          \"DOGE\",\"DOT\",\"ETH\",\"LTC\",\"USDT\",\n",
        "          \"XLM\",\"XMR\",\"XRP\"]\n",
        "  \"\"\"\n",
        "  dji = [\"btc\",\"ltc\",\"eth\"]\n",
        "\n",
        "  \n",
        "  # Make a list of symbols from the list of tickers\n",
        "  context.dji_symbols = [symbol(s) for s in dji]\n",
        "\n",
        "  # Set commission and slippage.\n",
        "  if enable_commission:\n",
        "    comm_model = PerDollar(cost=commission_pct) \n",
        "  else:\n",
        "    comm_model = PerDollar(cost=0.0) \n",
        "  set_commission(comm_model)\n",
        "  if enable_slippage: slippage_model=VolumeShareSlippage(volume_limit=slippage_volume_limit,\n",
        "price_impact=slippage_impact) \n",
        "  else:\n",
        "    slippage_model=FixedSlippage(spread=0.0) \n",
        "  set_slippage(slippage_model)\n",
        "\n",
        "\n",
        "  #Schedule rebalance monthly. \n",
        "  schedule_function(\n",
        "    func=rebalance, \n",
        "    date_rule=date_rules.month_start(), \n",
        "    time_rule=time_rules.market_open()\n",
        "  )\n",
        "\n",
        "def rebalance(context, data):\n",
        "\n",
        "  # Get historical data\n",
        "  hist = data.history(context.dji_symbols, \"close\", context.rolling_window, \"1d\")\n",
        "\n",
        "  # Make momentum ranking table\n",
        "  ranking_table = hist.apply(momentum_score).sort_values(ascending=False)\n",
        "\n",
        "  #Sell Logic\n",
        "  #First we check if any existing position should be sold.\n",
        "    #Sell if stock is no longer part of index.\n",
        "    #Sell if stock has too low momentum value.\n",
        "\n",
        "  kept_positions = list(context.portfolio.positions.keys()) \n",
        "  for security in context.portfolio.positions:\n",
        "    if ranking_table[security] < minimum_momentum: \n",
        "      order_target_percent(security, 0.0)\n",
        "      kept_positions.remove(security)\n",
        " \n",
        "  #Stock Selection Logic\n",
        "  #Check how many stocks we are keeping from last month.\n",
        "  #Fill from top of ranking list, until we reach the desired total number of portfolio holdings.\n",
        "\n",
        "  replacement_stocks = portfolio_size - len(kept_positions) \n",
        "  buy_list = ranking_table.loc[\n",
        "    ~ranking_table.index.isin(kept_positions)][:replacement_stocks]\n",
        "  new_portfolio = pd.concat(\n",
        "    (buy_list,\n",
        "    ranking_table.loc[ranking_table.index.isin(kept_positions)])\n",
        "  )\n",
        "  buy_list = ranking_table.loc[\n",
        "    ~ranking_table.index.isin(kept_positions)][:replacement_stocks]\n",
        "\n",
        "  #Calculate inverse volatility for stocks, and make target position weights.\n",
        "\n",
        "  vola_table = hist[new_portfolio.index].apply(volatility) \n",
        "  inv_vola_table = 1 / vola_table\n",
        "  sum_inv_vola = np.sum(inv_vola_table) \n",
        "  vola_target_weights = inv_vola_table / sum_inv_vola\n",
        "  for security, rank in new_portfolio.iteritems(): \n",
        "    weight = vola_target_weights[security]\n",
        "    if security in kept_positions:\n",
        "      order_target_percent(security, weight)\n",
        "    else:\n",
        "      if ranking_table[security] > minimum_momentum: \n",
        "        order_target_percent(security, weight)\n",
        "\n",
        "\n",
        "def analyze(context, perf):\n",
        "    \n",
        "  # Use PyFolio to generate a performance report\n",
        "  returns, positions, transactions = pf.utils.extract_rets_pos_txn_from_zipline(perf)\n",
        "\n",
        "  benchmark_period_return = perf['benchmark_period_return']\n",
        "\n",
        "  daily_benchmark_returns = np.exp(np.log(benchmark_period_return + 1.0).diff()) - 1\n",
        "\n",
        "  # Create tear sheet\n",
        "  pf.create_full_tear_sheet(returns, positions=positions, transactions=transactions, benchmark_rets=None)\n",
        "\n",
        "start= pd.Timestamp('2015-5-1', tz='utc')\n",
        "end = pd.Timestamp('2022-5-2', tz='utc')\n",
        "\n",
        "perf = zipline.run_algorithm(start=start, \n",
        "                             end=end, \n",
        "                             initialize=initialize, \n",
        "                             analyze=analyze, \n",
        "                             capital_base=initial_portfolio, \n",
        "                             data_frequency='daily',\n",
        "                             bundle='crypto')"
      ],
      "metadata": {
        "id": "OfmZYBZ4p4nv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Export Performance Result to disk in csv file\n",
        "\n",
        "perf.portfolio_value.to_csv('crypto_momentum.csv')"
      ],
      "metadata": {
        "id": "M18L5KZe3rQr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Model Performance**"
      ],
      "metadata": {
        "id": "kPK0-JU_Y1Ke"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gyaPFiaykaNm",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}